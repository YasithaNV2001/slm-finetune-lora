{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 12630,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0023752969121140144,
      "grad_norm": 0.9023419618606567,
      "learning_rate": 4.996041171813143e-05,
      "loss": 0.6967,
      "step": 10
    },
    {
      "epoch": 0.004750593824228029,
      "grad_norm": 1.8849676847457886,
      "learning_rate": 4.992082343626287e-05,
      "loss": 0.6743,
      "step": 20
    },
    {
      "epoch": 0.007125890736342043,
      "grad_norm": 1.84205961227417,
      "learning_rate": 4.98812351543943e-05,
      "loss": 0.6717,
      "step": 30
    },
    {
      "epoch": 0.009501187648456057,
      "grad_norm": 0.9188621640205383,
      "learning_rate": 4.984164687252573e-05,
      "loss": 0.666,
      "step": 40
    },
    {
      "epoch": 0.011876484560570071,
      "grad_norm": 1.1191372871398926,
      "learning_rate": 4.980205859065717e-05,
      "loss": 0.6585,
      "step": 50
    },
    {
      "epoch": 0.014251781472684086,
      "grad_norm": 0.983137309551239,
      "learning_rate": 4.97624703087886e-05,
      "loss": 0.626,
      "step": 60
    },
    {
      "epoch": 0.0166270783847981,
      "grad_norm": 1.583526372909546,
      "learning_rate": 4.972288202692003e-05,
      "loss": 0.5825,
      "step": 70
    },
    {
      "epoch": 0.019002375296912115,
      "grad_norm": 1.8200016021728516,
      "learning_rate": 4.968329374505147e-05,
      "loss": 0.5255,
      "step": 80
    },
    {
      "epoch": 0.021377672209026127,
      "grad_norm": 1.9179775714874268,
      "learning_rate": 4.96437054631829e-05,
      "loss": 0.452,
      "step": 90
    },
    {
      "epoch": 0.023752969121140142,
      "grad_norm": 1.8782144784927368,
      "learning_rate": 4.9604117181314336e-05,
      "loss": 0.4371,
      "step": 100
    },
    {
      "epoch": 0.026128266033254157,
      "grad_norm": 1.8363395929336548,
      "learning_rate": 4.956452889944577e-05,
      "loss": 0.3719,
      "step": 110
    },
    {
      "epoch": 0.028503562945368172,
      "grad_norm": 3.679140567779541,
      "learning_rate": 4.95249406175772e-05,
      "loss": 0.3764,
      "step": 120
    },
    {
      "epoch": 0.030878859857482184,
      "grad_norm": 1.9157711267471313,
      "learning_rate": 4.9485352335708635e-05,
      "loss": 0.3815,
      "step": 130
    },
    {
      "epoch": 0.0332541567695962,
      "grad_norm": 1.7918108701705933,
      "learning_rate": 4.9445764053840065e-05,
      "loss": 0.4261,
      "step": 140
    },
    {
      "epoch": 0.035629453681710214,
      "grad_norm": 7.312460422515869,
      "learning_rate": 4.9406175771971496e-05,
      "loss": 0.2836,
      "step": 150
    },
    {
      "epoch": 0.03800475059382423,
      "grad_norm": 1.246088981628418,
      "learning_rate": 4.9366587490102933e-05,
      "loss": 0.286,
      "step": 160
    },
    {
      "epoch": 0.040380047505938245,
      "grad_norm": 2.9810447692871094,
      "learning_rate": 4.9326999208234364e-05,
      "loss": 0.3148,
      "step": 170
    },
    {
      "epoch": 0.04275534441805225,
      "grad_norm": 5.62047815322876,
      "learning_rate": 4.9287410926365795e-05,
      "loss": 0.3494,
      "step": 180
    },
    {
      "epoch": 0.04513064133016627,
      "grad_norm": 6.425576210021973,
      "learning_rate": 4.924782264449723e-05,
      "loss": 0.3933,
      "step": 190
    },
    {
      "epoch": 0.047505938242280284,
      "grad_norm": 3.434051990509033,
      "learning_rate": 4.920823436262866e-05,
      "loss": 0.4896,
      "step": 200
    },
    {
      "epoch": 0.0498812351543943,
      "grad_norm": 2.787813663482666,
      "learning_rate": 4.9168646080760093e-05,
      "loss": 0.3353,
      "step": 210
    },
    {
      "epoch": 0.052256532066508314,
      "grad_norm": 1.5819844007492065,
      "learning_rate": 4.912905779889153e-05,
      "loss": 0.3375,
      "step": 220
    },
    {
      "epoch": 0.05463182897862233,
      "grad_norm": 3.7400686740875244,
      "learning_rate": 4.908946951702296e-05,
      "loss": 0.3217,
      "step": 230
    },
    {
      "epoch": 0.057007125890736345,
      "grad_norm": 2.1032869815826416,
      "learning_rate": 4.90498812351544e-05,
      "loss": 0.3593,
      "step": 240
    },
    {
      "epoch": 0.05938242280285035,
      "grad_norm": 1.1997096538543701,
      "learning_rate": 4.901029295328583e-05,
      "loss": 0.2083,
      "step": 250
    },
    {
      "epoch": 0.06175771971496437,
      "grad_norm": 2.7333967685699463,
      "learning_rate": 4.897070467141726e-05,
      "loss": 0.3379,
      "step": 260
    },
    {
      "epoch": 0.06413301662707839,
      "grad_norm": 5.4823150634765625,
      "learning_rate": 4.89311163895487e-05,
      "loss": 0.3624,
      "step": 270
    },
    {
      "epoch": 0.0665083135391924,
      "grad_norm": 2.847093105316162,
      "learning_rate": 4.889152810768013e-05,
      "loss": 0.3322,
      "step": 280
    },
    {
      "epoch": 0.0688836104513064,
      "grad_norm": 5.480992317199707,
      "learning_rate": 4.885193982581156e-05,
      "loss": 0.3481,
      "step": 290
    },
    {
      "epoch": 0.07125890736342043,
      "grad_norm": 2.6716067790985107,
      "learning_rate": 4.8812351543942996e-05,
      "loss": 0.2956,
      "step": 300
    },
    {
      "epoch": 0.07363420427553444,
      "grad_norm": 3.5539002418518066,
      "learning_rate": 4.877276326207443e-05,
      "loss": 0.3756,
      "step": 310
    },
    {
      "epoch": 0.07600950118764846,
      "grad_norm": 4.575502395629883,
      "learning_rate": 4.873317498020586e-05,
      "loss": 0.376,
      "step": 320
    },
    {
      "epoch": 0.07838479809976247,
      "grad_norm": 2.875171422958374,
      "learning_rate": 4.8693586698337295e-05,
      "loss": 0.3847,
      "step": 330
    },
    {
      "epoch": 0.08076009501187649,
      "grad_norm": 1.700289249420166,
      "learning_rate": 4.8653998416468726e-05,
      "loss": 0.4599,
      "step": 340
    },
    {
      "epoch": 0.0831353919239905,
      "grad_norm": 4.116451740264893,
      "learning_rate": 4.8614410134600156e-05,
      "loss": 0.3114,
      "step": 350
    },
    {
      "epoch": 0.0855106888361045,
      "grad_norm": 3.094240188598633,
      "learning_rate": 4.8574821852731594e-05,
      "loss": 0.3525,
      "step": 360
    },
    {
      "epoch": 0.08788598574821853,
      "grad_norm": 2.7389416694641113,
      "learning_rate": 4.8535233570863024e-05,
      "loss": 0.3537,
      "step": 370
    },
    {
      "epoch": 0.09026128266033254,
      "grad_norm": 4.127866268157959,
      "learning_rate": 4.849564528899446e-05,
      "loss": 0.3418,
      "step": 380
    },
    {
      "epoch": 0.09263657957244656,
      "grad_norm": 2.5872344970703125,
      "learning_rate": 4.845605700712589e-05,
      "loss": 0.3109,
      "step": 390
    },
    {
      "epoch": 0.09501187648456057,
      "grad_norm": 3.9851958751678467,
      "learning_rate": 4.841646872525732e-05,
      "loss": 0.3502,
      "step": 400
    },
    {
      "epoch": 0.09738717339667459,
      "grad_norm": 2.611020803451538,
      "learning_rate": 4.837688044338876e-05,
      "loss": 0.3878,
      "step": 410
    },
    {
      "epoch": 0.0997624703087886,
      "grad_norm": 3.9006192684173584,
      "learning_rate": 4.833729216152019e-05,
      "loss": 0.2943,
      "step": 420
    },
    {
      "epoch": 0.1021377672209026,
      "grad_norm": 6.639471054077148,
      "learning_rate": 4.829770387965162e-05,
      "loss": 0.2895,
      "step": 430
    },
    {
      "epoch": 0.10451306413301663,
      "grad_norm": 2.5532779693603516,
      "learning_rate": 4.825811559778306e-05,
      "loss": 0.3227,
      "step": 440
    },
    {
      "epoch": 0.10688836104513064,
      "grad_norm": 1.7102805376052856,
      "learning_rate": 4.821852731591449e-05,
      "loss": 0.3505,
      "step": 450
    },
    {
      "epoch": 0.10926365795724466,
      "grad_norm": 7.355833530426025,
      "learning_rate": 4.817893903404592e-05,
      "loss": 0.3435,
      "step": 460
    },
    {
      "epoch": 0.11163895486935867,
      "grad_norm": 1.3442585468292236,
      "learning_rate": 4.813935075217736e-05,
      "loss": 0.2693,
      "step": 470
    },
    {
      "epoch": 0.11401425178147269,
      "grad_norm": 4.597161293029785,
      "learning_rate": 4.809976247030879e-05,
      "loss": 0.4172,
      "step": 480
    },
    {
      "epoch": 0.1163895486935867,
      "grad_norm": 3.8236286640167236,
      "learning_rate": 4.806017418844022e-05,
      "loss": 0.3623,
      "step": 490
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 4.543306350708008,
      "learning_rate": 4.802058590657166e-05,
      "loss": 0.3535,
      "step": 500
    },
    {
      "epoch": 0.12114014251781473,
      "grad_norm": 3.1373798847198486,
      "learning_rate": 4.798099762470309e-05,
      "loss": 0.2908,
      "step": 510
    },
    {
      "epoch": 0.12351543942992874,
      "grad_norm": 3.2414956092834473,
      "learning_rate": 4.7941409342834525e-05,
      "loss": 0.3278,
      "step": 520
    },
    {
      "epoch": 0.12589073634204276,
      "grad_norm": 3.6513545513153076,
      "learning_rate": 4.7901821060965955e-05,
      "loss": 0.3645,
      "step": 530
    },
    {
      "epoch": 0.12826603325415678,
      "grad_norm": 1.3465805053710938,
      "learning_rate": 4.7862232779097386e-05,
      "loss": 0.282,
      "step": 540
    },
    {
      "epoch": 0.13064133016627077,
      "grad_norm": 3.4117796421051025,
      "learning_rate": 4.7822644497228824e-05,
      "loss": 0.3431,
      "step": 550
    },
    {
      "epoch": 0.1330166270783848,
      "grad_norm": 2.1140780448913574,
      "learning_rate": 4.7783056215360254e-05,
      "loss": 0.4226,
      "step": 560
    },
    {
      "epoch": 0.13539192399049882,
      "grad_norm": 2.7171778678894043,
      "learning_rate": 4.7743467933491685e-05,
      "loss": 0.4307,
      "step": 570
    },
    {
      "epoch": 0.1377672209026128,
      "grad_norm": 1.6500588655471802,
      "learning_rate": 4.770387965162312e-05,
      "loss": 0.3465,
      "step": 580
    },
    {
      "epoch": 0.14014251781472684,
      "grad_norm": 1.721325397491455,
      "learning_rate": 4.766429136975455e-05,
      "loss": 0.3766,
      "step": 590
    },
    {
      "epoch": 0.14251781472684086,
      "grad_norm": 1.2814574241638184,
      "learning_rate": 4.7624703087885984e-05,
      "loss": 0.3181,
      "step": 600
    },
    {
      "epoch": 0.14489311163895488,
      "grad_norm": 8.169124603271484,
      "learning_rate": 4.758511480601742e-05,
      "loss": 0.344,
      "step": 610
    },
    {
      "epoch": 0.14726840855106887,
      "grad_norm": 3.3702383041381836,
      "learning_rate": 4.754552652414885e-05,
      "loss": 0.3378,
      "step": 620
    },
    {
      "epoch": 0.1496437054631829,
      "grad_norm": 4.281397819519043,
      "learning_rate": 4.750593824228028e-05,
      "loss": 0.2915,
      "step": 630
    },
    {
      "epoch": 0.15201900237529692,
      "grad_norm": 5.131885528564453,
      "learning_rate": 4.746634996041172e-05,
      "loss": 0.3304,
      "step": 640
    },
    {
      "epoch": 0.1543942992874109,
      "grad_norm": 2.094928026199341,
      "learning_rate": 4.742676167854315e-05,
      "loss": 0.2518,
      "step": 650
    },
    {
      "epoch": 0.15676959619952494,
      "grad_norm": 3.8811023235321045,
      "learning_rate": 4.738717339667459e-05,
      "loss": 0.361,
      "step": 660
    },
    {
      "epoch": 0.15914489311163896,
      "grad_norm": 2.2299013137817383,
      "learning_rate": 4.734758511480602e-05,
      "loss": 0.2864,
      "step": 670
    },
    {
      "epoch": 0.16152019002375298,
      "grad_norm": 3.59177303314209,
      "learning_rate": 4.730799683293745e-05,
      "loss": 0.2201,
      "step": 680
    },
    {
      "epoch": 0.16389548693586697,
      "grad_norm": 3.442707061767578,
      "learning_rate": 4.7268408551068886e-05,
      "loss": 0.2674,
      "step": 690
    },
    {
      "epoch": 0.166270783847981,
      "grad_norm": 4.737551212310791,
      "learning_rate": 4.722882026920032e-05,
      "loss": 0.3548,
      "step": 700
    },
    {
      "epoch": 0.16864608076009502,
      "grad_norm": 3.540510892868042,
      "learning_rate": 4.718923198733175e-05,
      "loss": 0.2642,
      "step": 710
    },
    {
      "epoch": 0.171021377672209,
      "grad_norm": 3.3979647159576416,
      "learning_rate": 4.7149643705463185e-05,
      "loss": 0.3604,
      "step": 720
    },
    {
      "epoch": 0.17339667458432304,
      "grad_norm": 1.6775354146957397,
      "learning_rate": 4.7110055423594616e-05,
      "loss": 0.3362,
      "step": 730
    },
    {
      "epoch": 0.17577197149643706,
      "grad_norm": 3.125659227371216,
      "learning_rate": 4.7070467141726046e-05,
      "loss": 0.3646,
      "step": 740
    },
    {
      "epoch": 0.17814726840855108,
      "grad_norm": 3.2922115325927734,
      "learning_rate": 4.7030878859857484e-05,
      "loss": 0.267,
      "step": 750
    },
    {
      "epoch": 0.18052256532066507,
      "grad_norm": 5.285987854003906,
      "learning_rate": 4.6991290577988915e-05,
      "loss": 0.2978,
      "step": 760
    },
    {
      "epoch": 0.1828978622327791,
      "grad_norm": 2.391538381576538,
      "learning_rate": 4.6951702296120345e-05,
      "loss": 0.3982,
      "step": 770
    },
    {
      "epoch": 0.18527315914489312,
      "grad_norm": 4.405084133148193,
      "learning_rate": 4.691211401425178e-05,
      "loss": 0.29,
      "step": 780
    },
    {
      "epoch": 0.1876484560570071,
      "grad_norm": 1.1882610321044922,
      "learning_rate": 4.687252573238321e-05,
      "loss": 0.3052,
      "step": 790
    },
    {
      "epoch": 0.19002375296912113,
      "grad_norm": 3.3139946460723877,
      "learning_rate": 4.683293745051465e-05,
      "loss": 0.3383,
      "step": 800
    },
    {
      "epoch": 0.19239904988123516,
      "grad_norm": 2.4827256202697754,
      "learning_rate": 4.679334916864608e-05,
      "loss": 0.2817,
      "step": 810
    },
    {
      "epoch": 0.19477434679334918,
      "grad_norm": 5.404379367828369,
      "learning_rate": 4.675376088677751e-05,
      "loss": 0.4025,
      "step": 820
    },
    {
      "epoch": 0.19714964370546317,
      "grad_norm": 2.4820125102996826,
      "learning_rate": 4.671417260490895e-05,
      "loss": 0.3134,
      "step": 830
    },
    {
      "epoch": 0.1995249406175772,
      "grad_norm": 6.342955112457275,
      "learning_rate": 4.667458432304038e-05,
      "loss": 0.3644,
      "step": 840
    },
    {
      "epoch": 0.20190023752969122,
      "grad_norm": 3.8509984016418457,
      "learning_rate": 4.663499604117181e-05,
      "loss": 0.349,
      "step": 850
    },
    {
      "epoch": 0.2042755344418052,
      "grad_norm": 5.530254364013672,
      "learning_rate": 4.659540775930325e-05,
      "loss": 0.3837,
      "step": 860
    },
    {
      "epoch": 0.20665083135391923,
      "grad_norm": 3.2420105934143066,
      "learning_rate": 4.655581947743468e-05,
      "loss": 0.3619,
      "step": 870
    },
    {
      "epoch": 0.20902612826603326,
      "grad_norm": 2.9654345512390137,
      "learning_rate": 4.651623119556611e-05,
      "loss": 0.3763,
      "step": 880
    },
    {
      "epoch": 0.21140142517814728,
      "grad_norm": 6.1763505935668945,
      "learning_rate": 4.647664291369755e-05,
      "loss": 0.3723,
      "step": 890
    },
    {
      "epoch": 0.21377672209026127,
      "grad_norm": 2.71142840385437,
      "learning_rate": 4.643705463182898e-05,
      "loss": 0.3849,
      "step": 900
    },
    {
      "epoch": 0.2161520190023753,
      "grad_norm": 2.8069100379943848,
      "learning_rate": 4.639746634996041e-05,
      "loss": 0.227,
      "step": 910
    },
    {
      "epoch": 0.21852731591448932,
      "grad_norm": 1.744861125946045,
      "learning_rate": 4.6357878068091846e-05,
      "loss": 0.3747,
      "step": 920
    },
    {
      "epoch": 0.2209026128266033,
      "grad_norm": 2.166450023651123,
      "learning_rate": 4.6318289786223276e-05,
      "loss": 0.3678,
      "step": 930
    },
    {
      "epoch": 0.22327790973871733,
      "grad_norm": 7.423383712768555,
      "learning_rate": 4.6278701504354714e-05,
      "loss": 0.291,
      "step": 940
    },
    {
      "epoch": 0.22565320665083136,
      "grad_norm": 3.8548946380615234,
      "learning_rate": 4.6239113222486144e-05,
      "loss": 0.3701,
      "step": 950
    },
    {
      "epoch": 0.22802850356294538,
      "grad_norm": 3.0892255306243896,
      "learning_rate": 4.6199524940617575e-05,
      "loss": 0.2379,
      "step": 960
    },
    {
      "epoch": 0.23040380047505937,
      "grad_norm": 4.141510486602783,
      "learning_rate": 4.615993665874901e-05,
      "loss": 0.2738,
      "step": 970
    },
    {
      "epoch": 0.2327790973871734,
      "grad_norm": 5.517606258392334,
      "learning_rate": 4.612034837688044e-05,
      "loss": 0.3198,
      "step": 980
    },
    {
      "epoch": 0.23515439429928742,
      "grad_norm": 5.449410438537598,
      "learning_rate": 4.6080760095011874e-05,
      "loss": 0.3157,
      "step": 990
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 3.684709310531616,
      "learning_rate": 4.604117181314331e-05,
      "loss": 0.3041,
      "step": 1000
    },
    {
      "epoch": 0.23990498812351543,
      "grad_norm": 9.504312515258789,
      "learning_rate": 4.600158353127474e-05,
      "loss": 0.3138,
      "step": 1010
    },
    {
      "epoch": 0.24228028503562946,
      "grad_norm": 2.570462942123413,
      "learning_rate": 4.596199524940617e-05,
      "loss": 0.2771,
      "step": 1020
    },
    {
      "epoch": 0.24465558194774348,
      "grad_norm": 3.185668468475342,
      "learning_rate": 4.592240696753761e-05,
      "loss": 0.2984,
      "step": 1030
    },
    {
      "epoch": 0.24703087885985747,
      "grad_norm": 3.2402119636535645,
      "learning_rate": 4.588281868566904e-05,
      "loss": 0.3067,
      "step": 1040
    },
    {
      "epoch": 0.2494061757719715,
      "grad_norm": 5.202507019042969,
      "learning_rate": 4.584323040380048e-05,
      "loss": 0.3576,
      "step": 1050
    },
    {
      "epoch": 0.2517814726840855,
      "grad_norm": 2.2043144702911377,
      "learning_rate": 4.580364212193191e-05,
      "loss": 0.3464,
      "step": 1060
    },
    {
      "epoch": 0.25415676959619954,
      "grad_norm": 4.154271125793457,
      "learning_rate": 4.576405384006334e-05,
      "loss": 0.3166,
      "step": 1070
    },
    {
      "epoch": 0.25653206650831356,
      "grad_norm": 2.8200716972351074,
      "learning_rate": 4.5724465558194777e-05,
      "loss": 0.3239,
      "step": 1080
    },
    {
      "epoch": 0.2589073634204275,
      "grad_norm": 8.144580841064453,
      "learning_rate": 4.568487727632621e-05,
      "loss": 0.3395,
      "step": 1090
    },
    {
      "epoch": 0.26128266033254155,
      "grad_norm": 3.1333534717559814,
      "learning_rate": 4.564528899445764e-05,
      "loss": 0.2936,
      "step": 1100
    },
    {
      "epoch": 0.26365795724465557,
      "grad_norm": 1.4494658708572388,
      "learning_rate": 4.5605700712589075e-05,
      "loss": 0.2827,
      "step": 1110
    },
    {
      "epoch": 0.2660332541567696,
      "grad_norm": 1.565819263458252,
      "learning_rate": 4.5566112430720506e-05,
      "loss": 0.2959,
      "step": 1120
    },
    {
      "epoch": 0.2684085510688836,
      "grad_norm": 2.672501802444458,
      "learning_rate": 4.552652414885194e-05,
      "loss": 0.2532,
      "step": 1130
    },
    {
      "epoch": 0.27078384798099764,
      "grad_norm": 2.68205189704895,
      "learning_rate": 4.5486935866983374e-05,
      "loss": 0.3183,
      "step": 1140
    },
    {
      "epoch": 0.27315914489311166,
      "grad_norm": 2.776737689971924,
      "learning_rate": 4.5447347585114805e-05,
      "loss": 0.3288,
      "step": 1150
    },
    {
      "epoch": 0.2755344418052256,
      "grad_norm": 3.6635184288024902,
      "learning_rate": 4.540775930324624e-05,
      "loss": 0.3039,
      "step": 1160
    },
    {
      "epoch": 0.27790973871733965,
      "grad_norm": 4.238193511962891,
      "learning_rate": 4.536817102137767e-05,
      "loss": 0.2048,
      "step": 1170
    },
    {
      "epoch": 0.28028503562945367,
      "grad_norm": 1.7611582279205322,
      "learning_rate": 4.5328582739509103e-05,
      "loss": 0.227,
      "step": 1180
    },
    {
      "epoch": 0.2826603325415677,
      "grad_norm": 1.1435492038726807,
      "learning_rate": 4.528899445764054e-05,
      "loss": 0.1898,
      "step": 1190
    },
    {
      "epoch": 0.2850356294536817,
      "grad_norm": 6.577297210693359,
      "learning_rate": 4.524940617577197e-05,
      "loss": 0.3418,
      "step": 1200
    },
    {
      "epoch": 0.28741092636579574,
      "grad_norm": 3.7595107555389404,
      "learning_rate": 4.520981789390341e-05,
      "loss": 0.4054,
      "step": 1210
    },
    {
      "epoch": 0.28978622327790976,
      "grad_norm": 3.3109991550445557,
      "learning_rate": 4.517022961203484e-05,
      "loss": 0.2938,
      "step": 1220
    },
    {
      "epoch": 0.2921615201900237,
      "grad_norm": 2.964686393737793,
      "learning_rate": 4.513064133016627e-05,
      "loss": 0.2172,
      "step": 1230
    },
    {
      "epoch": 0.29453681710213775,
      "grad_norm": 3.665468692779541,
      "learning_rate": 4.509105304829771e-05,
      "loss": 0.3602,
      "step": 1240
    },
    {
      "epoch": 0.29691211401425177,
      "grad_norm": 2.4029064178466797,
      "learning_rate": 4.505146476642914e-05,
      "loss": 0.3336,
      "step": 1250
    },
    {
      "epoch": 0.2992874109263658,
      "grad_norm": 2.635908842086792,
      "learning_rate": 4.501187648456057e-05,
      "loss": 0.2621,
      "step": 1260
    },
    {
      "epoch": 0.3016627078384798,
      "grad_norm": 2.075921058654785,
      "learning_rate": 4.4972288202692006e-05,
      "loss": 0.3054,
      "step": 1270
    },
    {
      "epoch": 0.30403800475059384,
      "grad_norm": 2.734119415283203,
      "learning_rate": 4.493269992082344e-05,
      "loss": 0.3676,
      "step": 1280
    },
    {
      "epoch": 0.30641330166270786,
      "grad_norm": 1.2646734714508057,
      "learning_rate": 4.4893111638954874e-05,
      "loss": 0.2859,
      "step": 1290
    },
    {
      "epoch": 0.3087885985748218,
      "grad_norm": 3.1952197551727295,
      "learning_rate": 4.4853523357086305e-05,
      "loss": 0.2983,
      "step": 1300
    },
    {
      "epoch": 0.31116389548693585,
      "grad_norm": 4.236024379730225,
      "learning_rate": 4.4813935075217736e-05,
      "loss": 0.3434,
      "step": 1310
    },
    {
      "epoch": 0.31353919239904987,
      "grad_norm": 2.8742425441741943,
      "learning_rate": 4.477434679334917e-05,
      "loss": 0.2482,
      "step": 1320
    },
    {
      "epoch": 0.3159144893111639,
      "grad_norm": 3.8534696102142334,
      "learning_rate": 4.4734758511480604e-05,
      "loss": 0.3868,
      "step": 1330
    },
    {
      "epoch": 0.3182897862232779,
      "grad_norm": 4.516327381134033,
      "learning_rate": 4.469517022961204e-05,
      "loss": 0.293,
      "step": 1340
    },
    {
      "epoch": 0.32066508313539194,
      "grad_norm": 1.6330692768096924,
      "learning_rate": 4.465558194774347e-05,
      "loss": 0.3199,
      "step": 1350
    },
    {
      "epoch": 0.32304038004750596,
      "grad_norm": 5.557164669036865,
      "learning_rate": 4.46159936658749e-05,
      "loss": 0.2328,
      "step": 1360
    },
    {
      "epoch": 0.3254156769596199,
      "grad_norm": 3.280874490737915,
      "learning_rate": 4.457640538400634e-05,
      "loss": 0.2972,
      "step": 1370
    },
    {
      "epoch": 0.32779097387173395,
      "grad_norm": 4.8099188804626465,
      "learning_rate": 4.453681710213777e-05,
      "loss": 0.2863,
      "step": 1380
    },
    {
      "epoch": 0.33016627078384797,
      "grad_norm": 5.023634433746338,
      "learning_rate": 4.44972288202692e-05,
      "loss": 0.3074,
      "step": 1390
    },
    {
      "epoch": 0.332541567695962,
      "grad_norm": 2.085508346557617,
      "learning_rate": 4.445764053840064e-05,
      "loss": 0.2704,
      "step": 1400
    },
    {
      "epoch": 0.334916864608076,
      "grad_norm": 7.6895575523376465,
      "learning_rate": 4.441805225653207e-05,
      "loss": 0.2723,
      "step": 1410
    },
    {
      "epoch": 0.33729216152019004,
      "grad_norm": 4.318644046783447,
      "learning_rate": 4.437846397466351e-05,
      "loss": 0.2772,
      "step": 1420
    },
    {
      "epoch": 0.33966745843230406,
      "grad_norm": 1.8686046600341797,
      "learning_rate": 4.433887569279494e-05,
      "loss": 0.2434,
      "step": 1430
    },
    {
      "epoch": 0.342042755344418,
      "grad_norm": 6.854090690612793,
      "learning_rate": 4.429928741092637e-05,
      "loss": 0.248,
      "step": 1440
    },
    {
      "epoch": 0.34441805225653205,
      "grad_norm": 2.040499448776245,
      "learning_rate": 4.4259699129057805e-05,
      "loss": 0.1893,
      "step": 1450
    },
    {
      "epoch": 0.34679334916864607,
      "grad_norm": 6.204543590545654,
      "learning_rate": 4.4220110847189236e-05,
      "loss": 0.2106,
      "step": 1460
    },
    {
      "epoch": 0.3491686460807601,
      "grad_norm": 2.143360137939453,
      "learning_rate": 4.418052256532067e-05,
      "loss": 0.3578,
      "step": 1470
    },
    {
      "epoch": 0.3515439429928741,
      "grad_norm": 3.647315740585327,
      "learning_rate": 4.4140934283452104e-05,
      "loss": 0.4223,
      "step": 1480
    },
    {
      "epoch": 0.35391923990498814,
      "grad_norm": 2.606480836868286,
      "learning_rate": 4.4101346001583535e-05,
      "loss": 0.3375,
      "step": 1490
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 3.323969602584839,
      "learning_rate": 4.406175771971497e-05,
      "loss": 0.274,
      "step": 1500
    },
    {
      "epoch": 0.3586698337292161,
      "grad_norm": 8.768320083618164,
      "learning_rate": 4.40221694378464e-05,
      "loss": 0.2541,
      "step": 1510
    },
    {
      "epoch": 0.36104513064133015,
      "grad_norm": 4.466680526733398,
      "learning_rate": 4.3982581155977833e-05,
      "loss": 0.3688,
      "step": 1520
    },
    {
      "epoch": 0.36342042755344417,
      "grad_norm": 3.4251415729522705,
      "learning_rate": 4.394299287410927e-05,
      "loss": 0.342,
      "step": 1530
    },
    {
      "epoch": 0.3657957244655582,
      "grad_norm": 4.331849098205566,
      "learning_rate": 4.39034045922407e-05,
      "loss": 0.2999,
      "step": 1540
    },
    {
      "epoch": 0.3681710213776722,
      "grad_norm": 2.1322925090789795,
      "learning_rate": 4.386381631037213e-05,
      "loss": 0.3466,
      "step": 1550
    },
    {
      "epoch": 0.37054631828978624,
      "grad_norm": 4.331733703613281,
      "learning_rate": 4.382422802850357e-05,
      "loss": 0.2076,
      "step": 1560
    },
    {
      "epoch": 0.37292161520190026,
      "grad_norm": 2.6358981132507324,
      "learning_rate": 4.3784639746635e-05,
      "loss": 0.263,
      "step": 1570
    },
    {
      "epoch": 0.3752969121140142,
      "grad_norm": 3.308182954788208,
      "learning_rate": 4.374505146476643e-05,
      "loss": 0.1946,
      "step": 1580
    },
    {
      "epoch": 0.37767220902612825,
      "grad_norm": 4.376931190490723,
      "learning_rate": 4.370546318289787e-05,
      "loss": 0.3347,
      "step": 1590
    },
    {
      "epoch": 0.38004750593824227,
      "grad_norm": 2.0666439533233643,
      "learning_rate": 4.36658749010293e-05,
      "loss": 0.235,
      "step": 1600
    },
    {
      "epoch": 0.3824228028503563,
      "grad_norm": 0.8317428827285767,
      "learning_rate": 4.362628661916073e-05,
      "loss": 0.3424,
      "step": 1610
    },
    {
      "epoch": 0.3847980997624703,
      "grad_norm": 5.360532760620117,
      "learning_rate": 4.358669833729217e-05,
      "loss": 0.2549,
      "step": 1620
    },
    {
      "epoch": 0.38717339667458434,
      "grad_norm": 3.2089245319366455,
      "learning_rate": 4.35471100554236e-05,
      "loss": 0.3263,
      "step": 1630
    },
    {
      "epoch": 0.38954869358669836,
      "grad_norm": 2.982063055038452,
      "learning_rate": 4.3507521773555035e-05,
      "loss": 0.2857,
      "step": 1640
    },
    {
      "epoch": 0.3919239904988123,
      "grad_norm": 3.1527254581451416,
      "learning_rate": 4.3467933491686466e-05,
      "loss": 0.3672,
      "step": 1650
    },
    {
      "epoch": 0.39429928741092635,
      "grad_norm": 1.1030875444412231,
      "learning_rate": 4.3428345209817896e-05,
      "loss": 0.2917,
      "step": 1660
    },
    {
      "epoch": 0.39667458432304037,
      "grad_norm": 3.761397123336792,
      "learning_rate": 4.3388756927949334e-05,
      "loss": 0.3046,
      "step": 1670
    },
    {
      "epoch": 0.3990498812351544,
      "grad_norm": 2.057110071182251,
      "learning_rate": 4.3349168646080765e-05,
      "loss": 0.2569,
      "step": 1680
    },
    {
      "epoch": 0.4014251781472684,
      "grad_norm": 4.349730014801025,
      "learning_rate": 4.3309580364212195e-05,
      "loss": 0.245,
      "step": 1690
    },
    {
      "epoch": 0.40380047505938244,
      "grad_norm": 3.422415256500244,
      "learning_rate": 4.326999208234363e-05,
      "loss": 0.2249,
      "step": 1700
    },
    {
      "epoch": 0.40617577197149646,
      "grad_norm": 1.0804188251495361,
      "learning_rate": 4.323040380047506e-05,
      "loss": 0.1819,
      "step": 1710
    },
    {
      "epoch": 0.4085510688836104,
      "grad_norm": 8.49078369140625,
      "learning_rate": 4.3190815518606494e-05,
      "loss": 0.3136,
      "step": 1720
    },
    {
      "epoch": 0.41092636579572445,
      "grad_norm": 1.870681881904602,
      "learning_rate": 4.315122723673793e-05,
      "loss": 0.3665,
      "step": 1730
    },
    {
      "epoch": 0.41330166270783847,
      "grad_norm": 5.508764743804932,
      "learning_rate": 4.311163895486936e-05,
      "loss": 0.2908,
      "step": 1740
    },
    {
      "epoch": 0.4156769596199525,
      "grad_norm": 6.257874488830566,
      "learning_rate": 4.307205067300079e-05,
      "loss": 0.298,
      "step": 1750
    },
    {
      "epoch": 0.4180522565320665,
      "grad_norm": 2.226869821548462,
      "learning_rate": 4.303246239113223e-05,
      "loss": 0.3507,
      "step": 1760
    },
    {
      "epoch": 0.42042755344418054,
      "grad_norm": 1.3604352474212646,
      "learning_rate": 4.299287410926366e-05,
      "loss": 0.2673,
      "step": 1770
    },
    {
      "epoch": 0.42280285035629456,
      "grad_norm": 5.932120323181152,
      "learning_rate": 4.29532858273951e-05,
      "loss": 0.2074,
      "step": 1780
    },
    {
      "epoch": 0.4251781472684085,
      "grad_norm": 4.56141996383667,
      "learning_rate": 4.291369754552653e-05,
      "loss": 0.2837,
      "step": 1790
    },
    {
      "epoch": 0.42755344418052255,
      "grad_norm": 4.66403865814209,
      "learning_rate": 4.287410926365796e-05,
      "loss": 0.3268,
      "step": 1800
    },
    {
      "epoch": 0.42992874109263657,
      "grad_norm": 2.2722327709198,
      "learning_rate": 4.28345209817894e-05,
      "loss": 0.3287,
      "step": 1810
    },
    {
      "epoch": 0.4323040380047506,
      "grad_norm": 5.6882524490356445,
      "learning_rate": 4.279493269992083e-05,
      "loss": 0.2505,
      "step": 1820
    },
    {
      "epoch": 0.4346793349168646,
      "grad_norm": 2.5424811840057373,
      "learning_rate": 4.275534441805226e-05,
      "loss": 0.2878,
      "step": 1830
    },
    {
      "epoch": 0.43705463182897863,
      "grad_norm": 4.40482234954834,
      "learning_rate": 4.2715756136183696e-05,
      "loss": 0.3086,
      "step": 1840
    },
    {
      "epoch": 0.43942992874109266,
      "grad_norm": 4.272251605987549,
      "learning_rate": 4.2676167854315126e-05,
      "loss": 0.2799,
      "step": 1850
    },
    {
      "epoch": 0.4418052256532066,
      "grad_norm": 0.7674789428710938,
      "learning_rate": 4.263657957244656e-05,
      "loss": 0.28,
      "step": 1860
    },
    {
      "epoch": 0.44418052256532065,
      "grad_norm": 5.211869239807129,
      "learning_rate": 4.2596991290577994e-05,
      "loss": 0.2502,
      "step": 1870
    },
    {
      "epoch": 0.44655581947743467,
      "grad_norm": 4.196356296539307,
      "learning_rate": 4.2557403008709425e-05,
      "loss": 0.2307,
      "step": 1880
    },
    {
      "epoch": 0.4489311163895487,
      "grad_norm": 3.1637983322143555,
      "learning_rate": 4.2517814726840856e-05,
      "loss": 0.4536,
      "step": 1890
    },
    {
      "epoch": 0.4513064133016627,
      "grad_norm": 2.896940231323242,
      "learning_rate": 4.247822644497229e-05,
      "loss": 0.2962,
      "step": 1900
    },
    {
      "epoch": 0.45368171021377673,
      "grad_norm": 2.481635332107544,
      "learning_rate": 4.2438638163103724e-05,
      "loss": 0.3009,
      "step": 1910
    },
    {
      "epoch": 0.45605700712589076,
      "grad_norm": 3.911674737930298,
      "learning_rate": 4.239904988123516e-05,
      "loss": 0.2658,
      "step": 1920
    },
    {
      "epoch": 0.4584323040380047,
      "grad_norm": 2.716381549835205,
      "learning_rate": 4.235946159936659e-05,
      "loss": 0.3295,
      "step": 1930
    },
    {
      "epoch": 0.46080760095011875,
      "grad_norm": 8.2633695602417,
      "learning_rate": 4.231987331749802e-05,
      "loss": 0.3439,
      "step": 1940
    },
    {
      "epoch": 0.46318289786223277,
      "grad_norm": 5.841331481933594,
      "learning_rate": 4.228028503562946e-05,
      "loss": 0.2386,
      "step": 1950
    },
    {
      "epoch": 0.4655581947743468,
      "grad_norm": 6.851850509643555,
      "learning_rate": 4.224069675376089e-05,
      "loss": 0.2888,
      "step": 1960
    },
    {
      "epoch": 0.4679334916864608,
      "grad_norm": 1.1782606840133667,
      "learning_rate": 4.220110847189232e-05,
      "loss": 0.2691,
      "step": 1970
    },
    {
      "epoch": 0.47030878859857483,
      "grad_norm": 3.184253215789795,
      "learning_rate": 4.216152019002376e-05,
      "loss": 0.2884,
      "step": 1980
    },
    {
      "epoch": 0.47268408551068886,
      "grad_norm": 4.463771343231201,
      "learning_rate": 4.212193190815519e-05,
      "loss": 0.3074,
      "step": 1990
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 4.468111991882324,
      "learning_rate": 4.208234362628662e-05,
      "loss": 0.2904,
      "step": 2000
    },
    {
      "epoch": 0.47743467933491684,
      "grad_norm": 3.443540334701538,
      "learning_rate": 4.204275534441806e-05,
      "loss": 0.3108,
      "step": 2010
    },
    {
      "epoch": 0.47980997624703087,
      "grad_norm": 3.928481101989746,
      "learning_rate": 4.200316706254949e-05,
      "loss": 0.4079,
      "step": 2020
    },
    {
      "epoch": 0.4821852731591449,
      "grad_norm": 6.360701560974121,
      "learning_rate": 4.196357878068092e-05,
      "loss": 0.3637,
      "step": 2030
    },
    {
      "epoch": 0.4845605700712589,
      "grad_norm": 1.6439045667648315,
      "learning_rate": 4.1923990498812356e-05,
      "loss": 0.3058,
      "step": 2040
    },
    {
      "epoch": 0.48693586698337293,
      "grad_norm": 1.7497013807296753,
      "learning_rate": 4.1884402216943787e-05,
      "loss": 0.341,
      "step": 2050
    },
    {
      "epoch": 0.48931116389548696,
      "grad_norm": 3.040517807006836,
      "learning_rate": 4.1844813935075224e-05,
      "loss": 0.2698,
      "step": 2060
    },
    {
      "epoch": 0.4916864608076009,
      "grad_norm": 1.6658546924591064,
      "learning_rate": 4.1805225653206655e-05,
      "loss": 0.2299,
      "step": 2070
    },
    {
      "epoch": 0.49406175771971494,
      "grad_norm": 2.8386142253875732,
      "learning_rate": 4.1765637371338085e-05,
      "loss": 0.334,
      "step": 2080
    },
    {
      "epoch": 0.49643705463182897,
      "grad_norm": 0.895543098449707,
      "learning_rate": 4.172604908946952e-05,
      "loss": 0.2291,
      "step": 2090
    },
    {
      "epoch": 0.498812351543943,
      "grad_norm": 4.175216197967529,
      "learning_rate": 4.168646080760095e-05,
      "loss": 0.345,
      "step": 2100
    },
    {
      "epoch": 0.501187648456057,
      "grad_norm": 5.521766185760498,
      "learning_rate": 4.1646872525732384e-05,
      "loss": 0.3477,
      "step": 2110
    },
    {
      "epoch": 0.503562945368171,
      "grad_norm": 1.487247109413147,
      "learning_rate": 4.160728424386382e-05,
      "loss": 0.2169,
      "step": 2120
    },
    {
      "epoch": 0.505938242280285,
      "grad_norm": 3.2412960529327393,
      "learning_rate": 4.156769596199525e-05,
      "loss": 0.2609,
      "step": 2130
    },
    {
      "epoch": 0.5083135391923991,
      "grad_norm": 6.470788478851318,
      "learning_rate": 4.152810768012668e-05,
      "loss": 0.308,
      "step": 2140
    },
    {
      "epoch": 0.5106888361045131,
      "grad_norm": 4.284290790557861,
      "learning_rate": 4.148851939825812e-05,
      "loss": 0.2072,
      "step": 2150
    },
    {
      "epoch": 0.5130641330166271,
      "grad_norm": 6.265307903289795,
      "learning_rate": 4.144893111638955e-05,
      "loss": 0.3613,
      "step": 2160
    },
    {
      "epoch": 0.5154394299287411,
      "grad_norm": 3.322880983352661,
      "learning_rate": 4.140934283452098e-05,
      "loss": 0.2573,
      "step": 2170
    },
    {
      "epoch": 0.517814726840855,
      "grad_norm": 0.7035495042800903,
      "learning_rate": 4.136975455265242e-05,
      "loss": 0.3021,
      "step": 2180
    },
    {
      "epoch": 0.5201900237529691,
      "grad_norm": 1.5585628747940063,
      "learning_rate": 4.133016627078385e-05,
      "loss": 0.3032,
      "step": 2190
    },
    {
      "epoch": 0.5225653206650831,
      "grad_norm": 2.7460052967071533,
      "learning_rate": 4.129057798891529e-05,
      "loss": 0.2976,
      "step": 2200
    },
    {
      "epoch": 0.5249406175771971,
      "grad_norm": 3.35516357421875,
      "learning_rate": 4.125098970704672e-05,
      "loss": 0.3331,
      "step": 2210
    },
    {
      "epoch": 0.5273159144893111,
      "grad_norm": 2.2085697650909424,
      "learning_rate": 4.121140142517815e-05,
      "loss": 0.2153,
      "step": 2220
    },
    {
      "epoch": 0.5296912114014252,
      "grad_norm": 2.4279987812042236,
      "learning_rate": 4.1171813143309586e-05,
      "loss": 0.2599,
      "step": 2230
    },
    {
      "epoch": 0.5320665083135392,
      "grad_norm": 2.9075980186462402,
      "learning_rate": 4.1132224861441016e-05,
      "loss": 0.2305,
      "step": 2240
    },
    {
      "epoch": 0.5344418052256532,
      "grad_norm": 3.604077100753784,
      "learning_rate": 4.109263657957245e-05,
      "loss": 0.1812,
      "step": 2250
    },
    {
      "epoch": 0.5368171021377672,
      "grad_norm": 4.215694427490234,
      "learning_rate": 4.1053048297703884e-05,
      "loss": 0.2431,
      "step": 2260
    },
    {
      "epoch": 0.5391923990498813,
      "grad_norm": 4.937476634979248,
      "learning_rate": 4.1013460015835315e-05,
      "loss": 0.2204,
      "step": 2270
    },
    {
      "epoch": 0.5415676959619953,
      "grad_norm": 8.234173774719238,
      "learning_rate": 4.0973871733966746e-05,
      "loss": 0.3533,
      "step": 2280
    },
    {
      "epoch": 0.5439429928741093,
      "grad_norm": 1.7764869928359985,
      "learning_rate": 4.093428345209818e-05,
      "loss": 0.2343,
      "step": 2290
    },
    {
      "epoch": 0.5463182897862233,
      "grad_norm": 4.835221767425537,
      "learning_rate": 4.0894695170229614e-05,
      "loss": 0.2408,
      "step": 2300
    },
    {
      "epoch": 0.5486935866983373,
      "grad_norm": 3.169559955596924,
      "learning_rate": 4.0855106888361044e-05,
      "loss": 0.2289,
      "step": 2310
    },
    {
      "epoch": 0.5510688836104513,
      "grad_norm": 2.503525972366333,
      "learning_rate": 4.081551860649248e-05,
      "loss": 0.3034,
      "step": 2320
    },
    {
      "epoch": 0.5534441805225653,
      "grad_norm": 2.900887966156006,
      "learning_rate": 4.077593032462391e-05,
      "loss": 0.2933,
      "step": 2330
    },
    {
      "epoch": 0.5558194774346793,
      "grad_norm": 2.6902365684509277,
      "learning_rate": 4.073634204275535e-05,
      "loss": 0.1792,
      "step": 2340
    },
    {
      "epoch": 0.5581947743467933,
      "grad_norm": 1.8465964794158936,
      "learning_rate": 4.069675376088678e-05,
      "loss": 0.369,
      "step": 2350
    },
    {
      "epoch": 0.5605700712589073,
      "grad_norm": 2.9238853454589844,
      "learning_rate": 4.065716547901821e-05,
      "loss": 0.1986,
      "step": 2360
    },
    {
      "epoch": 0.5629453681710214,
      "grad_norm": 5.297476768493652,
      "learning_rate": 4.061757719714965e-05,
      "loss": 0.2251,
      "step": 2370
    },
    {
      "epoch": 0.5653206650831354,
      "grad_norm": 3.738619804382324,
      "learning_rate": 4.057798891528108e-05,
      "loss": 0.1926,
      "step": 2380
    },
    {
      "epoch": 0.5676959619952494,
      "grad_norm": 4.234147548675537,
      "learning_rate": 4.053840063341251e-05,
      "loss": 0.2958,
      "step": 2390
    },
    {
      "epoch": 0.5700712589073634,
      "grad_norm": 4.113717079162598,
      "learning_rate": 4.049881235154395e-05,
      "loss": 0.2603,
      "step": 2400
    },
    {
      "epoch": 0.5724465558194775,
      "grad_norm": 2.143848419189453,
      "learning_rate": 4.045922406967538e-05,
      "loss": 0.201,
      "step": 2410
    },
    {
      "epoch": 0.5748218527315915,
      "grad_norm": 1.2052828073501587,
      "learning_rate": 4.041963578780681e-05,
      "loss": 0.3599,
      "step": 2420
    },
    {
      "epoch": 0.5771971496437055,
      "grad_norm": 3.514299154281616,
      "learning_rate": 4.0380047505938246e-05,
      "loss": 0.2503,
      "step": 2430
    },
    {
      "epoch": 0.5795724465558195,
      "grad_norm": 15.576227188110352,
      "learning_rate": 4.034045922406968e-05,
      "loss": 0.3395,
      "step": 2440
    },
    {
      "epoch": 0.5819477434679335,
      "grad_norm": 1.6916155815124512,
      "learning_rate": 4.030087094220111e-05,
      "loss": 0.2581,
      "step": 2450
    },
    {
      "epoch": 0.5843230403800475,
      "grad_norm": 2.8708066940307617,
      "learning_rate": 4.0261282660332545e-05,
      "loss": 0.3226,
      "step": 2460
    },
    {
      "epoch": 0.5866983372921615,
      "grad_norm": 0.9602584838867188,
      "learning_rate": 4.0221694378463975e-05,
      "loss": 0.2462,
      "step": 2470
    },
    {
      "epoch": 0.5890736342042755,
      "grad_norm": 3.721339464187622,
      "learning_rate": 4.018210609659541e-05,
      "loss": 0.2868,
      "step": 2480
    },
    {
      "epoch": 0.5914489311163895,
      "grad_norm": 2.03108549118042,
      "learning_rate": 4.0142517814726843e-05,
      "loss": 0.1932,
      "step": 2490
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 2.800994396209717,
      "learning_rate": 4.0102929532858274e-05,
      "loss": 0.2967,
      "step": 2500
    },
    {
      "epoch": 0.5961995249406176,
      "grad_norm": 2.4332761764526367,
      "learning_rate": 4.006334125098971e-05,
      "loss": 0.2376,
      "step": 2510
    },
    {
      "epoch": 0.5985748218527316,
      "grad_norm": 6.23856258392334,
      "learning_rate": 4.002375296912114e-05,
      "loss": 0.2403,
      "step": 2520
    },
    {
      "epoch": 0.6009501187648456,
      "grad_norm": 3.0966365337371826,
      "learning_rate": 3.998416468725257e-05,
      "loss": 0.298,
      "step": 2530
    },
    {
      "epoch": 0.6033254156769596,
      "grad_norm": 3.4524216651916504,
      "learning_rate": 3.994457640538401e-05,
      "loss": 0.3089,
      "step": 2540
    },
    {
      "epoch": 0.6057007125890737,
      "grad_norm": 3.7064664363861084,
      "learning_rate": 3.990498812351544e-05,
      "loss": 0.3127,
      "step": 2550
    },
    {
      "epoch": 0.6080760095011877,
      "grad_norm": 3.2101340293884277,
      "learning_rate": 3.986539984164687e-05,
      "loss": 0.4055,
      "step": 2560
    },
    {
      "epoch": 0.6104513064133017,
      "grad_norm": 2.419114112854004,
      "learning_rate": 3.982581155977831e-05,
      "loss": 0.2384,
      "step": 2570
    },
    {
      "epoch": 0.6128266033254157,
      "grad_norm": 3.8857288360595703,
      "learning_rate": 3.978622327790974e-05,
      "loss": 0.2649,
      "step": 2580
    },
    {
      "epoch": 0.6152019002375297,
      "grad_norm": 2.1785006523132324,
      "learning_rate": 3.974663499604117e-05,
      "loss": 0.3369,
      "step": 2590
    },
    {
      "epoch": 0.6175771971496437,
      "grad_norm": 3.2080750465393066,
      "learning_rate": 3.970704671417261e-05,
      "loss": 0.2328,
      "step": 2600
    },
    {
      "epoch": 0.6199524940617577,
      "grad_norm": 3.374831199645996,
      "learning_rate": 3.966745843230404e-05,
      "loss": 0.2898,
      "step": 2610
    },
    {
      "epoch": 0.6223277909738717,
      "grad_norm": 1.4965949058532715,
      "learning_rate": 3.9627870150435476e-05,
      "loss": 0.3181,
      "step": 2620
    },
    {
      "epoch": 0.6247030878859857,
      "grad_norm": 3.365359306335449,
      "learning_rate": 3.9588281868566906e-05,
      "loss": 0.3865,
      "step": 2630
    },
    {
      "epoch": 0.6270783847980997,
      "grad_norm": 4.226669788360596,
      "learning_rate": 3.954869358669834e-05,
      "loss": 0.294,
      "step": 2640
    },
    {
      "epoch": 0.6294536817102138,
      "grad_norm": 2.031865119934082,
      "learning_rate": 3.9509105304829774e-05,
      "loss": 0.2815,
      "step": 2650
    },
    {
      "epoch": 0.6318289786223278,
      "grad_norm": 3.288355827331543,
      "learning_rate": 3.9469517022961205e-05,
      "loss": 0.2864,
      "step": 2660
    },
    {
      "epoch": 0.6342042755344418,
      "grad_norm": 3.082977294921875,
      "learning_rate": 3.9429928741092636e-05,
      "loss": 0.2672,
      "step": 2670
    },
    {
      "epoch": 0.6365795724465558,
      "grad_norm": 4.099735260009766,
      "learning_rate": 3.939034045922407e-05,
      "loss": 0.234,
      "step": 2680
    },
    {
      "epoch": 0.6389548693586699,
      "grad_norm": 6.202897548675537,
      "learning_rate": 3.9350752177355504e-05,
      "loss": 0.2536,
      "step": 2690
    },
    {
      "epoch": 0.6413301662707839,
      "grad_norm": 2.9458022117614746,
      "learning_rate": 3.9311163895486934e-05,
      "loss": 0.2439,
      "step": 2700
    },
    {
      "epoch": 0.6437054631828979,
      "grad_norm": 1.5490047931671143,
      "learning_rate": 3.927157561361837e-05,
      "loss": 0.3435,
      "step": 2710
    },
    {
      "epoch": 0.6460807600950119,
      "grad_norm": 5.354594707489014,
      "learning_rate": 3.92319873317498e-05,
      "loss": 0.4731,
      "step": 2720
    },
    {
      "epoch": 0.6484560570071259,
      "grad_norm": 1.7656323909759521,
      "learning_rate": 3.919239904988123e-05,
      "loss": 0.2436,
      "step": 2730
    },
    {
      "epoch": 0.6508313539192399,
      "grad_norm": 1.2266463041305542,
      "learning_rate": 3.915281076801267e-05,
      "loss": 0.2128,
      "step": 2740
    },
    {
      "epoch": 0.6532066508313539,
      "grad_norm": 4.167529106140137,
      "learning_rate": 3.91132224861441e-05,
      "loss": 0.303,
      "step": 2750
    },
    {
      "epoch": 0.6555819477434679,
      "grad_norm": 4.594629764556885,
      "learning_rate": 3.907363420427554e-05,
      "loss": 0.325,
      "step": 2760
    },
    {
      "epoch": 0.6579572446555819,
      "grad_norm": 6.753587245941162,
      "learning_rate": 3.903404592240697e-05,
      "loss": 0.3266,
      "step": 2770
    },
    {
      "epoch": 0.6603325415676959,
      "grad_norm": 6.197601318359375,
      "learning_rate": 3.89944576405384e-05,
      "loss": 0.2356,
      "step": 2780
    },
    {
      "epoch": 0.66270783847981,
      "grad_norm": 3.913351535797119,
      "learning_rate": 3.895486935866984e-05,
      "loss": 0.2767,
      "step": 2790
    },
    {
      "epoch": 0.665083135391924,
      "grad_norm": 3.326707363128662,
      "learning_rate": 3.891528107680127e-05,
      "loss": 0.2421,
      "step": 2800
    },
    {
      "epoch": 0.667458432304038,
      "grad_norm": 3.7766220569610596,
      "learning_rate": 3.88756927949327e-05,
      "loss": 0.2297,
      "step": 2810
    },
    {
      "epoch": 0.669833729216152,
      "grad_norm": 2.0354814529418945,
      "learning_rate": 3.8836104513064136e-05,
      "loss": 0.2926,
      "step": 2820
    },
    {
      "epoch": 0.672209026128266,
      "grad_norm": 2.2542803287506104,
      "learning_rate": 3.879651623119557e-05,
      "loss": 0.2927,
      "step": 2830
    },
    {
      "epoch": 0.6745843230403801,
      "grad_norm": 5.62080717086792,
      "learning_rate": 3.8756927949327e-05,
      "loss": 0.4104,
      "step": 2840
    },
    {
      "epoch": 0.6769596199524941,
      "grad_norm": 2.083305835723877,
      "learning_rate": 3.8717339667458435e-05,
      "loss": 0.2874,
      "step": 2850
    },
    {
      "epoch": 0.6793349168646081,
      "grad_norm": 4.066093921661377,
      "learning_rate": 3.8677751385589865e-05,
      "loss": 0.3173,
      "step": 2860
    },
    {
      "epoch": 0.6817102137767221,
      "grad_norm": 3.7250232696533203,
      "learning_rate": 3.8638163103721296e-05,
      "loss": 0.2894,
      "step": 2870
    },
    {
      "epoch": 0.684085510688836,
      "grad_norm": 2.0194921493530273,
      "learning_rate": 3.8598574821852734e-05,
      "loss": 0.2783,
      "step": 2880
    },
    {
      "epoch": 0.6864608076009501,
      "grad_norm": 1.9576935768127441,
      "learning_rate": 3.8558986539984164e-05,
      "loss": 0.3294,
      "step": 2890
    },
    {
      "epoch": 0.6888361045130641,
      "grad_norm": 3.2114481925964355,
      "learning_rate": 3.85193982581156e-05,
      "loss": 0.1938,
      "step": 2900
    },
    {
      "epoch": 0.6912114014251781,
      "grad_norm": 3.7990405559539795,
      "learning_rate": 3.847980997624703e-05,
      "loss": 0.3024,
      "step": 2910
    },
    {
      "epoch": 0.6935866983372921,
      "grad_norm": 2.3084769248962402,
      "learning_rate": 3.844022169437846e-05,
      "loss": 0.3233,
      "step": 2920
    },
    {
      "epoch": 0.6959619952494062,
      "grad_norm": 1.1630833148956299,
      "learning_rate": 3.84006334125099e-05,
      "loss": 0.3248,
      "step": 2930
    },
    {
      "epoch": 0.6983372921615202,
      "grad_norm": 3.0807127952575684,
      "learning_rate": 3.836104513064133e-05,
      "loss": 0.2906,
      "step": 2940
    },
    {
      "epoch": 0.7007125890736342,
      "grad_norm": 4.948851108551025,
      "learning_rate": 3.832145684877276e-05,
      "loss": 0.2241,
      "step": 2950
    },
    {
      "epoch": 0.7030878859857482,
      "grad_norm": 6.232032775878906,
      "learning_rate": 3.82818685669042e-05,
      "loss": 0.2856,
      "step": 2960
    },
    {
      "epoch": 0.7054631828978623,
      "grad_norm": 4.165072441101074,
      "learning_rate": 3.824228028503563e-05,
      "loss": 0.3148,
      "step": 2970
    },
    {
      "epoch": 0.7078384798099763,
      "grad_norm": 2.2644898891448975,
      "learning_rate": 3.820269200316706e-05,
      "loss": 0.2123,
      "step": 2980
    },
    {
      "epoch": 0.7102137767220903,
      "grad_norm": 2.1224818229675293,
      "learning_rate": 3.81631037212985e-05,
      "loss": 0.3472,
      "step": 2990
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 2.3067140579223633,
      "learning_rate": 3.812351543942993e-05,
      "loss": 0.2291,
      "step": 3000
    },
    {
      "epoch": 0.7149643705463183,
      "grad_norm": 2.658961534500122,
      "learning_rate": 3.808392715756136e-05,
      "loss": 0.3086,
      "step": 3010
    },
    {
      "epoch": 0.7173396674584323,
      "grad_norm": 2.987653970718384,
      "learning_rate": 3.8044338875692797e-05,
      "loss": 0.278,
      "step": 3020
    },
    {
      "epoch": 0.7197149643705463,
      "grad_norm": 3.3768179416656494,
      "learning_rate": 3.800475059382423e-05,
      "loss": 0.2426,
      "step": 3030
    },
    {
      "epoch": 0.7220902612826603,
      "grad_norm": 6.853292465209961,
      "learning_rate": 3.7965162311955665e-05,
      "loss": 0.3273,
      "step": 3040
    },
    {
      "epoch": 0.7244655581947743,
      "grad_norm": 7.445337772369385,
      "learning_rate": 3.7925574030087095e-05,
      "loss": 0.4141,
      "step": 3050
    },
    {
      "epoch": 0.7268408551068883,
      "grad_norm": 1.5207802057266235,
      "learning_rate": 3.7885985748218526e-05,
      "loss": 0.2943,
      "step": 3060
    },
    {
      "epoch": 0.7292161520190024,
      "grad_norm": 3.8929221630096436,
      "learning_rate": 3.784639746634996e-05,
      "loss": 0.2653,
      "step": 3070
    },
    {
      "epoch": 0.7315914489311164,
      "grad_norm": 1.7479041814804077,
      "learning_rate": 3.7806809184481394e-05,
      "loss": 0.3131,
      "step": 3080
    },
    {
      "epoch": 0.7339667458432304,
      "grad_norm": 4.9283294677734375,
      "learning_rate": 3.7767220902612825e-05,
      "loss": 0.3352,
      "step": 3090
    },
    {
      "epoch": 0.7363420427553444,
      "grad_norm": 5.755313396453857,
      "learning_rate": 3.772763262074426e-05,
      "loss": 0.2619,
      "step": 3100
    },
    {
      "epoch": 0.7387173396674585,
      "grad_norm": 3.0468482971191406,
      "learning_rate": 3.768804433887569e-05,
      "loss": 0.3693,
      "step": 3110
    },
    {
      "epoch": 0.7410926365795725,
      "grad_norm": 3.5200870037078857,
      "learning_rate": 3.764845605700712e-05,
      "loss": 0.3046,
      "step": 3120
    },
    {
      "epoch": 0.7434679334916865,
      "grad_norm": 4.012732028961182,
      "learning_rate": 3.760886777513856e-05,
      "loss": 0.3306,
      "step": 3130
    },
    {
      "epoch": 0.7458432304038005,
      "grad_norm": 1.5031263828277588,
      "learning_rate": 3.756927949326999e-05,
      "loss": 0.2509,
      "step": 3140
    },
    {
      "epoch": 0.7482185273159145,
      "grad_norm": 2.927400588989258,
      "learning_rate": 3.752969121140142e-05,
      "loss": 0.321,
      "step": 3150
    },
    {
      "epoch": 0.7505938242280285,
      "grad_norm": 4.579587936401367,
      "learning_rate": 3.749010292953286e-05,
      "loss": 0.3906,
      "step": 3160
    },
    {
      "epoch": 0.7529691211401425,
      "grad_norm": 2.247955322265625,
      "learning_rate": 3.745051464766429e-05,
      "loss": 0.2436,
      "step": 3170
    },
    {
      "epoch": 0.7553444180522565,
      "grad_norm": 1.1799217462539673,
      "learning_rate": 3.741092636579573e-05,
      "loss": 0.3207,
      "step": 3180
    },
    {
      "epoch": 0.7577197149643705,
      "grad_norm": 2.3879787921905518,
      "learning_rate": 3.737133808392716e-05,
      "loss": 0.3224,
      "step": 3190
    },
    {
      "epoch": 0.7600950118764845,
      "grad_norm": 2.0414109230041504,
      "learning_rate": 3.733174980205859e-05,
      "loss": 0.3211,
      "step": 3200
    },
    {
      "epoch": 0.7624703087885986,
      "grad_norm": 0.8482092618942261,
      "learning_rate": 3.7292161520190026e-05,
      "loss": 0.2369,
      "step": 3210
    },
    {
      "epoch": 0.7648456057007126,
      "grad_norm": 4.594536304473877,
      "learning_rate": 3.725257323832146e-05,
      "loss": 0.2049,
      "step": 3220
    },
    {
      "epoch": 0.7672209026128266,
      "grad_norm": 3.6459431648254395,
      "learning_rate": 3.721298495645289e-05,
      "loss": 0.2573,
      "step": 3230
    },
    {
      "epoch": 0.7695961995249406,
      "grad_norm": 7.25452995300293,
      "learning_rate": 3.7173396674584325e-05,
      "loss": 0.272,
      "step": 3240
    },
    {
      "epoch": 0.7719714964370546,
      "grad_norm": 4.104382514953613,
      "learning_rate": 3.7133808392715756e-05,
      "loss": 0.2802,
      "step": 3250
    },
    {
      "epoch": 0.7743467933491687,
      "grad_norm": 2.4179375171661377,
      "learning_rate": 3.7094220110847186e-05,
      "loss": 0.2419,
      "step": 3260
    },
    {
      "epoch": 0.7767220902612827,
      "grad_norm": 3.0566837787628174,
      "learning_rate": 3.7054631828978624e-05,
      "loss": 0.324,
      "step": 3270
    },
    {
      "epoch": 0.7790973871733967,
      "grad_norm": 4.763742923736572,
      "learning_rate": 3.7015043547110054e-05,
      "loss": 0.226,
      "step": 3280
    },
    {
      "epoch": 0.7814726840855107,
      "grad_norm": 1.5642869472503662,
      "learning_rate": 3.6975455265241485e-05,
      "loss": 0.264,
      "step": 3290
    },
    {
      "epoch": 0.7838479809976246,
      "grad_norm": 6.078758716583252,
      "learning_rate": 3.693586698337292e-05,
      "loss": 0.2812,
      "step": 3300
    },
    {
      "epoch": 0.7862232779097387,
      "grad_norm": 4.553238868713379,
      "learning_rate": 3.689627870150435e-05,
      "loss": 0.2948,
      "step": 3310
    },
    {
      "epoch": 0.7885985748218527,
      "grad_norm": 2.3570594787597656,
      "learning_rate": 3.685669041963579e-05,
      "loss": 0.213,
      "step": 3320
    },
    {
      "epoch": 0.7909738717339667,
      "grad_norm": 1.8212382793426514,
      "learning_rate": 3.681710213776722e-05,
      "loss": 0.2424,
      "step": 3330
    },
    {
      "epoch": 0.7933491686460807,
      "grad_norm": 4.033612251281738,
      "learning_rate": 3.677751385589865e-05,
      "loss": 0.209,
      "step": 3340
    },
    {
      "epoch": 0.7957244655581948,
      "grad_norm": 9.392571449279785,
      "learning_rate": 3.673792557403009e-05,
      "loss": 0.3282,
      "step": 3350
    },
    {
      "epoch": 0.7980997624703088,
      "grad_norm": 4.699637413024902,
      "learning_rate": 3.669833729216152e-05,
      "loss": 0.1964,
      "step": 3360
    },
    {
      "epoch": 0.8004750593824228,
      "grad_norm": 2.323463201522827,
      "learning_rate": 3.665874901029295e-05,
      "loss": 0.2063,
      "step": 3370
    },
    {
      "epoch": 0.8028503562945368,
      "grad_norm": 4.106771945953369,
      "learning_rate": 3.661916072842439e-05,
      "loss": 0.3939,
      "step": 3380
    },
    {
      "epoch": 0.8052256532066508,
      "grad_norm": 9.028138160705566,
      "learning_rate": 3.657957244655582e-05,
      "loss": 0.3609,
      "step": 3390
    },
    {
      "epoch": 0.8076009501187649,
      "grad_norm": 4.925477981567383,
      "learning_rate": 3.653998416468725e-05,
      "loss": 0.3269,
      "step": 3400
    },
    {
      "epoch": 0.8099762470308789,
      "grad_norm": 3.305384397506714,
      "learning_rate": 3.650039588281869e-05,
      "loss": 0.2973,
      "step": 3410
    },
    {
      "epoch": 0.8123515439429929,
      "grad_norm": 4.618465900421143,
      "learning_rate": 3.646080760095012e-05,
      "loss": 0.2702,
      "step": 3420
    },
    {
      "epoch": 0.8147268408551069,
      "grad_norm": 4.889001846313477,
      "learning_rate": 3.642121931908155e-05,
      "loss": 0.3175,
      "step": 3430
    },
    {
      "epoch": 0.8171021377672208,
      "grad_norm": 2.2261972427368164,
      "learning_rate": 3.6381631037212985e-05,
      "loss": 0.2766,
      "step": 3440
    },
    {
      "epoch": 0.8194774346793349,
      "grad_norm": 3.674713373184204,
      "learning_rate": 3.6342042755344416e-05,
      "loss": 0.3379,
      "step": 3450
    },
    {
      "epoch": 0.8218527315914489,
      "grad_norm": 7.818405628204346,
      "learning_rate": 3.6302454473475853e-05,
      "loss": 0.2756,
      "step": 3460
    },
    {
      "epoch": 0.8242280285035629,
      "grad_norm": 5.440181255340576,
      "learning_rate": 3.6262866191607284e-05,
      "loss": 0.3547,
      "step": 3470
    },
    {
      "epoch": 0.8266033254156769,
      "grad_norm": 3.625793695449829,
      "learning_rate": 3.6223277909738715e-05,
      "loss": 0.2615,
      "step": 3480
    },
    {
      "epoch": 0.828978622327791,
      "grad_norm": 2.3035945892333984,
      "learning_rate": 3.618368962787015e-05,
      "loss": 0.2127,
      "step": 3490
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 3.712932586669922,
      "learning_rate": 3.614410134600158e-05,
      "loss": 0.2316,
      "step": 3500
    },
    {
      "epoch": 0.833729216152019,
      "grad_norm": 3.479130506515503,
      "learning_rate": 3.6104513064133013e-05,
      "loss": 0.2561,
      "step": 3510
    },
    {
      "epoch": 0.836104513064133,
      "grad_norm": 5.353648662567139,
      "learning_rate": 3.606492478226445e-05,
      "loss": 0.3916,
      "step": 3520
    },
    {
      "epoch": 0.838479809976247,
      "grad_norm": 6.944727420806885,
      "learning_rate": 3.602533650039588e-05,
      "loss": 0.2513,
      "step": 3530
    },
    {
      "epoch": 0.8408551068883611,
      "grad_norm": 6.172438144683838,
      "learning_rate": 3.598574821852731e-05,
      "loss": 0.3671,
      "step": 3540
    },
    {
      "epoch": 0.8432304038004751,
      "grad_norm": 4.440491676330566,
      "learning_rate": 3.594615993665875e-05,
      "loss": 0.2249,
      "step": 3550
    },
    {
      "epoch": 0.8456057007125891,
      "grad_norm": 4.402902603149414,
      "learning_rate": 3.590657165479018e-05,
      "loss": 0.3146,
      "step": 3560
    },
    {
      "epoch": 0.8479809976247031,
      "grad_norm": 3.9836461544036865,
      "learning_rate": 3.586698337292162e-05,
      "loss": 0.2944,
      "step": 3570
    },
    {
      "epoch": 0.850356294536817,
      "grad_norm": 2.115917205810547,
      "learning_rate": 3.582739509105305e-05,
      "loss": 0.2001,
      "step": 3580
    },
    {
      "epoch": 0.8527315914489311,
      "grad_norm": 2.497608184814453,
      "learning_rate": 3.578780680918448e-05,
      "loss": 0.2187,
      "step": 3590
    },
    {
      "epoch": 0.8551068883610451,
      "grad_norm": 3.00380277633667,
      "learning_rate": 3.5748218527315916e-05,
      "loss": 0.3775,
      "step": 3600
    },
    {
      "epoch": 0.8574821852731591,
      "grad_norm": 1.4601664543151855,
      "learning_rate": 3.570863024544735e-05,
      "loss": 0.3876,
      "step": 3610
    },
    {
      "epoch": 0.8598574821852731,
      "grad_norm": 1.9190014600753784,
      "learning_rate": 3.566904196357878e-05,
      "loss": 0.2958,
      "step": 3620
    },
    {
      "epoch": 0.8622327790973872,
      "grad_norm": 2.856644868850708,
      "learning_rate": 3.5629453681710215e-05,
      "loss": 0.2448,
      "step": 3630
    },
    {
      "epoch": 0.8646080760095012,
      "grad_norm": 6.216080665588379,
      "learning_rate": 3.5589865399841646e-05,
      "loss": 0.2565,
      "step": 3640
    },
    {
      "epoch": 0.8669833729216152,
      "grad_norm": 2.975482702255249,
      "learning_rate": 3.555027711797308e-05,
      "loss": 0.1588,
      "step": 3650
    },
    {
      "epoch": 0.8693586698337292,
      "grad_norm": 6.1334004402160645,
      "learning_rate": 3.5510688836104514e-05,
      "loss": 0.3028,
      "step": 3660
    },
    {
      "epoch": 0.8717339667458432,
      "grad_norm": 7.9876389503479,
      "learning_rate": 3.5471100554235944e-05,
      "loss": 0.1926,
      "step": 3670
    },
    {
      "epoch": 0.8741092636579573,
      "grad_norm": 3.666408061981201,
      "learning_rate": 3.543151227236738e-05,
      "loss": 0.3172,
      "step": 3680
    },
    {
      "epoch": 0.8764845605700713,
      "grad_norm": 4.453779697418213,
      "learning_rate": 3.539192399049881e-05,
      "loss": 0.2805,
      "step": 3690
    },
    {
      "epoch": 0.8788598574821853,
      "grad_norm": 1.2228847742080688,
      "learning_rate": 3.535233570863024e-05,
      "loss": 0.3002,
      "step": 3700
    },
    {
      "epoch": 0.8812351543942993,
      "grad_norm": 1.4763884544372559,
      "learning_rate": 3.531274742676168e-05,
      "loss": 0.3249,
      "step": 3710
    },
    {
      "epoch": 0.8836104513064132,
      "grad_norm": 4.505195140838623,
      "learning_rate": 3.527315914489311e-05,
      "loss": 0.3077,
      "step": 3720
    },
    {
      "epoch": 0.8859857482185273,
      "grad_norm": 6.133833885192871,
      "learning_rate": 3.523357086302455e-05,
      "loss": 0.2138,
      "step": 3730
    },
    {
      "epoch": 0.8883610451306413,
      "grad_norm": 2.652393341064453,
      "learning_rate": 3.519398258115598e-05,
      "loss": 0.2971,
      "step": 3740
    },
    {
      "epoch": 0.8907363420427553,
      "grad_norm": 6.1796040534973145,
      "learning_rate": 3.515439429928741e-05,
      "loss": 0.2524,
      "step": 3750
    },
    {
      "epoch": 0.8931116389548693,
      "grad_norm": 1.6154899597167969,
      "learning_rate": 3.511480601741885e-05,
      "loss": 0.2331,
      "step": 3760
    },
    {
      "epoch": 0.8954869358669834,
      "grad_norm": 3.9668495655059814,
      "learning_rate": 3.507521773555028e-05,
      "loss": 0.3323,
      "step": 3770
    },
    {
      "epoch": 0.8978622327790974,
      "grad_norm": 5.729796886444092,
      "learning_rate": 3.503562945368171e-05,
      "loss": 0.2671,
      "step": 3780
    },
    {
      "epoch": 0.9002375296912114,
      "grad_norm": 1.2669016122817993,
      "learning_rate": 3.4996041171813146e-05,
      "loss": 0.2193,
      "step": 3790
    },
    {
      "epoch": 0.9026128266033254,
      "grad_norm": 3.199336290359497,
      "learning_rate": 3.495645288994458e-05,
      "loss": 0.2629,
      "step": 3800
    },
    {
      "epoch": 0.9049881235154394,
      "grad_norm": 9.708815574645996,
      "learning_rate": 3.4916864608076014e-05,
      "loss": 0.2845,
      "step": 3810
    },
    {
      "epoch": 0.9073634204275535,
      "grad_norm": 3.0540390014648438,
      "learning_rate": 3.4877276326207445e-05,
      "loss": 0.249,
      "step": 3820
    },
    {
      "epoch": 0.9097387173396675,
      "grad_norm": 6.206895351409912,
      "learning_rate": 3.4837688044338875e-05,
      "loss": 0.2657,
      "step": 3830
    },
    {
      "epoch": 0.9121140142517815,
      "grad_norm": 4.052343368530273,
      "learning_rate": 3.479809976247031e-05,
      "loss": 0.2448,
      "step": 3840
    },
    {
      "epoch": 0.9144893111638955,
      "grad_norm": 6.615355014801025,
      "learning_rate": 3.4758511480601744e-05,
      "loss": 0.2202,
      "step": 3850
    },
    {
      "epoch": 0.9168646080760094,
      "grad_norm": 4.512532711029053,
      "learning_rate": 3.4718923198733174e-05,
      "loss": 0.3006,
      "step": 3860
    },
    {
      "epoch": 0.9192399049881235,
      "grad_norm": 4.553630828857422,
      "learning_rate": 3.467933491686461e-05,
      "loss": 0.2248,
      "step": 3870
    },
    {
      "epoch": 0.9216152019002375,
      "grad_norm": 3.448530673980713,
      "learning_rate": 3.463974663499604e-05,
      "loss": 0.3096,
      "step": 3880
    },
    {
      "epoch": 0.9239904988123515,
      "grad_norm": 3.5617711544036865,
      "learning_rate": 3.460015835312748e-05,
      "loss": 0.269,
      "step": 3890
    },
    {
      "epoch": 0.9263657957244655,
      "grad_norm": 1.747910737991333,
      "learning_rate": 3.456057007125891e-05,
      "loss": 0.1201,
      "step": 3900
    },
    {
      "epoch": 0.9287410926365796,
      "grad_norm": 6.799576759338379,
      "learning_rate": 3.452098178939034e-05,
      "loss": 0.2456,
      "step": 3910
    },
    {
      "epoch": 0.9311163895486936,
      "grad_norm": 3.5148556232452393,
      "learning_rate": 3.448139350752178e-05,
      "loss": 0.2504,
      "step": 3920
    },
    {
      "epoch": 0.9334916864608076,
      "grad_norm": 6.583720684051514,
      "learning_rate": 3.444180522565321e-05,
      "loss": 0.2368,
      "step": 3930
    },
    {
      "epoch": 0.9358669833729216,
      "grad_norm": 3.125171661376953,
      "learning_rate": 3.4402216943784646e-05,
      "loss": 0.2952,
      "step": 3940
    },
    {
      "epoch": 0.9382422802850356,
      "grad_norm": 4.03120231628418,
      "learning_rate": 3.436262866191608e-05,
      "loss": 0.2313,
      "step": 3950
    },
    {
      "epoch": 0.9406175771971497,
      "grad_norm": 4.029020309448242,
      "learning_rate": 3.432304038004751e-05,
      "loss": 0.2225,
      "step": 3960
    },
    {
      "epoch": 0.9429928741092637,
      "grad_norm": 2.525146722793579,
      "learning_rate": 3.4283452098178945e-05,
      "loss": 0.2891,
      "step": 3970
    },
    {
      "epoch": 0.9453681710213777,
      "grad_norm": 3.8918983936309814,
      "learning_rate": 3.4243863816310376e-05,
      "loss": 0.245,
      "step": 3980
    },
    {
      "epoch": 0.9477434679334917,
      "grad_norm": 6.345534801483154,
      "learning_rate": 3.4204275534441806e-05,
      "loss": 0.299,
      "step": 3990
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 3.180553913116455,
      "learning_rate": 3.4164687252573244e-05,
      "loss": 0.3568,
      "step": 4000
    },
    {
      "epoch": 0.9524940617577197,
      "grad_norm": 3.2571518421173096,
      "learning_rate": 3.4125098970704675e-05,
      "loss": 0.211,
      "step": 4010
    },
    {
      "epoch": 0.9548693586698337,
      "grad_norm": 2.8912787437438965,
      "learning_rate": 3.408551068883611e-05,
      "loss": 0.2724,
      "step": 4020
    },
    {
      "epoch": 0.9572446555819477,
      "grad_norm": 3.6365935802459717,
      "learning_rate": 3.404592240696754e-05,
      "loss": 0.2376,
      "step": 4030
    },
    {
      "epoch": 0.9596199524940617,
      "grad_norm": 2.1275691986083984,
      "learning_rate": 3.400633412509897e-05,
      "loss": 0.3341,
      "step": 4040
    },
    {
      "epoch": 0.9619952494061758,
      "grad_norm": 4.507723331451416,
      "learning_rate": 3.396674584323041e-05,
      "loss": 0.2613,
      "step": 4050
    },
    {
      "epoch": 0.9643705463182898,
      "grad_norm": 5.77063512802124,
      "learning_rate": 3.392715756136184e-05,
      "loss": 0.2727,
      "step": 4060
    },
    {
      "epoch": 0.9667458432304038,
      "grad_norm": 5.146459102630615,
      "learning_rate": 3.388756927949327e-05,
      "loss": 0.2863,
      "step": 4070
    },
    {
      "epoch": 0.9691211401425178,
      "grad_norm": 1.3422889709472656,
      "learning_rate": 3.384798099762471e-05,
      "loss": 0.2819,
      "step": 4080
    },
    {
      "epoch": 0.9714964370546318,
      "grad_norm": 4.1740336418151855,
      "learning_rate": 3.380839271575614e-05,
      "loss": 0.2516,
      "step": 4090
    },
    {
      "epoch": 0.9738717339667459,
      "grad_norm": 2.926675319671631,
      "learning_rate": 3.376880443388757e-05,
      "loss": 0.2303,
      "step": 4100
    },
    {
      "epoch": 0.9762470308788599,
      "grad_norm": 4.6421003341674805,
      "learning_rate": 3.372921615201901e-05,
      "loss": 0.2687,
      "step": 4110
    },
    {
      "epoch": 0.9786223277909739,
      "grad_norm": 3.300119638442993,
      "learning_rate": 3.368962787015044e-05,
      "loss": 0.3029,
      "step": 4120
    },
    {
      "epoch": 0.9809976247030879,
      "grad_norm": 11.574631690979004,
      "learning_rate": 3.365003958828187e-05,
      "loss": 0.2302,
      "step": 4130
    },
    {
      "epoch": 0.9833729216152018,
      "grad_norm": 4.662942886352539,
      "learning_rate": 3.361045130641331e-05,
      "loss": 0.3301,
      "step": 4140
    },
    {
      "epoch": 0.9857482185273159,
      "grad_norm": 2.2968175411224365,
      "learning_rate": 3.357086302454474e-05,
      "loss": 0.2437,
      "step": 4150
    },
    {
      "epoch": 0.9881235154394299,
      "grad_norm": 2.7515294551849365,
      "learning_rate": 3.3531274742676175e-05,
      "loss": 0.26,
      "step": 4160
    },
    {
      "epoch": 0.9904988123515439,
      "grad_norm": 3.5145692825317383,
      "learning_rate": 3.3491686460807606e-05,
      "loss": 0.2788,
      "step": 4170
    },
    {
      "epoch": 0.9928741092636579,
      "grad_norm": 2.7928812503814697,
      "learning_rate": 3.3452098178939036e-05,
      "loss": 0.209,
      "step": 4180
    },
    {
      "epoch": 0.995249406175772,
      "grad_norm": 5.137038230895996,
      "learning_rate": 3.3412509897070474e-05,
      "loss": 0.2882,
      "step": 4190
    },
    {
      "epoch": 0.997624703087886,
      "grad_norm": 3.078490734100342,
      "learning_rate": 3.3372921615201904e-05,
      "loss": 0.3787,
      "step": 4200
    },
    {
      "epoch": 1.0,
      "grad_norm": 11.389293670654297,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.3179,
      "step": 4210
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.284347265958786,
      "eval_runtime": 50.3636,
      "eval_samples_per_second": 17.314,
      "eval_steps_per_second": 1.092,
      "step": 4210
    },
    {
      "epoch": 1.002375296912114,
      "grad_norm": 3.3440232276916504,
      "learning_rate": 3.329374505146477e-05,
      "loss": 0.3088,
      "step": 4220
    },
    {
      "epoch": 1.004750593824228,
      "grad_norm": 1.588987112045288,
      "learning_rate": 3.32541567695962e-05,
      "loss": 0.2551,
      "step": 4230
    },
    {
      "epoch": 1.007125890736342,
      "grad_norm": 2.2819855213165283,
      "learning_rate": 3.3214568487727634e-05,
      "loss": 0.2792,
      "step": 4240
    },
    {
      "epoch": 1.009501187648456,
      "grad_norm": 3.1305887699127197,
      "learning_rate": 3.317498020585907e-05,
      "loss": 0.2261,
      "step": 4250
    },
    {
      "epoch": 1.01187648456057,
      "grad_norm": 5.0632195472717285,
      "learning_rate": 3.31353919239905e-05,
      "loss": 0.2736,
      "step": 4260
    },
    {
      "epoch": 1.0142517814726841,
      "grad_norm": 3.1848466396331787,
      "learning_rate": 3.309580364212193e-05,
      "loss": 0.2939,
      "step": 4270
    },
    {
      "epoch": 1.0166270783847982,
      "grad_norm": 4.251872539520264,
      "learning_rate": 3.305621536025337e-05,
      "loss": 0.2012,
      "step": 4280
    },
    {
      "epoch": 1.0190023752969122,
      "grad_norm": 4.787411689758301,
      "learning_rate": 3.30166270783848e-05,
      "loss": 0.3008,
      "step": 4290
    },
    {
      "epoch": 1.0213776722090262,
      "grad_norm": 4.798641681671143,
      "learning_rate": 3.297703879651624e-05,
      "loss": 0.303,
      "step": 4300
    },
    {
      "epoch": 1.0237529691211402,
      "grad_norm": 2.552243232727051,
      "learning_rate": 3.293745051464767e-05,
      "loss": 0.2972,
      "step": 4310
    },
    {
      "epoch": 1.0261282660332542,
      "grad_norm": 5.350612163543701,
      "learning_rate": 3.28978622327791e-05,
      "loss": 0.238,
      "step": 4320
    },
    {
      "epoch": 1.0285035629453683,
      "grad_norm": 2.9745960235595703,
      "learning_rate": 3.2858273950910537e-05,
      "loss": 0.2566,
      "step": 4330
    },
    {
      "epoch": 1.0308788598574823,
      "grad_norm": 6.886068344116211,
      "learning_rate": 3.281868566904197e-05,
      "loss": 0.2781,
      "step": 4340
    },
    {
      "epoch": 1.0332541567695963,
      "grad_norm": 4.506169319152832,
      "learning_rate": 3.27790973871734e-05,
      "loss": 0.2207,
      "step": 4350
    },
    {
      "epoch": 1.03562945368171,
      "grad_norm": 6.691051483154297,
      "learning_rate": 3.2739509105304835e-05,
      "loss": 0.2154,
      "step": 4360
    },
    {
      "epoch": 1.0380047505938241,
      "grad_norm": 4.299533367156982,
      "learning_rate": 3.2699920823436266e-05,
      "loss": 0.3923,
      "step": 4370
    },
    {
      "epoch": 1.0403800475059382,
      "grad_norm": 2.8056163787841797,
      "learning_rate": 3.2660332541567697e-05,
      "loss": 0.2597,
      "step": 4380
    },
    {
      "epoch": 1.0427553444180522,
      "grad_norm": 0.9019702076911926,
      "learning_rate": 3.2620744259699134e-05,
      "loss": 0.2684,
      "step": 4390
    },
    {
      "epoch": 1.0451306413301662,
      "grad_norm": 4.357205867767334,
      "learning_rate": 3.2581155977830565e-05,
      "loss": 0.286,
      "step": 4400
    },
    {
      "epoch": 1.0475059382422802,
      "grad_norm": 3.3427846431732178,
      "learning_rate": 3.2541567695961995e-05,
      "loss": 0.2112,
      "step": 4410
    },
    {
      "epoch": 1.0498812351543942,
      "grad_norm": 5.793449878692627,
      "learning_rate": 3.250197941409343e-05,
      "loss": 0.3152,
      "step": 4420
    },
    {
      "epoch": 1.0522565320665083,
      "grad_norm": 11.046650886535645,
      "learning_rate": 3.246239113222486e-05,
      "loss": 0.2412,
      "step": 4430
    },
    {
      "epoch": 1.0546318289786223,
      "grad_norm": 6.370227813720703,
      "learning_rate": 3.24228028503563e-05,
      "loss": 0.2445,
      "step": 4440
    },
    {
      "epoch": 1.0570071258907363,
      "grad_norm": 9.092110633850098,
      "learning_rate": 3.238321456848773e-05,
      "loss": 0.304,
      "step": 4450
    },
    {
      "epoch": 1.0593824228028503,
      "grad_norm": 2.6575124263763428,
      "learning_rate": 3.234362628661916e-05,
      "loss": 0.2424,
      "step": 4460
    },
    {
      "epoch": 1.0617577197149644,
      "grad_norm": 4.1144843101501465,
      "learning_rate": 3.23040380047506e-05,
      "loss": 0.2398,
      "step": 4470
    },
    {
      "epoch": 1.0641330166270784,
      "grad_norm": 2.0200083255767822,
      "learning_rate": 3.226444972288203e-05,
      "loss": 0.2033,
      "step": 4480
    },
    {
      "epoch": 1.0665083135391924,
      "grad_norm": 2.586608409881592,
      "learning_rate": 3.222486144101346e-05,
      "loss": 0.3067,
      "step": 4490
    },
    {
      "epoch": 1.0688836104513064,
      "grad_norm": 2.8598737716674805,
      "learning_rate": 3.21852731591449e-05,
      "loss": 0.2499,
      "step": 4500
    },
    {
      "epoch": 1.0712589073634204,
      "grad_norm": 1.5184568166732788,
      "learning_rate": 3.214568487727633e-05,
      "loss": 0.2687,
      "step": 4510
    },
    {
      "epoch": 1.0736342042755345,
      "grad_norm": 4.271984577178955,
      "learning_rate": 3.210609659540776e-05,
      "loss": 0.2915,
      "step": 4520
    },
    {
      "epoch": 1.0760095011876485,
      "grad_norm": 4.78103494644165,
      "learning_rate": 3.20665083135392e-05,
      "loss": 0.1805,
      "step": 4530
    },
    {
      "epoch": 1.0783847980997625,
      "grad_norm": 4.823672294616699,
      "learning_rate": 3.202692003167063e-05,
      "loss": 0.254,
      "step": 4540
    },
    {
      "epoch": 1.0807600950118765,
      "grad_norm": 3.2086257934570312,
      "learning_rate": 3.198733174980206e-05,
      "loss": 0.2387,
      "step": 4550
    },
    {
      "epoch": 1.0831353919239906,
      "grad_norm": 3.7120354175567627,
      "learning_rate": 3.1947743467933496e-05,
      "loss": 0.3403,
      "step": 4560
    },
    {
      "epoch": 1.0855106888361046,
      "grad_norm": 13.606532096862793,
      "learning_rate": 3.1908155186064926e-05,
      "loss": 0.2187,
      "step": 4570
    },
    {
      "epoch": 1.0878859857482186,
      "grad_norm": 5.033980846405029,
      "learning_rate": 3.1868566904196364e-05,
      "loss": 0.263,
      "step": 4580
    },
    {
      "epoch": 1.0902612826603326,
      "grad_norm": 3.6875271797180176,
      "learning_rate": 3.1828978622327794e-05,
      "loss": 0.259,
      "step": 4590
    },
    {
      "epoch": 1.0926365795724466,
      "grad_norm": 8.247024536132812,
      "learning_rate": 3.1789390340459225e-05,
      "loss": 0.2997,
      "step": 4600
    },
    {
      "epoch": 1.0950118764845607,
      "grad_norm": 4.095966339111328,
      "learning_rate": 3.174980205859066e-05,
      "loss": 0.2341,
      "step": 4610
    },
    {
      "epoch": 1.0973871733966747,
      "grad_norm": 4.901895046234131,
      "learning_rate": 3.171021377672209e-05,
      "loss": 0.3017,
      "step": 4620
    },
    {
      "epoch": 1.0997624703087885,
      "grad_norm": 4.7988996505737305,
      "learning_rate": 3.1670625494853524e-05,
      "loss": 0.2771,
      "step": 4630
    },
    {
      "epoch": 1.1021377672209025,
      "grad_norm": 3.407935857772827,
      "learning_rate": 3.163103721298496e-05,
      "loss": 0.2367,
      "step": 4640
    },
    {
      "epoch": 1.1045130641330165,
      "grad_norm": 5.3515729904174805,
      "learning_rate": 3.159144893111639e-05,
      "loss": 0.2675,
      "step": 4650
    },
    {
      "epoch": 1.1068883610451306,
      "grad_norm": 10.018866539001465,
      "learning_rate": 3.155186064924782e-05,
      "loss": 0.2156,
      "step": 4660
    },
    {
      "epoch": 1.1092636579572446,
      "grad_norm": 3.0413589477539062,
      "learning_rate": 3.151227236737926e-05,
      "loss": 0.1851,
      "step": 4670
    },
    {
      "epoch": 1.1116389548693586,
      "grad_norm": 1.7464921474456787,
      "learning_rate": 3.147268408551069e-05,
      "loss": 0.2619,
      "step": 4680
    },
    {
      "epoch": 1.1140142517814726,
      "grad_norm": 2.7596983909606934,
      "learning_rate": 3.143309580364212e-05,
      "loss": 0.25,
      "step": 4690
    },
    {
      "epoch": 1.1163895486935866,
      "grad_norm": 3.5624032020568848,
      "learning_rate": 3.139350752177356e-05,
      "loss": 0.2539,
      "step": 4700
    },
    {
      "epoch": 1.1187648456057007,
      "grad_norm": 3.487409830093384,
      "learning_rate": 3.135391923990499e-05,
      "loss": 0.3117,
      "step": 4710
    },
    {
      "epoch": 1.1211401425178147,
      "grad_norm": 0.9690169095993042,
      "learning_rate": 3.131433095803643e-05,
      "loss": 0.2755,
      "step": 4720
    },
    {
      "epoch": 1.1235154394299287,
      "grad_norm": 7.792211532592773,
      "learning_rate": 3.127474267616786e-05,
      "loss": 0.2431,
      "step": 4730
    },
    {
      "epoch": 1.1258907363420427,
      "grad_norm": 4.322487831115723,
      "learning_rate": 3.123515439429929e-05,
      "loss": 0.2752,
      "step": 4740
    },
    {
      "epoch": 1.1282660332541568,
      "grad_norm": 4.3630475997924805,
      "learning_rate": 3.1195566112430725e-05,
      "loss": 0.3185,
      "step": 4750
    },
    {
      "epoch": 1.1306413301662708,
      "grad_norm": 2.5317699909210205,
      "learning_rate": 3.1155977830562156e-05,
      "loss": 0.3108,
      "step": 4760
    },
    {
      "epoch": 1.1330166270783848,
      "grad_norm": 2.187008857727051,
      "learning_rate": 3.111638954869359e-05,
      "loss": 0.2252,
      "step": 4770
    },
    {
      "epoch": 1.1353919239904988,
      "grad_norm": 3.7941670417785645,
      "learning_rate": 3.1076801266825024e-05,
      "loss": 0.2385,
      "step": 4780
    },
    {
      "epoch": 1.1377672209026128,
      "grad_norm": 4.014402866363525,
      "learning_rate": 3.1037212984956455e-05,
      "loss": 0.2471,
      "step": 4790
    },
    {
      "epoch": 1.1401425178147269,
      "grad_norm": 3.2437307834625244,
      "learning_rate": 3.0997624703087885e-05,
      "loss": 0.2787,
      "step": 4800
    },
    {
      "epoch": 1.1425178147268409,
      "grad_norm": 4.065128326416016,
      "learning_rate": 3.095803642121932e-05,
      "loss": 0.3229,
      "step": 4810
    },
    {
      "epoch": 1.144893111638955,
      "grad_norm": 4.144003868103027,
      "learning_rate": 3.0918448139350753e-05,
      "loss": 0.2864,
      "step": 4820
    },
    {
      "epoch": 1.147268408551069,
      "grad_norm": 2.129490852355957,
      "learning_rate": 3.0878859857482184e-05,
      "loss": 0.3411,
      "step": 4830
    },
    {
      "epoch": 1.149643705463183,
      "grad_norm": 4.690135478973389,
      "learning_rate": 3.083927157561362e-05,
      "loss": 0.2979,
      "step": 4840
    },
    {
      "epoch": 1.152019002375297,
      "grad_norm": 4.719354629516602,
      "learning_rate": 3.079968329374505e-05,
      "loss": 0.2491,
      "step": 4850
    },
    {
      "epoch": 1.154394299287411,
      "grad_norm": 4.476076126098633,
      "learning_rate": 3.076009501187649e-05,
      "loss": 0.2224,
      "step": 4860
    },
    {
      "epoch": 1.156769596199525,
      "grad_norm": 4.528599739074707,
      "learning_rate": 3.072050673000792e-05,
      "loss": 0.2864,
      "step": 4870
    },
    {
      "epoch": 1.159144893111639,
      "grad_norm": 2.475113868713379,
      "learning_rate": 3.068091844813935e-05,
      "loss": 0.242,
      "step": 4880
    },
    {
      "epoch": 1.161520190023753,
      "grad_norm": 4.457276821136475,
      "learning_rate": 3.064133016627079e-05,
      "loss": 0.3039,
      "step": 4890
    },
    {
      "epoch": 1.1638954869358669,
      "grad_norm": 3.9018118381500244,
      "learning_rate": 3.060174188440222e-05,
      "loss": 0.3123,
      "step": 4900
    },
    {
      "epoch": 1.166270783847981,
      "grad_norm": 1.2887693643569946,
      "learning_rate": 3.056215360253365e-05,
      "loss": 0.2638,
      "step": 4910
    },
    {
      "epoch": 1.168646080760095,
      "grad_norm": 5.210658550262451,
      "learning_rate": 3.052256532066509e-05,
      "loss": 0.2646,
      "step": 4920
    },
    {
      "epoch": 1.171021377672209,
      "grad_norm": 0.7126054167747498,
      "learning_rate": 3.0482977038796518e-05,
      "loss": 0.3105,
      "step": 4930
    },
    {
      "epoch": 1.173396674584323,
      "grad_norm": 1.0631651878356934,
      "learning_rate": 3.044338875692795e-05,
      "loss": 0.2426,
      "step": 4940
    },
    {
      "epoch": 1.175771971496437,
      "grad_norm": 1.100005030632019,
      "learning_rate": 3.0403800475059386e-05,
      "loss": 0.2737,
      "step": 4950
    },
    {
      "epoch": 1.178147268408551,
      "grad_norm": 1.0185184478759766,
      "learning_rate": 3.0364212193190816e-05,
      "loss": 0.205,
      "step": 4960
    },
    {
      "epoch": 1.180522565320665,
      "grad_norm": 3.073004722595215,
      "learning_rate": 3.0324623911322247e-05,
      "loss": 0.2391,
      "step": 4970
    },
    {
      "epoch": 1.182897862232779,
      "grad_norm": 2.9137983322143555,
      "learning_rate": 3.0285035629453685e-05,
      "loss": 0.2848,
      "step": 4980
    },
    {
      "epoch": 1.185273159144893,
      "grad_norm": 5.679600238800049,
      "learning_rate": 3.0245447347585115e-05,
      "loss": 0.2797,
      "step": 4990
    },
    {
      "epoch": 1.187648456057007,
      "grad_norm": 5.393233299255371,
      "learning_rate": 3.0205859065716553e-05,
      "loss": 0.2377,
      "step": 5000
    },
    {
      "epoch": 1.190023752969121,
      "grad_norm": 4.435635566711426,
      "learning_rate": 3.0166270783847983e-05,
      "loss": 0.3221,
      "step": 5010
    },
    {
      "epoch": 1.1923990498812351,
      "grad_norm": 4.036543369293213,
      "learning_rate": 3.0126682501979414e-05,
      "loss": 0.2446,
      "step": 5020
    },
    {
      "epoch": 1.1947743467933492,
      "grad_norm": 3.896369695663452,
      "learning_rate": 3.008709422011085e-05,
      "loss": 0.2705,
      "step": 5030
    },
    {
      "epoch": 1.1971496437054632,
      "grad_norm": 3.6257693767547607,
      "learning_rate": 3.0047505938242282e-05,
      "loss": 0.3021,
      "step": 5040
    },
    {
      "epoch": 1.1995249406175772,
      "grad_norm": 4.63031005859375,
      "learning_rate": 3.0007917656373713e-05,
      "loss": 0.3096,
      "step": 5050
    },
    {
      "epoch": 1.2019002375296912,
      "grad_norm": 6.003429889678955,
      "learning_rate": 2.996832937450515e-05,
      "loss": 0.2819,
      "step": 5060
    },
    {
      "epoch": 1.2042755344418052,
      "grad_norm": 3.2522318363189697,
      "learning_rate": 2.992874109263658e-05,
      "loss": 0.2274,
      "step": 5070
    },
    {
      "epoch": 1.2066508313539193,
      "grad_norm": 3.2491655349731445,
      "learning_rate": 2.988915281076801e-05,
      "loss": 0.2628,
      "step": 5080
    },
    {
      "epoch": 1.2090261282660333,
      "grad_norm": 1.8517805337905884,
      "learning_rate": 2.984956452889945e-05,
      "loss": 0.2692,
      "step": 5090
    },
    {
      "epoch": 1.2114014251781473,
      "grad_norm": 3.6156725883483887,
      "learning_rate": 2.980997624703088e-05,
      "loss": 0.244,
      "step": 5100
    },
    {
      "epoch": 1.2137767220902613,
      "grad_norm": 4.3293304443359375,
      "learning_rate": 2.977038796516231e-05,
      "loss": 0.2741,
      "step": 5110
    },
    {
      "epoch": 1.2161520190023754,
      "grad_norm": 3.323291301727295,
      "learning_rate": 2.9730799683293747e-05,
      "loss": 0.2135,
      "step": 5120
    },
    {
      "epoch": 1.2185273159144894,
      "grad_norm": 2.27443790435791,
      "learning_rate": 2.9691211401425178e-05,
      "loss": 0.2745,
      "step": 5130
    },
    {
      "epoch": 1.2209026128266034,
      "grad_norm": 2.53648042678833,
      "learning_rate": 2.9651623119556616e-05,
      "loss": 0.1727,
      "step": 5140
    },
    {
      "epoch": 1.2232779097387174,
      "grad_norm": 7.09758186340332,
      "learning_rate": 2.9612034837688046e-05,
      "loss": 0.2611,
      "step": 5150
    },
    {
      "epoch": 1.2256532066508314,
      "grad_norm": 2.647500514984131,
      "learning_rate": 2.9572446555819477e-05,
      "loss": 0.2723,
      "step": 5160
    },
    {
      "epoch": 1.2280285035629455,
      "grad_norm": 4.007715702056885,
      "learning_rate": 2.9532858273950914e-05,
      "loss": 0.2682,
      "step": 5170
    },
    {
      "epoch": 1.2304038004750595,
      "grad_norm": 5.630643844604492,
      "learning_rate": 2.9493269992082345e-05,
      "loss": 0.2861,
      "step": 5180
    },
    {
      "epoch": 1.2327790973871733,
      "grad_norm": 2.309504270553589,
      "learning_rate": 2.9453681710213776e-05,
      "loss": 0.2608,
      "step": 5190
    },
    {
      "epoch": 1.2351543942992875,
      "grad_norm": 2.2809863090515137,
      "learning_rate": 2.9414093428345213e-05,
      "loss": 0.2967,
      "step": 5200
    },
    {
      "epoch": 1.2375296912114013,
      "grad_norm": 6.112220764160156,
      "learning_rate": 2.9374505146476644e-05,
      "loss": 0.2411,
      "step": 5210
    },
    {
      "epoch": 1.2399049881235154,
      "grad_norm": 2.2980849742889404,
      "learning_rate": 2.9334916864608074e-05,
      "loss": 0.2857,
      "step": 5220
    },
    {
      "epoch": 1.2422802850356294,
      "grad_norm": 5.534721374511719,
      "learning_rate": 2.929532858273951e-05,
      "loss": 0.2269,
      "step": 5230
    },
    {
      "epoch": 1.2446555819477434,
      "grad_norm": 9.142240524291992,
      "learning_rate": 2.9255740300870942e-05,
      "loss": 0.2626,
      "step": 5240
    },
    {
      "epoch": 1.2470308788598574,
      "grad_norm": 4.789814472198486,
      "learning_rate": 2.9216152019002373e-05,
      "loss": 0.2754,
      "step": 5250
    },
    {
      "epoch": 1.2494061757719714,
      "grad_norm": 4.51373291015625,
      "learning_rate": 2.917656373713381e-05,
      "loss": 0.2959,
      "step": 5260
    },
    {
      "epoch": 1.2517814726840855,
      "grad_norm": 3.0754446983337402,
      "learning_rate": 2.913697545526524e-05,
      "loss": 0.2485,
      "step": 5270
    },
    {
      "epoch": 1.2541567695961995,
      "grad_norm": 4.543591022491455,
      "learning_rate": 2.909738717339668e-05,
      "loss": 0.2341,
      "step": 5280
    },
    {
      "epoch": 1.2565320665083135,
      "grad_norm": 2.741426706314087,
      "learning_rate": 2.905779889152811e-05,
      "loss": 0.289,
      "step": 5290
    },
    {
      "epoch": 1.2589073634204275,
      "grad_norm": 4.26570463180542,
      "learning_rate": 2.901821060965954e-05,
      "loss": 0.2422,
      "step": 5300
    },
    {
      "epoch": 1.2612826603325415,
      "grad_norm": 2.287720203399658,
      "learning_rate": 2.8978622327790977e-05,
      "loss": 0.2407,
      "step": 5310
    },
    {
      "epoch": 1.2636579572446556,
      "grad_norm": 2.0483126640319824,
      "learning_rate": 2.8939034045922408e-05,
      "loss": 0.24,
      "step": 5320
    },
    {
      "epoch": 1.2660332541567696,
      "grad_norm": 5.300848007202148,
      "learning_rate": 2.889944576405384e-05,
      "loss": 0.3652,
      "step": 5330
    },
    {
      "epoch": 1.2684085510688836,
      "grad_norm": 4.885062217712402,
      "learning_rate": 2.8859857482185276e-05,
      "loss": 0.2171,
      "step": 5340
    },
    {
      "epoch": 1.2707838479809976,
      "grad_norm": 3.182333469390869,
      "learning_rate": 2.8820269200316707e-05,
      "loss": 0.2396,
      "step": 5350
    },
    {
      "epoch": 1.2731591448931117,
      "grad_norm": 3.856501340866089,
      "learning_rate": 2.8780680918448137e-05,
      "loss": 0.3134,
      "step": 5360
    },
    {
      "epoch": 1.2755344418052257,
      "grad_norm": 4.275303840637207,
      "learning_rate": 2.8741092636579575e-05,
      "loss": 0.3242,
      "step": 5370
    },
    {
      "epoch": 1.2779097387173397,
      "grad_norm": 2.510289430618286,
      "learning_rate": 2.8701504354711005e-05,
      "loss": 0.2248,
      "step": 5380
    },
    {
      "epoch": 1.2802850356294537,
      "grad_norm": 3.4690709114074707,
      "learning_rate": 2.8661916072842436e-05,
      "loss": 0.2578,
      "step": 5390
    },
    {
      "epoch": 1.2826603325415677,
      "grad_norm": 5.13466215133667,
      "learning_rate": 2.8622327790973873e-05,
      "loss": 0.2727,
      "step": 5400
    },
    {
      "epoch": 1.2850356294536818,
      "grad_norm": 3.1185548305511475,
      "learning_rate": 2.8582739509105304e-05,
      "loss": 0.2565,
      "step": 5410
    },
    {
      "epoch": 1.2874109263657958,
      "grad_norm": 3.249129056930542,
      "learning_rate": 2.854315122723674e-05,
      "loss": 0.2261,
      "step": 5420
    },
    {
      "epoch": 1.2897862232779098,
      "grad_norm": 4.064042091369629,
      "learning_rate": 2.8503562945368172e-05,
      "loss": 0.252,
      "step": 5430
    },
    {
      "epoch": 1.2921615201900236,
      "grad_norm": 4.019872665405273,
      "learning_rate": 2.8463974663499603e-05,
      "loss": 0.2707,
      "step": 5440
    },
    {
      "epoch": 1.2945368171021379,
      "grad_norm": 6.660575866699219,
      "learning_rate": 2.842438638163104e-05,
      "loss": 0.3013,
      "step": 5450
    },
    {
      "epoch": 1.2969121140142517,
      "grad_norm": 2.539430856704712,
      "learning_rate": 2.838479809976247e-05,
      "loss": 0.223,
      "step": 5460
    },
    {
      "epoch": 1.299287410926366,
      "grad_norm": 5.428154945373535,
      "learning_rate": 2.83452098178939e-05,
      "loss": 0.2906,
      "step": 5470
    },
    {
      "epoch": 1.3016627078384797,
      "grad_norm": 5.699551582336426,
      "learning_rate": 2.830562153602534e-05,
      "loss": 0.2751,
      "step": 5480
    },
    {
      "epoch": 1.304038004750594,
      "grad_norm": 3.522059917449951,
      "learning_rate": 2.826603325415677e-05,
      "loss": 0.2794,
      "step": 5490
    },
    {
      "epoch": 1.3064133016627077,
      "grad_norm": 3.861022710800171,
      "learning_rate": 2.82264449722882e-05,
      "loss": 0.2172,
      "step": 5500
    },
    {
      "epoch": 1.3087885985748218,
      "grad_norm": 1.749778151512146,
      "learning_rate": 2.8186856690419638e-05,
      "loss": 0.3135,
      "step": 5510
    },
    {
      "epoch": 1.3111638954869358,
      "grad_norm": 1.742971420288086,
      "learning_rate": 2.8147268408551068e-05,
      "loss": 0.3121,
      "step": 5520
    },
    {
      "epoch": 1.3135391923990498,
      "grad_norm": 2.8139896392822266,
      "learning_rate": 2.8107680126682502e-05,
      "loss": 0.2482,
      "step": 5530
    },
    {
      "epoch": 1.3159144893111638,
      "grad_norm": 4.209640979766846,
      "learning_rate": 2.8068091844813936e-05,
      "loss": 0.2694,
      "step": 5540
    },
    {
      "epoch": 1.3182897862232779,
      "grad_norm": 3.016223669052124,
      "learning_rate": 2.8028503562945367e-05,
      "loss": 0.2856,
      "step": 5550
    },
    {
      "epoch": 1.3206650831353919,
      "grad_norm": 3.1658284664154053,
      "learning_rate": 2.7988915281076804e-05,
      "loss": 0.2239,
      "step": 5560
    },
    {
      "epoch": 1.323040380047506,
      "grad_norm": 3.4052467346191406,
      "learning_rate": 2.7949326999208235e-05,
      "loss": 0.2815,
      "step": 5570
    },
    {
      "epoch": 1.32541567695962,
      "grad_norm": 3.958951473236084,
      "learning_rate": 2.790973871733967e-05,
      "loss": 0.2485,
      "step": 5580
    },
    {
      "epoch": 1.327790973871734,
      "grad_norm": 2.8602113723754883,
      "learning_rate": 2.7870150435471103e-05,
      "loss": 0.2423,
      "step": 5590
    },
    {
      "epoch": 1.330166270783848,
      "grad_norm": 4.202701091766357,
      "learning_rate": 2.7830562153602534e-05,
      "loss": 0.1896,
      "step": 5600
    },
    {
      "epoch": 1.332541567695962,
      "grad_norm": 4.628777503967285,
      "learning_rate": 2.7790973871733968e-05,
      "loss": 0.1904,
      "step": 5610
    },
    {
      "epoch": 1.334916864608076,
      "grad_norm": 3.1220862865448,
      "learning_rate": 2.7751385589865402e-05,
      "loss": 0.2878,
      "step": 5620
    },
    {
      "epoch": 1.33729216152019,
      "grad_norm": 2.6017119884490967,
      "learning_rate": 2.7711797307996832e-05,
      "loss": 0.2418,
      "step": 5630
    },
    {
      "epoch": 1.339667458432304,
      "grad_norm": 3.809284210205078,
      "learning_rate": 2.7672209026128266e-05,
      "loss": 0.3042,
      "step": 5640
    },
    {
      "epoch": 1.342042755344418,
      "grad_norm": 3.0280182361602783,
      "learning_rate": 2.76326207442597e-05,
      "loss": 0.2413,
      "step": 5650
    },
    {
      "epoch": 1.344418052256532,
      "grad_norm": 4.44451379776001,
      "learning_rate": 2.7593032462391135e-05,
      "loss": 0.2523,
      "step": 5660
    },
    {
      "epoch": 1.3467933491686461,
      "grad_norm": 4.626204490661621,
      "learning_rate": 2.7553444180522565e-05,
      "loss": 0.3075,
      "step": 5670
    },
    {
      "epoch": 1.3491686460807601,
      "grad_norm": 4.539735794067383,
      "learning_rate": 2.7513855898654e-05,
      "loss": 0.1844,
      "step": 5680
    },
    {
      "epoch": 1.3515439429928742,
      "grad_norm": 7.631628036499023,
      "learning_rate": 2.7474267616785433e-05,
      "loss": 0.2312,
      "step": 5690
    },
    {
      "epoch": 1.3539192399049882,
      "grad_norm": 3.3173792362213135,
      "learning_rate": 2.7434679334916867e-05,
      "loss": 0.2798,
      "step": 5700
    },
    {
      "epoch": 1.3562945368171022,
      "grad_norm": 4.654519557952881,
      "learning_rate": 2.7395091053048298e-05,
      "loss": 0.2281,
      "step": 5710
    },
    {
      "epoch": 1.3586698337292162,
      "grad_norm": 9.7090425491333,
      "learning_rate": 2.7355502771179732e-05,
      "loss": 0.2911,
      "step": 5720
    },
    {
      "epoch": 1.36104513064133,
      "grad_norm": 4.266524791717529,
      "learning_rate": 2.7315914489311166e-05,
      "loss": 0.2155,
      "step": 5730
    },
    {
      "epoch": 1.3634204275534443,
      "grad_norm": 1.664469599723816,
      "learning_rate": 2.72763262074426e-05,
      "loss": 0.2378,
      "step": 5740
    },
    {
      "epoch": 1.365795724465558,
      "grad_norm": 1.5838985443115234,
      "learning_rate": 2.723673792557403e-05,
      "loss": 0.227,
      "step": 5750
    },
    {
      "epoch": 1.3681710213776723,
      "grad_norm": 1.9833300113677979,
      "learning_rate": 2.7197149643705465e-05,
      "loss": 0.2443,
      "step": 5760
    },
    {
      "epoch": 1.3705463182897861,
      "grad_norm": 3.6368775367736816,
      "learning_rate": 2.71575613618369e-05,
      "loss": 0.2304,
      "step": 5770
    },
    {
      "epoch": 1.3729216152019004,
      "grad_norm": 3.1879329681396484,
      "learning_rate": 2.711797307996833e-05,
      "loss": 0.2616,
      "step": 5780
    },
    {
      "epoch": 1.3752969121140142,
      "grad_norm": 1.113821268081665,
      "learning_rate": 2.7078384798099763e-05,
      "loss": 0.2095,
      "step": 5790
    },
    {
      "epoch": 1.3776722090261282,
      "grad_norm": 6.216457366943359,
      "learning_rate": 2.7038796516231197e-05,
      "loss": 0.1685,
      "step": 5800
    },
    {
      "epoch": 1.3800475059382422,
      "grad_norm": 7.692490100860596,
      "learning_rate": 2.6999208234362628e-05,
      "loss": 0.2672,
      "step": 5810
    },
    {
      "epoch": 1.3824228028503562,
      "grad_norm": 2.858137845993042,
      "learning_rate": 2.6959619952494066e-05,
      "loss": 0.2346,
      "step": 5820
    },
    {
      "epoch": 1.3847980997624703,
      "grad_norm": 3.535266637802124,
      "learning_rate": 2.6920031670625496e-05,
      "loss": 0.2711,
      "step": 5830
    },
    {
      "epoch": 1.3871733966745843,
      "grad_norm": 2.330580711364746,
      "learning_rate": 2.688044338875693e-05,
      "loss": 0.3504,
      "step": 5840
    },
    {
      "epoch": 1.3895486935866983,
      "grad_norm": 3.4794700145721436,
      "learning_rate": 2.6840855106888364e-05,
      "loss": 0.1917,
      "step": 5850
    },
    {
      "epoch": 1.3919239904988123,
      "grad_norm": 3.7150802612304688,
      "learning_rate": 2.6801266825019795e-05,
      "loss": 0.3043,
      "step": 5860
    },
    {
      "epoch": 1.3942992874109263,
      "grad_norm": 7.543777942657471,
      "learning_rate": 2.6761678543151232e-05,
      "loss": 0.3155,
      "step": 5870
    },
    {
      "epoch": 1.3966745843230404,
      "grad_norm": 2.5921695232391357,
      "learning_rate": 2.6722090261282663e-05,
      "loss": 0.247,
      "step": 5880
    },
    {
      "epoch": 1.3990498812351544,
      "grad_norm": 3.730830430984497,
      "learning_rate": 2.6682501979414094e-05,
      "loss": 0.2868,
      "step": 5890
    },
    {
      "epoch": 1.4014251781472684,
      "grad_norm": 4.111649513244629,
      "learning_rate": 2.664291369754553e-05,
      "loss": 0.2809,
      "step": 5900
    },
    {
      "epoch": 1.4038004750593824,
      "grad_norm": 3.8717949390411377,
      "learning_rate": 2.6603325415676962e-05,
      "loss": 0.1507,
      "step": 5910
    },
    {
      "epoch": 1.4061757719714965,
      "grad_norm": 5.39950704574585,
      "learning_rate": 2.6563737133808392e-05,
      "loss": 0.2754,
      "step": 5920
    },
    {
      "epoch": 1.4085510688836105,
      "grad_norm": 6.031144142150879,
      "learning_rate": 2.652414885193983e-05,
      "loss": 0.2117,
      "step": 5930
    },
    {
      "epoch": 1.4109263657957245,
      "grad_norm": 6.945388317108154,
      "learning_rate": 2.648456057007126e-05,
      "loss": 0.2909,
      "step": 5940
    },
    {
      "epoch": 1.4133016627078385,
      "grad_norm": 2.2029898166656494,
      "learning_rate": 2.644497228820269e-05,
      "loss": 0.3152,
      "step": 5950
    },
    {
      "epoch": 1.4156769596199525,
      "grad_norm": 1.4706047773361206,
      "learning_rate": 2.640538400633413e-05,
      "loss": 0.2301,
      "step": 5960
    },
    {
      "epoch": 1.4180522565320666,
      "grad_norm": 2.9663825035095215,
      "learning_rate": 2.636579572446556e-05,
      "loss": 0.2747,
      "step": 5970
    },
    {
      "epoch": 1.4204275534441806,
      "grad_norm": 5.004908084869385,
      "learning_rate": 2.6326207442596997e-05,
      "loss": 0.1955,
      "step": 5980
    },
    {
      "epoch": 1.4228028503562946,
      "grad_norm": 4.213899612426758,
      "learning_rate": 2.6286619160728427e-05,
      "loss": 0.2364,
      "step": 5990
    },
    {
      "epoch": 1.4251781472684084,
      "grad_norm": 3.6575920581817627,
      "learning_rate": 2.6247030878859858e-05,
      "loss": 0.2607,
      "step": 6000
    },
    {
      "epoch": 1.4275534441805227,
      "grad_norm": 1.8799519538879395,
      "learning_rate": 2.6207442596991295e-05,
      "loss": 0.1579,
      "step": 6010
    },
    {
      "epoch": 1.4299287410926365,
      "grad_norm": 2.5898380279541016,
      "learning_rate": 2.6167854315122726e-05,
      "loss": 0.2043,
      "step": 6020
    },
    {
      "epoch": 1.4323040380047507,
      "grad_norm": 0.373671293258667,
      "learning_rate": 2.6128266033254157e-05,
      "loss": 0.3317,
      "step": 6030
    },
    {
      "epoch": 1.4346793349168645,
      "grad_norm": 6.865359783172607,
      "learning_rate": 2.6088677751385594e-05,
      "loss": 0.2667,
      "step": 6040
    },
    {
      "epoch": 1.4370546318289787,
      "grad_norm": 2.431717872619629,
      "learning_rate": 2.6049089469517025e-05,
      "loss": 0.2294,
      "step": 6050
    },
    {
      "epoch": 1.4394299287410925,
      "grad_norm": 9.239567756652832,
      "learning_rate": 2.6009501187648455e-05,
      "loss": 0.2901,
      "step": 6060
    },
    {
      "epoch": 1.4418052256532066,
      "grad_norm": 4.443600654602051,
      "learning_rate": 2.5969912905779893e-05,
      "loss": 0.3219,
      "step": 6070
    },
    {
      "epoch": 1.4441805225653206,
      "grad_norm": 3.6053600311279297,
      "learning_rate": 2.5930324623911323e-05,
      "loss": 0.2126,
      "step": 6080
    },
    {
      "epoch": 1.4465558194774346,
      "grad_norm": 3.9027955532073975,
      "learning_rate": 2.5890736342042754e-05,
      "loss": 0.3177,
      "step": 6090
    },
    {
      "epoch": 1.4489311163895486,
      "grad_norm": 3.290138006210327,
      "learning_rate": 2.585114806017419e-05,
      "loss": 0.2513,
      "step": 6100
    },
    {
      "epoch": 1.4513064133016627,
      "grad_norm": 1.9204511642456055,
      "learning_rate": 2.5811559778305622e-05,
      "loss": 0.2036,
      "step": 6110
    },
    {
      "epoch": 1.4536817102137767,
      "grad_norm": 3.4345781803131104,
      "learning_rate": 2.577197149643706e-05,
      "loss": 0.2727,
      "step": 6120
    },
    {
      "epoch": 1.4560570071258907,
      "grad_norm": 4.734868049621582,
      "learning_rate": 2.573238321456849e-05,
      "loss": 0.2265,
      "step": 6130
    },
    {
      "epoch": 1.4584323040380047,
      "grad_norm": 1.7549560070037842,
      "learning_rate": 2.569279493269992e-05,
      "loss": 0.2251,
      "step": 6140
    },
    {
      "epoch": 1.4608076009501187,
      "grad_norm": 1.2990996837615967,
      "learning_rate": 2.5653206650831358e-05,
      "loss": 0.267,
      "step": 6150
    },
    {
      "epoch": 1.4631828978622328,
      "grad_norm": 3.726978063583374,
      "learning_rate": 2.561361836896279e-05,
      "loss": 0.2754,
      "step": 6160
    },
    {
      "epoch": 1.4655581947743468,
      "grad_norm": 7.147741794586182,
      "learning_rate": 2.557403008709422e-05,
      "loss": 0.2227,
      "step": 6170
    },
    {
      "epoch": 1.4679334916864608,
      "grad_norm": 3.660827398300171,
      "learning_rate": 2.5534441805225657e-05,
      "loss": 0.2311,
      "step": 6180
    },
    {
      "epoch": 1.4703087885985748,
      "grad_norm": 1.9535146951675415,
      "learning_rate": 2.5494853523357088e-05,
      "loss": 0.219,
      "step": 6190
    },
    {
      "epoch": 1.4726840855106889,
      "grad_norm": 4.777299404144287,
      "learning_rate": 2.5455265241488518e-05,
      "loss": 0.2155,
      "step": 6200
    },
    {
      "epoch": 1.4750593824228029,
      "grad_norm": 3.4654109477996826,
      "learning_rate": 2.5415676959619956e-05,
      "loss": 0.3158,
      "step": 6210
    },
    {
      "epoch": 1.477434679334917,
      "grad_norm": 3.0875887870788574,
      "learning_rate": 2.5376088677751386e-05,
      "loss": 0.2482,
      "step": 6220
    },
    {
      "epoch": 1.479809976247031,
      "grad_norm": 1.595487117767334,
      "learning_rate": 2.5336500395882817e-05,
      "loss": 0.248,
      "step": 6230
    },
    {
      "epoch": 1.482185273159145,
      "grad_norm": 8.7534818649292,
      "learning_rate": 2.5296912114014254e-05,
      "loss": 0.2016,
      "step": 6240
    },
    {
      "epoch": 1.484560570071259,
      "grad_norm": 4.569928169250488,
      "learning_rate": 2.5257323832145685e-05,
      "loss": 0.3781,
      "step": 6250
    },
    {
      "epoch": 1.486935866983373,
      "grad_norm": 1.3594779968261719,
      "learning_rate": 2.5217735550277122e-05,
      "loss": 0.2327,
      "step": 6260
    },
    {
      "epoch": 1.489311163895487,
      "grad_norm": 5.141453742980957,
      "learning_rate": 2.5178147268408553e-05,
      "loss": 0.246,
      "step": 6270
    },
    {
      "epoch": 1.491686460807601,
      "grad_norm": 4.897467136383057,
      "learning_rate": 2.5138558986539984e-05,
      "loss": 0.2048,
      "step": 6280
    },
    {
      "epoch": 1.4940617577197148,
      "grad_norm": 2.3693556785583496,
      "learning_rate": 2.509897070467142e-05,
      "loss": 0.2279,
      "step": 6290
    },
    {
      "epoch": 1.496437054631829,
      "grad_norm": 7.108677387237549,
      "learning_rate": 2.5059382422802852e-05,
      "loss": 0.3847,
      "step": 6300
    },
    {
      "epoch": 1.4988123515439429,
      "grad_norm": 5.464592933654785,
      "learning_rate": 2.5019794140934282e-05,
      "loss": 0.1778,
      "step": 6310
    },
    {
      "epoch": 1.5011876484560571,
      "grad_norm": 5.211793899536133,
      "learning_rate": 2.4980205859065717e-05,
      "loss": 0.227,
      "step": 6320
    },
    {
      "epoch": 1.503562945368171,
      "grad_norm": 1.4930418729782104,
      "learning_rate": 2.494061757719715e-05,
      "loss": 0.3483,
      "step": 6330
    },
    {
      "epoch": 1.5059382422802852,
      "grad_norm": 4.333076000213623,
      "learning_rate": 2.4901029295328585e-05,
      "loss": 0.3223,
      "step": 6340
    },
    {
      "epoch": 1.508313539192399,
      "grad_norm": 3.7642345428466797,
      "learning_rate": 2.4861441013460015e-05,
      "loss": 0.2729,
      "step": 6350
    },
    {
      "epoch": 1.5106888361045132,
      "grad_norm": 2.3134689331054688,
      "learning_rate": 2.482185273159145e-05,
      "loss": 0.241,
      "step": 6360
    },
    {
      "epoch": 1.513064133016627,
      "grad_norm": 1.4122990369796753,
      "learning_rate": 2.4782264449722883e-05,
      "loss": 0.1987,
      "step": 6370
    },
    {
      "epoch": 1.5154394299287413,
      "grad_norm": 4.475339412689209,
      "learning_rate": 2.4742676167854317e-05,
      "loss": 0.2473,
      "step": 6380
    },
    {
      "epoch": 1.517814726840855,
      "grad_norm": 4.317797660827637,
      "learning_rate": 2.4703087885985748e-05,
      "loss": 0.1998,
      "step": 6390
    },
    {
      "epoch": 1.520190023752969,
      "grad_norm": 11.29576301574707,
      "learning_rate": 2.4663499604117182e-05,
      "loss": 0.35,
      "step": 6400
    },
    {
      "epoch": 1.522565320665083,
      "grad_norm": 8.438430786132812,
      "learning_rate": 2.4623911322248616e-05,
      "loss": 0.2549,
      "step": 6410
    },
    {
      "epoch": 1.5249406175771971,
      "grad_norm": 5.07830810546875,
      "learning_rate": 2.4584323040380047e-05,
      "loss": 0.2966,
      "step": 6420
    },
    {
      "epoch": 1.5273159144893111,
      "grad_norm": 5.548941135406494,
      "learning_rate": 2.454473475851148e-05,
      "loss": 0.219,
      "step": 6430
    },
    {
      "epoch": 1.5296912114014252,
      "grad_norm": 3.2297017574310303,
      "learning_rate": 2.4505146476642915e-05,
      "loss": 0.2349,
      "step": 6440
    },
    {
      "epoch": 1.5320665083135392,
      "grad_norm": 1.8982256650924683,
      "learning_rate": 2.446555819477435e-05,
      "loss": 0.1954,
      "step": 6450
    },
    {
      "epoch": 1.5344418052256532,
      "grad_norm": 4.377315998077393,
      "learning_rate": 2.442596991290578e-05,
      "loss": 0.333,
      "step": 6460
    },
    {
      "epoch": 1.5368171021377672,
      "grad_norm": 6.896507263183594,
      "learning_rate": 2.4386381631037214e-05,
      "loss": 0.2442,
      "step": 6470
    },
    {
      "epoch": 1.5391923990498813,
      "grad_norm": 4.339461803436279,
      "learning_rate": 2.4346793349168648e-05,
      "loss": 0.3078,
      "step": 6480
    },
    {
      "epoch": 1.5415676959619953,
      "grad_norm": 4.080773830413818,
      "learning_rate": 2.4307205067300078e-05,
      "loss": 0.2939,
      "step": 6490
    },
    {
      "epoch": 1.5439429928741093,
      "grad_norm": 4.056666851043701,
      "learning_rate": 2.4267616785431512e-05,
      "loss": 0.2906,
      "step": 6500
    },
    {
      "epoch": 1.5463182897862233,
      "grad_norm": 5.19310188293457,
      "learning_rate": 2.4228028503562946e-05,
      "loss": 0.2776,
      "step": 6510
    },
    {
      "epoch": 1.5486935866983373,
      "grad_norm": 3.5808768272399902,
      "learning_rate": 2.418844022169438e-05,
      "loss": 0.1816,
      "step": 6520
    },
    {
      "epoch": 1.5510688836104514,
      "grad_norm": 1.4376474618911743,
      "learning_rate": 2.414885193982581e-05,
      "loss": 0.2134,
      "step": 6530
    },
    {
      "epoch": 1.5534441805225652,
      "grad_norm": 3.2468783855438232,
      "learning_rate": 2.4109263657957245e-05,
      "loss": 0.2125,
      "step": 6540
    },
    {
      "epoch": 1.5558194774346794,
      "grad_norm": 6.025643825531006,
      "learning_rate": 2.406967537608868e-05,
      "loss": 0.3776,
      "step": 6550
    },
    {
      "epoch": 1.5581947743467932,
      "grad_norm": 2.168384313583374,
      "learning_rate": 2.403008709422011e-05,
      "loss": 0.2356,
      "step": 6560
    },
    {
      "epoch": 1.5605700712589075,
      "grad_norm": 1.4178522825241089,
      "learning_rate": 2.3990498812351544e-05,
      "loss": 0.1586,
      "step": 6570
    },
    {
      "epoch": 1.5629453681710213,
      "grad_norm": 4.725475311279297,
      "learning_rate": 2.3950910530482978e-05,
      "loss": 0.195,
      "step": 6580
    },
    {
      "epoch": 1.5653206650831355,
      "grad_norm": 6.633472919464111,
      "learning_rate": 2.3911322248614412e-05,
      "loss": 0.3346,
      "step": 6590
    },
    {
      "epoch": 1.5676959619952493,
      "grad_norm": 2.027087688446045,
      "learning_rate": 2.3871733966745842e-05,
      "loss": 0.1979,
      "step": 6600
    },
    {
      "epoch": 1.5700712589073635,
      "grad_norm": 4.734477996826172,
      "learning_rate": 2.3832145684877276e-05,
      "loss": 0.2892,
      "step": 6610
    },
    {
      "epoch": 1.5724465558194773,
      "grad_norm": 3.569859266281128,
      "learning_rate": 2.379255740300871e-05,
      "loss": 0.2224,
      "step": 6620
    },
    {
      "epoch": 1.5748218527315916,
      "grad_norm": 5.183345794677734,
      "learning_rate": 2.375296912114014e-05,
      "loss": 0.3021,
      "step": 6630
    },
    {
      "epoch": 1.5771971496437054,
      "grad_norm": 0.7436785697937012,
      "learning_rate": 2.3713380839271575e-05,
      "loss": 0.2223,
      "step": 6640
    },
    {
      "epoch": 1.5795724465558196,
      "grad_norm": 2.3185105323791504,
      "learning_rate": 2.367379255740301e-05,
      "loss": 0.2381,
      "step": 6650
    },
    {
      "epoch": 1.5819477434679334,
      "grad_norm": 0.6292287111282349,
      "learning_rate": 2.3634204275534443e-05,
      "loss": 0.2301,
      "step": 6660
    },
    {
      "epoch": 1.5843230403800475,
      "grad_norm": 3.054211378097534,
      "learning_rate": 2.3594615993665874e-05,
      "loss": 0.2155,
      "step": 6670
    },
    {
      "epoch": 1.5866983372921615,
      "grad_norm": 2.526115894317627,
      "learning_rate": 2.3555027711797308e-05,
      "loss": 0.2242,
      "step": 6680
    },
    {
      "epoch": 1.5890736342042755,
      "grad_norm": 1.701016902923584,
      "learning_rate": 2.3515439429928742e-05,
      "loss": 0.2096,
      "step": 6690
    },
    {
      "epoch": 1.5914489311163895,
      "grad_norm": 1.5610450506210327,
      "learning_rate": 2.3475851148060173e-05,
      "loss": 0.2648,
      "step": 6700
    },
    {
      "epoch": 1.5938242280285035,
      "grad_norm": 6.689398765563965,
      "learning_rate": 2.3436262866191607e-05,
      "loss": 0.2142,
      "step": 6710
    },
    {
      "epoch": 1.5961995249406176,
      "grad_norm": 3.789536952972412,
      "learning_rate": 2.339667458432304e-05,
      "loss": 0.1418,
      "step": 6720
    },
    {
      "epoch": 1.5985748218527316,
      "grad_norm": 8.111462593078613,
      "learning_rate": 2.3357086302454475e-05,
      "loss": 0.3078,
      "step": 6730
    },
    {
      "epoch": 1.6009501187648456,
      "grad_norm": 1.156406044960022,
      "learning_rate": 2.3317498020585905e-05,
      "loss": 0.298,
      "step": 6740
    },
    {
      "epoch": 1.6033254156769596,
      "grad_norm": 10.366470336914062,
      "learning_rate": 2.327790973871734e-05,
      "loss": 0.3105,
      "step": 6750
    },
    {
      "epoch": 1.6057007125890737,
      "grad_norm": 3.207740306854248,
      "learning_rate": 2.3238321456848773e-05,
      "loss": 0.2246,
      "step": 6760
    },
    {
      "epoch": 1.6080760095011877,
      "grad_norm": 2.2539749145507812,
      "learning_rate": 2.3198733174980204e-05,
      "loss": 0.2276,
      "step": 6770
    },
    {
      "epoch": 1.6104513064133017,
      "grad_norm": 9.241523742675781,
      "learning_rate": 2.3159144893111638e-05,
      "loss": 0.3297,
      "step": 6780
    },
    {
      "epoch": 1.6128266033254157,
      "grad_norm": 6.789071559906006,
      "learning_rate": 2.3119556611243072e-05,
      "loss": 0.2582,
      "step": 6790
    },
    {
      "epoch": 1.6152019002375297,
      "grad_norm": 9.213420867919922,
      "learning_rate": 2.3079968329374506e-05,
      "loss": 0.2963,
      "step": 6800
    },
    {
      "epoch": 1.6175771971496435,
      "grad_norm": 3.7488949298858643,
      "learning_rate": 2.3040380047505937e-05,
      "loss": 0.1989,
      "step": 6810
    },
    {
      "epoch": 1.6199524940617578,
      "grad_norm": 6.03447151184082,
      "learning_rate": 2.300079176563737e-05,
      "loss": 0.2028,
      "step": 6820
    },
    {
      "epoch": 1.6223277909738716,
      "grad_norm": 2.406342029571533,
      "learning_rate": 2.2961203483768805e-05,
      "loss": 0.2862,
      "step": 6830
    },
    {
      "epoch": 1.6247030878859858,
      "grad_norm": 5.686324119567871,
      "learning_rate": 2.292161520190024e-05,
      "loss": 0.2919,
      "step": 6840
    },
    {
      "epoch": 1.6270783847980996,
      "grad_norm": 3.5051066875457764,
      "learning_rate": 2.288202692003167e-05,
      "loss": 0.3189,
      "step": 6850
    },
    {
      "epoch": 1.6294536817102139,
      "grad_norm": 7.061840057373047,
      "learning_rate": 2.2842438638163104e-05,
      "loss": 0.3252,
      "step": 6860
    },
    {
      "epoch": 1.6318289786223277,
      "grad_norm": 5.0837273597717285,
      "learning_rate": 2.2802850356294538e-05,
      "loss": 0.27,
      "step": 6870
    },
    {
      "epoch": 1.634204275534442,
      "grad_norm": 2.22723126411438,
      "learning_rate": 2.276326207442597e-05,
      "loss": 0.238,
      "step": 6880
    },
    {
      "epoch": 1.6365795724465557,
      "grad_norm": 5.332601070404053,
      "learning_rate": 2.2723673792557402e-05,
      "loss": 0.2205,
      "step": 6890
    },
    {
      "epoch": 1.63895486935867,
      "grad_norm": 6.007065773010254,
      "learning_rate": 2.2684085510688836e-05,
      "loss": 0.3102,
      "step": 6900
    },
    {
      "epoch": 1.6413301662707838,
      "grad_norm": 2.611891031265259,
      "learning_rate": 2.264449722882027e-05,
      "loss": 0.2873,
      "step": 6910
    },
    {
      "epoch": 1.643705463182898,
      "grad_norm": 3.3843371868133545,
      "learning_rate": 2.2604908946951704e-05,
      "loss": 0.1847,
      "step": 6920
    },
    {
      "epoch": 1.6460807600950118,
      "grad_norm": 2.65649151802063,
      "learning_rate": 2.2565320665083135e-05,
      "loss": 0.2272,
      "step": 6930
    },
    {
      "epoch": 1.648456057007126,
      "grad_norm": 3.6309289932250977,
      "learning_rate": 2.252573238321457e-05,
      "loss": 0.2432,
      "step": 6940
    },
    {
      "epoch": 1.6508313539192399,
      "grad_norm": 0.9985310435295105,
      "learning_rate": 2.2486144101346003e-05,
      "loss": 0.2572,
      "step": 6950
    },
    {
      "epoch": 1.6532066508313539,
      "grad_norm": 8.737298011779785,
      "learning_rate": 2.2446555819477437e-05,
      "loss": 0.2188,
      "step": 6960
    },
    {
      "epoch": 1.655581947743468,
      "grad_norm": 2.6727473735809326,
      "learning_rate": 2.2406967537608868e-05,
      "loss": 0.2392,
      "step": 6970
    },
    {
      "epoch": 1.657957244655582,
      "grad_norm": 6.521080017089844,
      "learning_rate": 2.2367379255740302e-05,
      "loss": 0.187,
      "step": 6980
    },
    {
      "epoch": 1.660332541567696,
      "grad_norm": 2.920935869216919,
      "learning_rate": 2.2327790973871736e-05,
      "loss": 0.3241,
      "step": 6990
    },
    {
      "epoch": 1.66270783847981,
      "grad_norm": 3.470811605453491,
      "learning_rate": 2.228820269200317e-05,
      "loss": 0.1731,
      "step": 7000
    },
    {
      "epoch": 1.665083135391924,
      "grad_norm": 2.1117305755615234,
      "learning_rate": 2.22486144101346e-05,
      "loss": 0.2172,
      "step": 7010
    },
    {
      "epoch": 1.667458432304038,
      "grad_norm": 3.9716320037841797,
      "learning_rate": 2.2209026128266035e-05,
      "loss": 0.2424,
      "step": 7020
    },
    {
      "epoch": 1.669833729216152,
      "grad_norm": 1.120033860206604,
      "learning_rate": 2.216943784639747e-05,
      "loss": 0.2396,
      "step": 7030
    },
    {
      "epoch": 1.672209026128266,
      "grad_norm": 1.286803126335144,
      "learning_rate": 2.2129849564528903e-05,
      "loss": 0.1607,
      "step": 7040
    },
    {
      "epoch": 1.67458432304038,
      "grad_norm": 1.5607872009277344,
      "learning_rate": 2.2090261282660333e-05,
      "loss": 0.1973,
      "step": 7050
    },
    {
      "epoch": 1.676959619952494,
      "grad_norm": 8.843927383422852,
      "learning_rate": 2.2050673000791767e-05,
      "loss": 0.2663,
      "step": 7060
    },
    {
      "epoch": 1.6793349168646081,
      "grad_norm": 6.693516731262207,
      "learning_rate": 2.20110847189232e-05,
      "loss": 0.2712,
      "step": 7070
    },
    {
      "epoch": 1.6817102137767221,
      "grad_norm": 3.206805467605591,
      "learning_rate": 2.1971496437054635e-05,
      "loss": 0.228,
      "step": 7080
    },
    {
      "epoch": 1.6840855106888362,
      "grad_norm": 3.749276638031006,
      "learning_rate": 2.1931908155186066e-05,
      "loss": 0.1717,
      "step": 7090
    },
    {
      "epoch": 1.68646080760095,
      "grad_norm": 4.219329357147217,
      "learning_rate": 2.18923198733175e-05,
      "loss": 0.171,
      "step": 7100
    },
    {
      "epoch": 1.6888361045130642,
      "grad_norm": 5.295365333557129,
      "learning_rate": 2.1852731591448934e-05,
      "loss": 0.3481,
      "step": 7110
    },
    {
      "epoch": 1.691211401425178,
      "grad_norm": 5.892553329467773,
      "learning_rate": 2.1813143309580365e-05,
      "loss": 0.2375,
      "step": 7120
    },
    {
      "epoch": 1.6935866983372923,
      "grad_norm": 4.999537467956543,
      "learning_rate": 2.17735550277118e-05,
      "loss": 0.2184,
      "step": 7130
    },
    {
      "epoch": 1.695961995249406,
      "grad_norm": 4.121006965637207,
      "learning_rate": 2.1733966745843233e-05,
      "loss": 0.3315,
      "step": 7140
    },
    {
      "epoch": 1.6983372921615203,
      "grad_norm": 2.358672618865967,
      "learning_rate": 2.1694378463974667e-05,
      "loss": 0.2679,
      "step": 7150
    },
    {
      "epoch": 1.700712589073634,
      "grad_norm": 3.8300390243530273,
      "learning_rate": 2.1654790182106098e-05,
      "loss": 0.3316,
      "step": 7160
    },
    {
      "epoch": 1.7030878859857483,
      "grad_norm": 4.256383419036865,
      "learning_rate": 2.161520190023753e-05,
      "loss": 0.2175,
      "step": 7170
    },
    {
      "epoch": 1.7054631828978621,
      "grad_norm": 3.250542402267456,
      "learning_rate": 2.1575613618368966e-05,
      "loss": 0.3743,
      "step": 7180
    },
    {
      "epoch": 1.7078384798099764,
      "grad_norm": 3.736212730407715,
      "learning_rate": 2.1536025336500396e-05,
      "loss": 0.2607,
      "step": 7190
    },
    {
      "epoch": 1.7102137767220902,
      "grad_norm": 3.488800048828125,
      "learning_rate": 2.149643705463183e-05,
      "loss": 0.2401,
      "step": 7200
    },
    {
      "epoch": 1.7125890736342044,
      "grad_norm": 6.938106536865234,
      "learning_rate": 2.1456848772763264e-05,
      "loss": 0.3757,
      "step": 7210
    },
    {
      "epoch": 1.7149643705463182,
      "grad_norm": 2.813478708267212,
      "learning_rate": 2.14172604908947e-05,
      "loss": 0.216,
      "step": 7220
    },
    {
      "epoch": 1.7173396674584323,
      "grad_norm": 1.6450824737548828,
      "learning_rate": 2.137767220902613e-05,
      "loss": 0.2343,
      "step": 7230
    },
    {
      "epoch": 1.7197149643705463,
      "grad_norm": 3.4373743534088135,
      "learning_rate": 2.1338083927157563e-05,
      "loss": 0.2994,
      "step": 7240
    },
    {
      "epoch": 1.7220902612826603,
      "grad_norm": 1.7843353748321533,
      "learning_rate": 2.1298495645288997e-05,
      "loss": 0.3082,
      "step": 7250
    },
    {
      "epoch": 1.7244655581947743,
      "grad_norm": 5.7710747718811035,
      "learning_rate": 2.1258907363420428e-05,
      "loss": 0.2322,
      "step": 7260
    },
    {
      "epoch": 1.7268408551068883,
      "grad_norm": 1.8217854499816895,
      "learning_rate": 2.1219319081551862e-05,
      "loss": 0.2503,
      "step": 7270
    },
    {
      "epoch": 1.7292161520190024,
      "grad_norm": 4.639873027801514,
      "learning_rate": 2.1179730799683296e-05,
      "loss": 0.2596,
      "step": 7280
    },
    {
      "epoch": 1.7315914489311164,
      "grad_norm": 6.4396562576293945,
      "learning_rate": 2.114014251781473e-05,
      "loss": 0.1977,
      "step": 7290
    },
    {
      "epoch": 1.7339667458432304,
      "grad_norm": 2.776458501815796,
      "learning_rate": 2.110055423594616e-05,
      "loss": 0.2781,
      "step": 7300
    },
    {
      "epoch": 1.7363420427553444,
      "grad_norm": 6.370488166809082,
      "learning_rate": 2.1060965954077595e-05,
      "loss": 0.2029,
      "step": 7310
    },
    {
      "epoch": 1.7387173396674585,
      "grad_norm": 2.02001690864563,
      "learning_rate": 2.102137767220903e-05,
      "loss": 0.2607,
      "step": 7320
    },
    {
      "epoch": 1.7410926365795725,
      "grad_norm": 2.1049304008483887,
      "learning_rate": 2.098178939034046e-05,
      "loss": 0.349,
      "step": 7330
    },
    {
      "epoch": 1.7434679334916865,
      "grad_norm": 2.012524366378784,
      "learning_rate": 2.0942201108471893e-05,
      "loss": 0.2315,
      "step": 7340
    },
    {
      "epoch": 1.7458432304038005,
      "grad_norm": 5.056481838226318,
      "learning_rate": 2.0902612826603327e-05,
      "loss": 0.1966,
      "step": 7350
    },
    {
      "epoch": 1.7482185273159145,
      "grad_norm": 4.52935266494751,
      "learning_rate": 2.086302454473476e-05,
      "loss": 0.2168,
      "step": 7360
    },
    {
      "epoch": 1.7505938242280283,
      "grad_norm": 6.736769676208496,
      "learning_rate": 2.0823436262866192e-05,
      "loss": 0.1768,
      "step": 7370
    },
    {
      "epoch": 1.7529691211401426,
      "grad_norm": 6.014269828796387,
      "learning_rate": 2.0783847980997626e-05,
      "loss": 0.2534,
      "step": 7380
    },
    {
      "epoch": 1.7553444180522564,
      "grad_norm": 2.0046591758728027,
      "learning_rate": 2.074425969912906e-05,
      "loss": 0.2495,
      "step": 7390
    },
    {
      "epoch": 1.7577197149643706,
      "grad_norm": 3.642914295196533,
      "learning_rate": 2.070467141726049e-05,
      "loss": 0.1702,
      "step": 7400
    },
    {
      "epoch": 1.7600950118764844,
      "grad_norm": 5.80967903137207,
      "learning_rate": 2.0665083135391925e-05,
      "loss": 0.2561,
      "step": 7410
    },
    {
      "epoch": 1.7624703087885987,
      "grad_norm": 1.224303960800171,
      "learning_rate": 2.062549485352336e-05,
      "loss": 0.1506,
      "step": 7420
    },
    {
      "epoch": 1.7648456057007125,
      "grad_norm": 6.156485080718994,
      "learning_rate": 2.0585906571654793e-05,
      "loss": 0.1961,
      "step": 7430
    },
    {
      "epoch": 1.7672209026128267,
      "grad_norm": 9.408491134643555,
      "learning_rate": 2.0546318289786223e-05,
      "loss": 0.1919,
      "step": 7440
    },
    {
      "epoch": 1.7695961995249405,
      "grad_norm": 4.546750545501709,
      "learning_rate": 2.0506730007917658e-05,
      "loss": 0.3957,
      "step": 7450
    },
    {
      "epoch": 1.7719714964370548,
      "grad_norm": 1.234792947769165,
      "learning_rate": 2.046714172604909e-05,
      "loss": 0.2555,
      "step": 7460
    },
    {
      "epoch": 1.7743467933491686,
      "grad_norm": 3.306380271911621,
      "learning_rate": 2.0427553444180522e-05,
      "loss": 0.1889,
      "step": 7470
    },
    {
      "epoch": 1.7767220902612828,
      "grad_norm": 1.2705215215682983,
      "learning_rate": 2.0387965162311956e-05,
      "loss": 0.2565,
      "step": 7480
    },
    {
      "epoch": 1.7790973871733966,
      "grad_norm": 3.9967596530914307,
      "learning_rate": 2.034837688044339e-05,
      "loss": 0.3144,
      "step": 7490
    },
    {
      "epoch": 1.7814726840855108,
      "grad_norm": 6.199375152587891,
      "learning_rate": 2.0308788598574824e-05,
      "loss": 0.2816,
      "step": 7500
    },
    {
      "epoch": 1.7838479809976246,
      "grad_norm": 2.721428871154785,
      "learning_rate": 2.0269200316706255e-05,
      "loss": 0.2541,
      "step": 7510
    },
    {
      "epoch": 1.7862232779097387,
      "grad_norm": 9.269559860229492,
      "learning_rate": 2.022961203483769e-05,
      "loss": 0.3411,
      "step": 7520
    },
    {
      "epoch": 1.7885985748218527,
      "grad_norm": 4.803077697753906,
      "learning_rate": 2.0190023752969123e-05,
      "loss": 0.2182,
      "step": 7530
    },
    {
      "epoch": 1.7909738717339667,
      "grad_norm": 2.948629140853882,
      "learning_rate": 2.0150435471100554e-05,
      "loss": 0.2889,
      "step": 7540
    },
    {
      "epoch": 1.7933491686460807,
      "grad_norm": 5.818037033081055,
      "learning_rate": 2.0110847189231988e-05,
      "loss": 0.2684,
      "step": 7550
    },
    {
      "epoch": 1.7957244655581948,
      "grad_norm": 2.506024122238159,
      "learning_rate": 2.0071258907363422e-05,
      "loss": 0.1582,
      "step": 7560
    },
    {
      "epoch": 1.7980997624703088,
      "grad_norm": 7.56680154800415,
      "learning_rate": 2.0031670625494856e-05,
      "loss": 0.1991,
      "step": 7570
    },
    {
      "epoch": 1.8004750593824228,
      "grad_norm": 6.389059066772461,
      "learning_rate": 1.9992082343626286e-05,
      "loss": 0.2512,
      "step": 7580
    },
    {
      "epoch": 1.8028503562945368,
      "grad_norm": 6.773447036743164,
      "learning_rate": 1.995249406175772e-05,
      "loss": 0.306,
      "step": 7590
    },
    {
      "epoch": 1.8052256532066508,
      "grad_norm": 3.25467848777771,
      "learning_rate": 1.9912905779889154e-05,
      "loss": 0.1984,
      "step": 7600
    },
    {
      "epoch": 1.8076009501187649,
      "grad_norm": 4.154933452606201,
      "learning_rate": 1.9873317498020585e-05,
      "loss": 0.2478,
      "step": 7610
    },
    {
      "epoch": 1.809976247030879,
      "grad_norm": 3.1424357891082764,
      "learning_rate": 1.983372921615202e-05,
      "loss": 0.2581,
      "step": 7620
    },
    {
      "epoch": 1.812351543942993,
      "grad_norm": 3.30865216255188,
      "learning_rate": 1.9794140934283453e-05,
      "loss": 0.3604,
      "step": 7630
    },
    {
      "epoch": 1.814726840855107,
      "grad_norm": 2.0685787200927734,
      "learning_rate": 1.9754552652414887e-05,
      "loss": 0.2348,
      "step": 7640
    },
    {
      "epoch": 1.817102137767221,
      "grad_norm": 2.44815731048584,
      "learning_rate": 1.9714964370546318e-05,
      "loss": 0.2101,
      "step": 7650
    },
    {
      "epoch": 1.8194774346793348,
      "grad_norm": 4.093263626098633,
      "learning_rate": 1.9675376088677752e-05,
      "loss": 0.1746,
      "step": 7660
    },
    {
      "epoch": 1.821852731591449,
      "grad_norm": 2.1568026542663574,
      "learning_rate": 1.9635787806809186e-05,
      "loss": 0.2486,
      "step": 7670
    },
    {
      "epoch": 1.8242280285035628,
      "grad_norm": 7.7324018478393555,
      "learning_rate": 1.9596199524940617e-05,
      "loss": 0.3171,
      "step": 7680
    },
    {
      "epoch": 1.826603325415677,
      "grad_norm": 3.889009714126587,
      "learning_rate": 1.955661124307205e-05,
      "loss": 0.3265,
      "step": 7690
    },
    {
      "epoch": 1.8289786223277908,
      "grad_norm": 2.9035305976867676,
      "learning_rate": 1.9517022961203485e-05,
      "loss": 0.2778,
      "step": 7700
    },
    {
      "epoch": 1.831353919239905,
      "grad_norm": 2.075197219848633,
      "learning_rate": 1.947743467933492e-05,
      "loss": 0.1909,
      "step": 7710
    },
    {
      "epoch": 1.833729216152019,
      "grad_norm": 1.505395770072937,
      "learning_rate": 1.943784639746635e-05,
      "loss": 0.2933,
      "step": 7720
    },
    {
      "epoch": 1.8361045130641331,
      "grad_norm": 3.285396099090576,
      "learning_rate": 1.9398258115597783e-05,
      "loss": 0.1997,
      "step": 7730
    },
    {
      "epoch": 1.838479809976247,
      "grad_norm": 2.8084843158721924,
      "learning_rate": 1.9358669833729217e-05,
      "loss": 0.2804,
      "step": 7740
    },
    {
      "epoch": 1.8408551068883612,
      "grad_norm": 1.9831221103668213,
      "learning_rate": 1.9319081551860648e-05,
      "loss": 0.2402,
      "step": 7750
    },
    {
      "epoch": 1.843230403800475,
      "grad_norm": 3.6506617069244385,
      "learning_rate": 1.9279493269992082e-05,
      "loss": 0.2071,
      "step": 7760
    },
    {
      "epoch": 1.8456057007125892,
      "grad_norm": 1.168588638305664,
      "learning_rate": 1.9239904988123516e-05,
      "loss": 0.2032,
      "step": 7770
    },
    {
      "epoch": 1.847980997624703,
      "grad_norm": 2.831160068511963,
      "learning_rate": 1.920031670625495e-05,
      "loss": 0.1684,
      "step": 7780
    },
    {
      "epoch": 1.850356294536817,
      "grad_norm": 3.6523759365081787,
      "learning_rate": 1.916072842438638e-05,
      "loss": 0.1903,
      "step": 7790
    },
    {
      "epoch": 1.852731591448931,
      "grad_norm": 2.870905876159668,
      "learning_rate": 1.9121140142517815e-05,
      "loss": 0.186,
      "step": 7800
    },
    {
      "epoch": 1.855106888361045,
      "grad_norm": 2.862297296524048,
      "learning_rate": 1.908155186064925e-05,
      "loss": 0.2084,
      "step": 7810
    },
    {
      "epoch": 1.8574821852731591,
      "grad_norm": 4.197899341583252,
      "learning_rate": 1.904196357878068e-05,
      "loss": 0.2864,
      "step": 7820
    },
    {
      "epoch": 1.8598574821852731,
      "grad_norm": 6.917893409729004,
      "learning_rate": 1.9002375296912114e-05,
      "loss": 0.2597,
      "step": 7830
    },
    {
      "epoch": 1.8622327790973872,
      "grad_norm": 4.913660526275635,
      "learning_rate": 1.8962787015043548e-05,
      "loss": 0.2221,
      "step": 7840
    },
    {
      "epoch": 1.8646080760095012,
      "grad_norm": 4.702284812927246,
      "learning_rate": 1.892319873317498e-05,
      "loss": 0.2735,
      "step": 7850
    },
    {
      "epoch": 1.8669833729216152,
      "grad_norm": 7.021848678588867,
      "learning_rate": 1.8883610451306412e-05,
      "loss": 0.3184,
      "step": 7860
    },
    {
      "epoch": 1.8693586698337292,
      "grad_norm": 2.7446177005767822,
      "learning_rate": 1.8844022169437846e-05,
      "loss": 0.2348,
      "step": 7870
    },
    {
      "epoch": 1.8717339667458432,
      "grad_norm": 4.613287448883057,
      "learning_rate": 1.880443388756928e-05,
      "loss": 0.2593,
      "step": 7880
    },
    {
      "epoch": 1.8741092636579573,
      "grad_norm": 5.463856220245361,
      "learning_rate": 1.876484560570071e-05,
      "loss": 0.2382,
      "step": 7890
    },
    {
      "epoch": 1.8764845605700713,
      "grad_norm": 2.7375550270080566,
      "learning_rate": 1.8725257323832145e-05,
      "loss": 0.1519,
      "step": 7900
    },
    {
      "epoch": 1.8788598574821853,
      "grad_norm": 5.930420398712158,
      "learning_rate": 1.868566904196358e-05,
      "loss": 0.2797,
      "step": 7910
    },
    {
      "epoch": 1.8812351543942993,
      "grad_norm": 6.534940242767334,
      "learning_rate": 1.8646080760095013e-05,
      "loss": 0.2649,
      "step": 7920
    },
    {
      "epoch": 1.8836104513064131,
      "grad_norm": 1.5143444538116455,
      "learning_rate": 1.8606492478226444e-05,
      "loss": 0.2107,
      "step": 7930
    },
    {
      "epoch": 1.8859857482185274,
      "grad_norm": 8.257457733154297,
      "learning_rate": 1.8566904196357878e-05,
      "loss": 0.2572,
      "step": 7940
    },
    {
      "epoch": 1.8883610451306412,
      "grad_norm": 5.323490619659424,
      "learning_rate": 1.8527315914489312e-05,
      "loss": 0.3752,
      "step": 7950
    },
    {
      "epoch": 1.8907363420427554,
      "grad_norm": 4.373366355895996,
      "learning_rate": 1.8487727632620742e-05,
      "loss": 0.2252,
      "step": 7960
    },
    {
      "epoch": 1.8931116389548692,
      "grad_norm": 6.7180914878845215,
      "learning_rate": 1.8448139350752177e-05,
      "loss": 0.1757,
      "step": 7970
    },
    {
      "epoch": 1.8954869358669835,
      "grad_norm": 5.044495582580566,
      "learning_rate": 1.840855106888361e-05,
      "loss": 0.21,
      "step": 7980
    },
    {
      "epoch": 1.8978622327790973,
      "grad_norm": 3.337050437927246,
      "learning_rate": 1.8368962787015045e-05,
      "loss": 0.3387,
      "step": 7990
    },
    {
      "epoch": 1.9002375296912115,
      "grad_norm": 4.888553142547607,
      "learning_rate": 1.8329374505146475e-05,
      "loss": 0.1923,
      "step": 8000
    },
    {
      "epoch": 1.9026128266033253,
      "grad_norm": 3.7839243412017822,
      "learning_rate": 1.828978622327791e-05,
      "loss": 0.2519,
      "step": 8010
    },
    {
      "epoch": 1.9049881235154396,
      "grad_norm": 3.628077507019043,
      "learning_rate": 1.8250197941409343e-05,
      "loss": 0.2179,
      "step": 8020
    },
    {
      "epoch": 1.9073634204275534,
      "grad_norm": 4.6443915367126465,
      "learning_rate": 1.8210609659540774e-05,
      "loss": 0.2879,
      "step": 8030
    },
    {
      "epoch": 1.9097387173396676,
      "grad_norm": 4.092402935028076,
      "learning_rate": 1.8171021377672208e-05,
      "loss": 0.2199,
      "step": 8040
    },
    {
      "epoch": 1.9121140142517814,
      "grad_norm": 2.614985227584839,
      "learning_rate": 1.8131433095803642e-05,
      "loss": 0.2761,
      "step": 8050
    },
    {
      "epoch": 1.9144893111638956,
      "grad_norm": 8.182034492492676,
      "learning_rate": 1.8091844813935076e-05,
      "loss": 0.3439,
      "step": 8060
    },
    {
      "epoch": 1.9168646080760094,
      "grad_norm": 1.1840242147445679,
      "learning_rate": 1.8052256532066507e-05,
      "loss": 0.2418,
      "step": 8070
    },
    {
      "epoch": 1.9192399049881235,
      "grad_norm": 6.779789924621582,
      "learning_rate": 1.801266825019794e-05,
      "loss": 0.3284,
      "step": 8080
    },
    {
      "epoch": 1.9216152019002375,
      "grad_norm": 1.5952585935592651,
      "learning_rate": 1.7973079968329375e-05,
      "loss": 0.1871,
      "step": 8090
    },
    {
      "epoch": 1.9239904988123515,
      "grad_norm": 4.594501972198486,
      "learning_rate": 1.793349168646081e-05,
      "loss": 0.2206,
      "step": 8100
    },
    {
      "epoch": 1.9263657957244655,
      "grad_norm": 2.308248281478882,
      "learning_rate": 1.789390340459224e-05,
      "loss": 0.2377,
      "step": 8110
    },
    {
      "epoch": 1.9287410926365796,
      "grad_norm": 0.9017259478569031,
      "learning_rate": 1.7854315122723674e-05,
      "loss": 0.2784,
      "step": 8120
    },
    {
      "epoch": 1.9311163895486936,
      "grad_norm": 3.304500102996826,
      "learning_rate": 1.7814726840855108e-05,
      "loss": 0.2384,
      "step": 8130
    },
    {
      "epoch": 1.9334916864608076,
      "grad_norm": 6.171999931335449,
      "learning_rate": 1.777513855898654e-05,
      "loss": 0.2209,
      "step": 8140
    },
    {
      "epoch": 1.9358669833729216,
      "grad_norm": 0.8342850208282471,
      "learning_rate": 1.7735550277117972e-05,
      "loss": 0.2172,
      "step": 8150
    },
    {
      "epoch": 1.9382422802850356,
      "grad_norm": 3.815030574798584,
      "learning_rate": 1.7695961995249406e-05,
      "loss": 0.1887,
      "step": 8160
    },
    {
      "epoch": 1.9406175771971497,
      "grad_norm": 5.462679386138916,
      "learning_rate": 1.765637371338084e-05,
      "loss": 0.2498,
      "step": 8170
    },
    {
      "epoch": 1.9429928741092637,
      "grad_norm": 4.528395652770996,
      "learning_rate": 1.7616785431512274e-05,
      "loss": 0.2048,
      "step": 8180
    },
    {
      "epoch": 1.9453681710213777,
      "grad_norm": 2.181781053543091,
      "learning_rate": 1.7577197149643705e-05,
      "loss": 0.1844,
      "step": 8190
    },
    {
      "epoch": 1.9477434679334917,
      "grad_norm": 3.3965537548065186,
      "learning_rate": 1.753760886777514e-05,
      "loss": 0.2555,
      "step": 8200
    },
    {
      "epoch": 1.9501187648456058,
      "grad_norm": 5.147976875305176,
      "learning_rate": 1.7498020585906573e-05,
      "loss": 0.2111,
      "step": 8210
    },
    {
      "epoch": 1.9524940617577196,
      "grad_norm": 4.38770866394043,
      "learning_rate": 1.7458432304038007e-05,
      "loss": 0.2759,
      "step": 8220
    },
    {
      "epoch": 1.9548693586698338,
      "grad_norm": 7.358724117279053,
      "learning_rate": 1.7418844022169438e-05,
      "loss": 0.299,
      "step": 8230
    },
    {
      "epoch": 1.9572446555819476,
      "grad_norm": 5.124621391296387,
      "learning_rate": 1.7379255740300872e-05,
      "loss": 0.2598,
      "step": 8240
    },
    {
      "epoch": 1.9596199524940618,
      "grad_norm": 1.4213274717330933,
      "learning_rate": 1.7339667458432306e-05,
      "loss": 0.2033,
      "step": 8250
    },
    {
      "epoch": 1.9619952494061756,
      "grad_norm": 2.66567063331604,
      "learning_rate": 1.730007917656374e-05,
      "loss": 0.2134,
      "step": 8260
    },
    {
      "epoch": 1.96437054631829,
      "grad_norm": 6.922293663024902,
      "learning_rate": 1.726049089469517e-05,
      "loss": 0.2428,
      "step": 8270
    },
    {
      "epoch": 1.9667458432304037,
      "grad_norm": 3.6282567977905273,
      "learning_rate": 1.7220902612826605e-05,
      "loss": 0.2205,
      "step": 8280
    },
    {
      "epoch": 1.969121140142518,
      "grad_norm": 6.087509632110596,
      "learning_rate": 1.718131433095804e-05,
      "loss": 0.2774,
      "step": 8290
    },
    {
      "epoch": 1.9714964370546317,
      "grad_norm": 3.8241074085235596,
      "learning_rate": 1.7141726049089473e-05,
      "loss": 0.2817,
      "step": 8300
    },
    {
      "epoch": 1.973871733966746,
      "grad_norm": 5.324867248535156,
      "learning_rate": 1.7102137767220903e-05,
      "loss": 0.3041,
      "step": 8310
    },
    {
      "epoch": 1.9762470308788598,
      "grad_norm": 3.563133478164673,
      "learning_rate": 1.7062549485352337e-05,
      "loss": 0.207,
      "step": 8320
    },
    {
      "epoch": 1.978622327790974,
      "grad_norm": 3.514974594116211,
      "learning_rate": 1.702296120348377e-05,
      "loss": 0.2386,
      "step": 8330
    },
    {
      "epoch": 1.9809976247030878,
      "grad_norm": 3.9862844944000244,
      "learning_rate": 1.6983372921615205e-05,
      "loss": 0.1938,
      "step": 8340
    },
    {
      "epoch": 1.9833729216152018,
      "grad_norm": 7.257059574127197,
      "learning_rate": 1.6943784639746636e-05,
      "loss": 0.2728,
      "step": 8350
    },
    {
      "epoch": 1.9857482185273159,
      "grad_norm": 4.631311416625977,
      "learning_rate": 1.690419635787807e-05,
      "loss": 0.2649,
      "step": 8360
    },
    {
      "epoch": 1.98812351543943,
      "grad_norm": 1.908205270767212,
      "learning_rate": 1.6864608076009504e-05,
      "loss": 0.2373,
      "step": 8370
    },
    {
      "epoch": 1.990498812351544,
      "grad_norm": 1.0021679401397705,
      "learning_rate": 1.6825019794140935e-05,
      "loss": 0.1838,
      "step": 8380
    },
    {
      "epoch": 1.992874109263658,
      "grad_norm": 1.4156218767166138,
      "learning_rate": 1.678543151227237e-05,
      "loss": 0.2244,
      "step": 8390
    },
    {
      "epoch": 1.995249406175772,
      "grad_norm": 4.203983306884766,
      "learning_rate": 1.6745843230403803e-05,
      "loss": 0.2052,
      "step": 8400
    },
    {
      "epoch": 1.997624703087886,
      "grad_norm": 7.206220626831055,
      "learning_rate": 1.6706254948535237e-05,
      "loss": 0.2817,
      "step": 8410
    },
    {
      "epoch": 2.0,
      "grad_norm": 8.675248146057129,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.2726,
      "step": 8420
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.29142025113105774,
      "eval_runtime": 51.2544,
      "eval_samples_per_second": 17.013,
      "eval_steps_per_second": 1.073,
      "step": 8420
    },
    {
      "epoch": 2.002375296912114,
      "grad_norm": 4.155923366546631,
      "learning_rate": 1.66270783847981e-05,
      "loss": 0.2811,
      "step": 8430
    },
    {
      "epoch": 2.004750593824228,
      "grad_norm": 3.970667600631714,
      "learning_rate": 1.6587490102929536e-05,
      "loss": 0.3292,
      "step": 8440
    },
    {
      "epoch": 2.007125890736342,
      "grad_norm": 3.6577019691467285,
      "learning_rate": 1.6547901821060966e-05,
      "loss": 0.2237,
      "step": 8450
    },
    {
      "epoch": 2.009501187648456,
      "grad_norm": 1.629809021949768,
      "learning_rate": 1.65083135391924e-05,
      "loss": 0.2999,
      "step": 8460
    },
    {
      "epoch": 2.01187648456057,
      "grad_norm": 3.3056554794311523,
      "learning_rate": 1.6468725257323834e-05,
      "loss": 0.1949,
      "step": 8470
    },
    {
      "epoch": 2.014251781472684,
      "grad_norm": 8.23547649383545,
      "learning_rate": 1.6429136975455268e-05,
      "loss": 0.196,
      "step": 8480
    },
    {
      "epoch": 2.016627078384798,
      "grad_norm": 1.654195785522461,
      "learning_rate": 1.63895486935867e-05,
      "loss": 0.1922,
      "step": 8490
    },
    {
      "epoch": 2.019002375296912,
      "grad_norm": 5.044126510620117,
      "learning_rate": 1.6349960411718133e-05,
      "loss": 0.2426,
      "step": 8500
    },
    {
      "epoch": 2.021377672209026,
      "grad_norm": 2.16266131401062,
      "learning_rate": 1.6310372129849567e-05,
      "loss": 0.3022,
      "step": 8510
    },
    {
      "epoch": 2.02375296912114,
      "grad_norm": 5.233140468597412,
      "learning_rate": 1.6270783847980998e-05,
      "loss": 0.1965,
      "step": 8520
    },
    {
      "epoch": 2.026128266033254,
      "grad_norm": 5.679583549499512,
      "learning_rate": 1.623119556611243e-05,
      "loss": 0.2645,
      "step": 8530
    },
    {
      "epoch": 2.0285035629453683,
      "grad_norm": 6.022873401641846,
      "learning_rate": 1.6191607284243866e-05,
      "loss": 0.2244,
      "step": 8540
    },
    {
      "epoch": 2.030878859857482,
      "grad_norm": 7.2052903175354,
      "learning_rate": 1.61520190023753e-05,
      "loss": 0.2486,
      "step": 8550
    },
    {
      "epoch": 2.0332541567695963,
      "grad_norm": 3.8192801475524902,
      "learning_rate": 1.611243072050673e-05,
      "loss": 0.2883,
      "step": 8560
    },
    {
      "epoch": 2.03562945368171,
      "grad_norm": 2.9005401134490967,
      "learning_rate": 1.6072842438638164e-05,
      "loss": 0.2596,
      "step": 8570
    },
    {
      "epoch": 2.0380047505938244,
      "grad_norm": 3.494047164916992,
      "learning_rate": 1.60332541567696e-05,
      "loss": 0.216,
      "step": 8580
    },
    {
      "epoch": 2.040380047505938,
      "grad_norm": 5.594691753387451,
      "learning_rate": 1.599366587490103e-05,
      "loss": 0.2007,
      "step": 8590
    },
    {
      "epoch": 2.0427553444180524,
      "grad_norm": 5.080216884613037,
      "learning_rate": 1.5954077593032463e-05,
      "loss": 0.2929,
      "step": 8600
    },
    {
      "epoch": 2.045130641330166,
      "grad_norm": 3.2801458835601807,
      "learning_rate": 1.5914489311163897e-05,
      "loss": 0.2285,
      "step": 8610
    },
    {
      "epoch": 2.0475059382422804,
      "grad_norm": 0.6281346678733826,
      "learning_rate": 1.587490102929533e-05,
      "loss": 0.166,
      "step": 8620
    },
    {
      "epoch": 2.0498812351543942,
      "grad_norm": 3.4388020038604736,
      "learning_rate": 1.5835312747426762e-05,
      "loss": 0.2316,
      "step": 8630
    },
    {
      "epoch": 2.0522565320665085,
      "grad_norm": 3.707766056060791,
      "learning_rate": 1.5795724465558196e-05,
      "loss": 0.275,
      "step": 8640
    },
    {
      "epoch": 2.0546318289786223,
      "grad_norm": 2.846259832382202,
      "learning_rate": 1.575613618368963e-05,
      "loss": 0.1909,
      "step": 8650
    },
    {
      "epoch": 2.0570071258907365,
      "grad_norm": 6.165411949157715,
      "learning_rate": 1.571654790182106e-05,
      "loss": 0.2309,
      "step": 8660
    },
    {
      "epoch": 2.0593824228028503,
      "grad_norm": 6.057371139526367,
      "learning_rate": 1.5676959619952495e-05,
      "loss": 0.1892,
      "step": 8670
    },
    {
      "epoch": 2.0617577197149646,
      "grad_norm": 6.349721908569336,
      "learning_rate": 1.563737133808393e-05,
      "loss": 0.1881,
      "step": 8680
    },
    {
      "epoch": 2.0641330166270784,
      "grad_norm": 6.030679702758789,
      "learning_rate": 1.5597783056215363e-05,
      "loss": 0.2849,
      "step": 8690
    },
    {
      "epoch": 2.0665083135391926,
      "grad_norm": 4.1475510597229,
      "learning_rate": 1.5558194774346793e-05,
      "loss": 0.2053,
      "step": 8700
    },
    {
      "epoch": 2.0688836104513064,
      "grad_norm": 3.98050594329834,
      "learning_rate": 1.5518606492478227e-05,
      "loss": 0.3121,
      "step": 8710
    },
    {
      "epoch": 2.07125890736342,
      "grad_norm": 4.885842323303223,
      "learning_rate": 1.547901821060966e-05,
      "loss": 0.149,
      "step": 8720
    },
    {
      "epoch": 2.0736342042755345,
      "grad_norm": 6.462407112121582,
      "learning_rate": 1.5439429928741092e-05,
      "loss": 0.1754,
      "step": 8730
    },
    {
      "epoch": 2.0760095011876483,
      "grad_norm": 4.753749370574951,
      "learning_rate": 1.5399841646872526e-05,
      "loss": 0.3188,
      "step": 8740
    },
    {
      "epoch": 2.0783847980997625,
      "grad_norm": 2.8315649032592773,
      "learning_rate": 1.536025336500396e-05,
      "loss": 0.3138,
      "step": 8750
    },
    {
      "epoch": 2.0807600950118763,
      "grad_norm": 10.999190330505371,
      "learning_rate": 1.5320665083135394e-05,
      "loss": 0.3095,
      "step": 8760
    },
    {
      "epoch": 2.0831353919239906,
      "grad_norm": 4.43978214263916,
      "learning_rate": 1.5281076801266825e-05,
      "loss": 0.2609,
      "step": 8770
    },
    {
      "epoch": 2.0855106888361044,
      "grad_norm": 8.606493949890137,
      "learning_rate": 1.5241488519398259e-05,
      "loss": 0.282,
      "step": 8780
    },
    {
      "epoch": 2.0878859857482186,
      "grad_norm": 6.476140022277832,
      "learning_rate": 1.5201900237529693e-05,
      "loss": 0.3371,
      "step": 8790
    },
    {
      "epoch": 2.0902612826603324,
      "grad_norm": 2.2042641639709473,
      "learning_rate": 1.5162311955661124e-05,
      "loss": 0.2739,
      "step": 8800
    },
    {
      "epoch": 2.0926365795724466,
      "grad_norm": 3.41548490524292,
      "learning_rate": 1.5122723673792558e-05,
      "loss": 0.1945,
      "step": 8810
    },
    {
      "epoch": 2.0950118764845604,
      "grad_norm": 4.710055828094482,
      "learning_rate": 1.5083135391923992e-05,
      "loss": 0.2352,
      "step": 8820
    },
    {
      "epoch": 2.0973871733966747,
      "grad_norm": 3.476792573928833,
      "learning_rate": 1.5043547110055426e-05,
      "loss": 0.2818,
      "step": 8830
    },
    {
      "epoch": 2.0997624703087885,
      "grad_norm": 3.59856915473938,
      "learning_rate": 1.5003958828186856e-05,
      "loss": 0.2385,
      "step": 8840
    },
    {
      "epoch": 2.1021377672209027,
      "grad_norm": 4.40670108795166,
      "learning_rate": 1.496437054631829e-05,
      "loss": 0.2668,
      "step": 8850
    },
    {
      "epoch": 2.1045130641330165,
      "grad_norm": 6.658414363861084,
      "learning_rate": 1.4924782264449724e-05,
      "loss": 0.2065,
      "step": 8860
    },
    {
      "epoch": 2.1068883610451308,
      "grad_norm": 3.0075490474700928,
      "learning_rate": 1.4885193982581155e-05,
      "loss": 0.3034,
      "step": 8870
    },
    {
      "epoch": 2.1092636579572446,
      "grad_norm": 4.755126476287842,
      "learning_rate": 1.4845605700712589e-05,
      "loss": 0.2183,
      "step": 8880
    },
    {
      "epoch": 2.111638954869359,
      "grad_norm": 3.902697801589966,
      "learning_rate": 1.4806017418844023e-05,
      "loss": 0.1804,
      "step": 8890
    },
    {
      "epoch": 2.1140142517814726,
      "grad_norm": 2.6655309200286865,
      "learning_rate": 1.4766429136975457e-05,
      "loss": 0.1736,
      "step": 8900
    },
    {
      "epoch": 2.116389548693587,
      "grad_norm": 6.730266094207764,
      "learning_rate": 1.4726840855106888e-05,
      "loss": 0.224,
      "step": 8910
    },
    {
      "epoch": 2.1187648456057007,
      "grad_norm": 1.8975952863693237,
      "learning_rate": 1.4687252573238322e-05,
      "loss": 0.2586,
      "step": 8920
    },
    {
      "epoch": 2.121140142517815,
      "grad_norm": 3.0889668464660645,
      "learning_rate": 1.4647664291369756e-05,
      "loss": 0.1983,
      "step": 8930
    },
    {
      "epoch": 2.1235154394299287,
      "grad_norm": 3.906947612762451,
      "learning_rate": 1.4608076009501186e-05,
      "loss": 0.2609,
      "step": 8940
    },
    {
      "epoch": 2.125890736342043,
      "grad_norm": 4.177544593811035,
      "learning_rate": 1.456848772763262e-05,
      "loss": 0.3077,
      "step": 8950
    },
    {
      "epoch": 2.1282660332541568,
      "grad_norm": 2.873918294906616,
      "learning_rate": 1.4528899445764055e-05,
      "loss": 0.2065,
      "step": 8960
    },
    {
      "epoch": 2.130641330166271,
      "grad_norm": 2.666425943374634,
      "learning_rate": 1.4489311163895489e-05,
      "loss": 0.2598,
      "step": 8970
    },
    {
      "epoch": 2.133016627078385,
      "grad_norm": 2.28790020942688,
      "learning_rate": 1.444972288202692e-05,
      "loss": 0.1925,
      "step": 8980
    },
    {
      "epoch": 2.1353919239904986,
      "grad_norm": 0.6028261780738831,
      "learning_rate": 1.4410134600158353e-05,
      "loss": 0.2935,
      "step": 8990
    },
    {
      "epoch": 2.137767220902613,
      "grad_norm": 1.074284315109253,
      "learning_rate": 1.4370546318289787e-05,
      "loss": 0.2668,
      "step": 9000
    },
    {
      "epoch": 2.1401425178147266,
      "grad_norm": 4.88573694229126,
      "learning_rate": 1.4330958036421218e-05,
      "loss": 0.2386,
      "step": 9010
    },
    {
      "epoch": 2.142517814726841,
      "grad_norm": 3.8650519847869873,
      "learning_rate": 1.4291369754552652e-05,
      "loss": 0.1782,
      "step": 9020
    },
    {
      "epoch": 2.1448931116389547,
      "grad_norm": 3.9599273204803467,
      "learning_rate": 1.4251781472684086e-05,
      "loss": 0.1559,
      "step": 9030
    },
    {
      "epoch": 2.147268408551069,
      "grad_norm": 5.681149005889893,
      "learning_rate": 1.421219319081552e-05,
      "loss": 0.2419,
      "step": 9040
    },
    {
      "epoch": 2.1496437054631827,
      "grad_norm": 3.33866548538208,
      "learning_rate": 1.417260490894695e-05,
      "loss": 0.2481,
      "step": 9050
    },
    {
      "epoch": 2.152019002375297,
      "grad_norm": 6.5915422439575195,
      "learning_rate": 1.4133016627078385e-05,
      "loss": 0.1871,
      "step": 9060
    },
    {
      "epoch": 2.1543942992874108,
      "grad_norm": 5.314243793487549,
      "learning_rate": 1.4093428345209819e-05,
      "loss": 0.2317,
      "step": 9070
    },
    {
      "epoch": 2.156769596199525,
      "grad_norm": 4.416479587554932,
      "learning_rate": 1.4053840063341251e-05,
      "loss": 0.2008,
      "step": 9080
    },
    {
      "epoch": 2.159144893111639,
      "grad_norm": 2.8875794410705566,
      "learning_rate": 1.4014251781472683e-05,
      "loss": 0.2645,
      "step": 9090
    },
    {
      "epoch": 2.161520190023753,
      "grad_norm": 3.982365608215332,
      "learning_rate": 1.3974663499604118e-05,
      "loss": 0.2638,
      "step": 9100
    },
    {
      "epoch": 2.163895486935867,
      "grad_norm": 4.80404806137085,
      "learning_rate": 1.3935075217735552e-05,
      "loss": 0.2849,
      "step": 9110
    },
    {
      "epoch": 2.166270783847981,
      "grad_norm": 3.825519323348999,
      "learning_rate": 1.3895486935866984e-05,
      "loss": 0.3471,
      "step": 9120
    },
    {
      "epoch": 2.168646080760095,
      "grad_norm": 5.239891529083252,
      "learning_rate": 1.3855898653998416e-05,
      "loss": 0.2773,
      "step": 9130
    },
    {
      "epoch": 2.171021377672209,
      "grad_norm": 7.351325035095215,
      "learning_rate": 1.381631037212985e-05,
      "loss": 0.2955,
      "step": 9140
    },
    {
      "epoch": 2.173396674584323,
      "grad_norm": 4.4234700202941895,
      "learning_rate": 1.3776722090261283e-05,
      "loss": 0.2281,
      "step": 9150
    },
    {
      "epoch": 2.175771971496437,
      "grad_norm": 11.287006378173828,
      "learning_rate": 1.3737133808392717e-05,
      "loss": 0.2536,
      "step": 9160
    },
    {
      "epoch": 2.178147268408551,
      "grad_norm": 4.2519989013671875,
      "learning_rate": 1.3697545526524149e-05,
      "loss": 0.3018,
      "step": 9170
    },
    {
      "epoch": 2.1805225653206652,
      "grad_norm": 10.395190238952637,
      "learning_rate": 1.3657957244655583e-05,
      "loss": 0.2854,
      "step": 9180
    },
    {
      "epoch": 2.182897862232779,
      "grad_norm": 2.237382411956787,
      "learning_rate": 1.3618368962787015e-05,
      "loss": 0.2126,
      "step": 9190
    },
    {
      "epoch": 2.1852731591448933,
      "grad_norm": 6.599295139312744,
      "learning_rate": 1.357878068091845e-05,
      "loss": 0.2246,
      "step": 9200
    },
    {
      "epoch": 2.187648456057007,
      "grad_norm": 4.315868854522705,
      "learning_rate": 1.3539192399049882e-05,
      "loss": 0.2464,
      "step": 9210
    },
    {
      "epoch": 2.1900237529691213,
      "grad_norm": 2.678330183029175,
      "learning_rate": 1.3499604117181314e-05,
      "loss": 0.2363,
      "step": 9220
    },
    {
      "epoch": 2.192399049881235,
      "grad_norm": 2.0136160850524902,
      "learning_rate": 1.3460015835312748e-05,
      "loss": 0.1733,
      "step": 9230
    },
    {
      "epoch": 2.1947743467933494,
      "grad_norm": 2.7251110076904297,
      "learning_rate": 1.3420427553444182e-05,
      "loss": 0.2573,
      "step": 9240
    },
    {
      "epoch": 2.197149643705463,
      "grad_norm": 6.215156555175781,
      "learning_rate": 1.3380839271575616e-05,
      "loss": 0.2033,
      "step": 9250
    },
    {
      "epoch": 2.199524940617577,
      "grad_norm": 3.572815418243408,
      "learning_rate": 1.3341250989707047e-05,
      "loss": 0.3242,
      "step": 9260
    },
    {
      "epoch": 2.201900237529691,
      "grad_norm": 5.009123802185059,
      "learning_rate": 1.3301662707838481e-05,
      "loss": 0.2311,
      "step": 9270
    },
    {
      "epoch": 2.204275534441805,
      "grad_norm": 7.3423380851745605,
      "learning_rate": 1.3262074425969915e-05,
      "loss": 0.2987,
      "step": 9280
    },
    {
      "epoch": 2.2066508313539193,
      "grad_norm": 3.8988776206970215,
      "learning_rate": 1.3222486144101346e-05,
      "loss": 0.2992,
      "step": 9290
    },
    {
      "epoch": 2.209026128266033,
      "grad_norm": 5.447833061218262,
      "learning_rate": 1.318289786223278e-05,
      "loss": 0.2603,
      "step": 9300
    },
    {
      "epoch": 2.2114014251781473,
      "grad_norm": 2.429558277130127,
      "learning_rate": 1.3143309580364214e-05,
      "loss": 0.1759,
      "step": 9310
    },
    {
      "epoch": 2.213776722090261,
      "grad_norm": 1.5842326879501343,
      "learning_rate": 1.3103721298495648e-05,
      "loss": 0.1987,
      "step": 9320
    },
    {
      "epoch": 2.2161520190023754,
      "grad_norm": 6.786671161651611,
      "learning_rate": 1.3064133016627078e-05,
      "loss": 0.189,
      "step": 9330
    },
    {
      "epoch": 2.218527315914489,
      "grad_norm": 2.6729791164398193,
      "learning_rate": 1.3024544734758512e-05,
      "loss": 0.252,
      "step": 9340
    },
    {
      "epoch": 2.2209026128266034,
      "grad_norm": 7.842126369476318,
      "learning_rate": 1.2984956452889946e-05,
      "loss": 0.1596,
      "step": 9350
    },
    {
      "epoch": 2.223277909738717,
      "grad_norm": 5.553077697753906,
      "learning_rate": 1.2945368171021377e-05,
      "loss": 0.2036,
      "step": 9360
    },
    {
      "epoch": 2.2256532066508314,
      "grad_norm": 4.170000076293945,
      "learning_rate": 1.2905779889152811e-05,
      "loss": 0.2656,
      "step": 9370
    },
    {
      "epoch": 2.2280285035629452,
      "grad_norm": 6.749270439147949,
      "learning_rate": 1.2866191607284245e-05,
      "loss": 0.1228,
      "step": 9380
    },
    {
      "epoch": 2.2304038004750595,
      "grad_norm": 7.802606105804443,
      "learning_rate": 1.2826603325415679e-05,
      "loss": 0.1795,
      "step": 9390
    },
    {
      "epoch": 2.2327790973871733,
      "grad_norm": 2.8421380519866943,
      "learning_rate": 1.278701504354711e-05,
      "loss": 0.2366,
      "step": 9400
    },
    {
      "epoch": 2.2351543942992875,
      "grad_norm": 9.116815567016602,
      "learning_rate": 1.2747426761678544e-05,
      "loss": 0.2159,
      "step": 9410
    },
    {
      "epoch": 2.2375296912114013,
      "grad_norm": 13.776389122009277,
      "learning_rate": 1.2707838479809978e-05,
      "loss": 0.2627,
      "step": 9420
    },
    {
      "epoch": 2.2399049881235156,
      "grad_norm": 8.49841594696045,
      "learning_rate": 1.2668250197941408e-05,
      "loss": 0.2214,
      "step": 9430
    },
    {
      "epoch": 2.2422802850356294,
      "grad_norm": 2.4081501960754395,
      "learning_rate": 1.2628661916072843e-05,
      "loss": 0.354,
      "step": 9440
    },
    {
      "epoch": 2.2446555819477436,
      "grad_norm": 2.7460758686065674,
      "learning_rate": 1.2589073634204277e-05,
      "loss": 0.1611,
      "step": 9450
    },
    {
      "epoch": 2.2470308788598574,
      "grad_norm": 5.961676120758057,
      "learning_rate": 1.254948535233571e-05,
      "loss": 0.2178,
      "step": 9460
    },
    {
      "epoch": 2.2494061757719717,
      "grad_norm": 7.503363609313965,
      "learning_rate": 1.2509897070467141e-05,
      "loss": 0.1841,
      "step": 9470
    },
    {
      "epoch": 2.2517814726840855,
      "grad_norm": 6.346668720245361,
      "learning_rate": 1.2470308788598575e-05,
      "loss": 0.203,
      "step": 9480
    },
    {
      "epoch": 2.2541567695961997,
      "grad_norm": 7.062134265899658,
      "learning_rate": 1.2430720506730008e-05,
      "loss": 0.2141,
      "step": 9490
    },
    {
      "epoch": 2.2565320665083135,
      "grad_norm": 3.989274501800537,
      "learning_rate": 1.2391132224861442e-05,
      "loss": 0.2201,
      "step": 9500
    },
    {
      "epoch": 2.2589073634204277,
      "grad_norm": 2.9363560676574707,
      "learning_rate": 1.2351543942992874e-05,
      "loss": 0.258,
      "step": 9510
    },
    {
      "epoch": 2.2612826603325415,
      "grad_norm": 3.74621844291687,
      "learning_rate": 1.2311955661124308e-05,
      "loss": 0.3215,
      "step": 9520
    },
    {
      "epoch": 2.2636579572446553,
      "grad_norm": 1.7182148694992065,
      "learning_rate": 1.227236737925574e-05,
      "loss": 0.1967,
      "step": 9530
    },
    {
      "epoch": 2.2660332541567696,
      "grad_norm": 5.102442741394043,
      "learning_rate": 1.2232779097387174e-05,
      "loss": 0.1968,
      "step": 9540
    },
    {
      "epoch": 2.268408551068884,
      "grad_norm": 3.4890880584716797,
      "learning_rate": 1.2193190815518607e-05,
      "loss": 0.2166,
      "step": 9550
    },
    {
      "epoch": 2.2707838479809976,
      "grad_norm": 2.523533344268799,
      "learning_rate": 1.2153602533650039e-05,
      "loss": 0.1707,
      "step": 9560
    },
    {
      "epoch": 2.2731591448931114,
      "grad_norm": 7.206142902374268,
      "learning_rate": 1.2114014251781473e-05,
      "loss": 0.2465,
      "step": 9570
    },
    {
      "epoch": 2.2755344418052257,
      "grad_norm": 2.9537734985351562,
      "learning_rate": 1.2074425969912905e-05,
      "loss": 0.2248,
      "step": 9580
    },
    {
      "epoch": 2.2779097387173395,
      "grad_norm": 6.387580394744873,
      "learning_rate": 1.203483768804434e-05,
      "loss": 0.2111,
      "step": 9590
    },
    {
      "epoch": 2.2802850356294537,
      "grad_norm": 4.0275163650512695,
      "learning_rate": 1.1995249406175772e-05,
      "loss": 0.2731,
      "step": 9600
    },
    {
      "epoch": 2.2826603325415675,
      "grad_norm": 4.610345840454102,
      "learning_rate": 1.1955661124307206e-05,
      "loss": 0.1803,
      "step": 9610
    },
    {
      "epoch": 2.2850356294536818,
      "grad_norm": 5.418450832366943,
      "learning_rate": 1.1916072842438638e-05,
      "loss": 0.2139,
      "step": 9620
    },
    {
      "epoch": 2.2874109263657956,
      "grad_norm": 3.0949978828430176,
      "learning_rate": 1.187648456057007e-05,
      "loss": 0.1784,
      "step": 9630
    },
    {
      "epoch": 2.28978622327791,
      "grad_norm": 4.350263595581055,
      "learning_rate": 1.1836896278701505e-05,
      "loss": 0.2116,
      "step": 9640
    },
    {
      "epoch": 2.2921615201900236,
      "grad_norm": 5.8209733963012695,
      "learning_rate": 1.1797307996832937e-05,
      "loss": 0.2652,
      "step": 9650
    },
    {
      "epoch": 2.294536817102138,
      "grad_norm": 7.391633033752441,
      "learning_rate": 1.1757719714964371e-05,
      "loss": 0.2591,
      "step": 9660
    },
    {
      "epoch": 2.2969121140142517,
      "grad_norm": 3.7903308868408203,
      "learning_rate": 1.1718131433095803e-05,
      "loss": 0.2262,
      "step": 9670
    },
    {
      "epoch": 2.299287410926366,
      "grad_norm": 3.6617531776428223,
      "learning_rate": 1.1678543151227237e-05,
      "loss": 0.2727,
      "step": 9680
    },
    {
      "epoch": 2.3016627078384797,
      "grad_norm": 2.9864869117736816,
      "learning_rate": 1.163895486935867e-05,
      "loss": 0.2203,
      "step": 9690
    },
    {
      "epoch": 2.304038004750594,
      "grad_norm": 0.991157591342926,
      "learning_rate": 1.1599366587490102e-05,
      "loss": 0.2985,
      "step": 9700
    },
    {
      "epoch": 2.3064133016627077,
      "grad_norm": 1.3024911880493164,
      "learning_rate": 1.1559778305621536e-05,
      "loss": 0.2059,
      "step": 9710
    },
    {
      "epoch": 2.308788598574822,
      "grad_norm": 6.358224868774414,
      "learning_rate": 1.1520190023752968e-05,
      "loss": 0.1836,
      "step": 9720
    },
    {
      "epoch": 2.311163895486936,
      "grad_norm": 4.526340961456299,
      "learning_rate": 1.1480601741884402e-05,
      "loss": 0.2403,
      "step": 9730
    },
    {
      "epoch": 2.31353919239905,
      "grad_norm": 9.19950008392334,
      "learning_rate": 1.1441013460015835e-05,
      "loss": 0.2356,
      "step": 9740
    },
    {
      "epoch": 2.315914489311164,
      "grad_norm": 5.065297603607178,
      "learning_rate": 1.1401425178147269e-05,
      "loss": 0.2991,
      "step": 9750
    },
    {
      "epoch": 2.318289786223278,
      "grad_norm": 3.123328685760498,
      "learning_rate": 1.1361836896278701e-05,
      "loss": 0.2248,
      "step": 9760
    },
    {
      "epoch": 2.320665083135392,
      "grad_norm": 7.841549873352051,
      "learning_rate": 1.1322248614410135e-05,
      "loss": 0.2182,
      "step": 9770
    },
    {
      "epoch": 2.323040380047506,
      "grad_norm": 5.680552959442139,
      "learning_rate": 1.1282660332541568e-05,
      "loss": 0.3464,
      "step": 9780
    },
    {
      "epoch": 2.32541567695962,
      "grad_norm": 3.9024620056152344,
      "learning_rate": 1.1243072050673002e-05,
      "loss": 0.2541,
      "step": 9790
    },
    {
      "epoch": 2.3277909738717337,
      "grad_norm": 6.266867637634277,
      "learning_rate": 1.1203483768804434e-05,
      "loss": 0.2362,
      "step": 9800
    },
    {
      "epoch": 2.330166270783848,
      "grad_norm": 3.386449098587036,
      "learning_rate": 1.1163895486935868e-05,
      "loss": 0.258,
      "step": 9810
    },
    {
      "epoch": 2.332541567695962,
      "grad_norm": 5.348028659820557,
      "learning_rate": 1.11243072050673e-05,
      "loss": 0.2489,
      "step": 9820
    },
    {
      "epoch": 2.334916864608076,
      "grad_norm": 4.6518754959106445,
      "learning_rate": 1.1084718923198734e-05,
      "loss": 0.2228,
      "step": 9830
    },
    {
      "epoch": 2.33729216152019,
      "grad_norm": 8.001349449157715,
      "learning_rate": 1.1045130641330167e-05,
      "loss": 0.223,
      "step": 9840
    },
    {
      "epoch": 2.339667458432304,
      "grad_norm": 5.120555400848389,
      "learning_rate": 1.10055423594616e-05,
      "loss": 0.3336,
      "step": 9850
    },
    {
      "epoch": 2.342042755344418,
      "grad_norm": 6.755390644073486,
      "learning_rate": 1.0965954077593033e-05,
      "loss": 0.2828,
      "step": 9860
    },
    {
      "epoch": 2.344418052256532,
      "grad_norm": 5.323808670043945,
      "learning_rate": 1.0926365795724467e-05,
      "loss": 0.264,
      "step": 9870
    },
    {
      "epoch": 2.346793349168646,
      "grad_norm": 2.3541524410247803,
      "learning_rate": 1.08867775138559e-05,
      "loss": 0.1638,
      "step": 9880
    },
    {
      "epoch": 2.34916864608076,
      "grad_norm": 5.424722671508789,
      "learning_rate": 1.0847189231987333e-05,
      "loss": 0.2391,
      "step": 9890
    },
    {
      "epoch": 2.351543942992874,
      "grad_norm": 5.55483341217041,
      "learning_rate": 1.0807600950118766e-05,
      "loss": 0.198,
      "step": 9900
    },
    {
      "epoch": 2.353919239904988,
      "grad_norm": 2.8202643394470215,
      "learning_rate": 1.0768012668250198e-05,
      "loss": 0.1794,
      "step": 9910
    },
    {
      "epoch": 2.356294536817102,
      "grad_norm": 6.208324909210205,
      "learning_rate": 1.0728424386381632e-05,
      "loss": 0.371,
      "step": 9920
    },
    {
      "epoch": 2.3586698337292162,
      "grad_norm": 3.3523032665252686,
      "learning_rate": 1.0688836104513065e-05,
      "loss": 0.2845,
      "step": 9930
    },
    {
      "epoch": 2.36104513064133,
      "grad_norm": 4.625404357910156,
      "learning_rate": 1.0649247822644499e-05,
      "loss": 0.2318,
      "step": 9940
    },
    {
      "epoch": 2.3634204275534443,
      "grad_norm": 3.646916389465332,
      "learning_rate": 1.0609659540775931e-05,
      "loss": 0.1701,
      "step": 9950
    },
    {
      "epoch": 2.365795724465558,
      "grad_norm": 3.857598304748535,
      "learning_rate": 1.0570071258907365e-05,
      "loss": 0.261,
      "step": 9960
    },
    {
      "epoch": 2.3681710213776723,
      "grad_norm": 5.994571685791016,
      "learning_rate": 1.0530482977038797e-05,
      "loss": 0.2923,
      "step": 9970
    },
    {
      "epoch": 2.370546318289786,
      "grad_norm": 1.865014910697937,
      "learning_rate": 1.049089469517023e-05,
      "loss": 0.2211,
      "step": 9980
    },
    {
      "epoch": 2.3729216152019004,
      "grad_norm": 5.15483283996582,
      "learning_rate": 1.0451306413301664e-05,
      "loss": 0.2967,
      "step": 9990
    },
    {
      "epoch": 2.375296912114014,
      "grad_norm": 4.019330024719238,
      "learning_rate": 1.0411718131433096e-05,
      "loss": 0.2332,
      "step": 10000
    },
    {
      "epoch": 2.3776722090261284,
      "grad_norm": 3.1507952213287354,
      "learning_rate": 1.037212984956453e-05,
      "loss": 0.2575,
      "step": 10010
    },
    {
      "epoch": 2.380047505938242,
      "grad_norm": 4.177978515625,
      "learning_rate": 1.0332541567695962e-05,
      "loss": 0.2451,
      "step": 10020
    },
    {
      "epoch": 2.3824228028503565,
      "grad_norm": 5.873077869415283,
      "learning_rate": 1.0292953285827396e-05,
      "loss": 0.2347,
      "step": 10030
    },
    {
      "epoch": 2.3847980997624703,
      "grad_norm": 6.250515937805176,
      "learning_rate": 1.0253365003958829e-05,
      "loss": 0.3195,
      "step": 10040
    },
    {
      "epoch": 2.3871733966745845,
      "grad_norm": 4.99135160446167,
      "learning_rate": 1.0213776722090261e-05,
      "loss": 0.273,
      "step": 10050
    },
    {
      "epoch": 2.3895486935866983,
      "grad_norm": 4.918543338775635,
      "learning_rate": 1.0174188440221695e-05,
      "loss": 0.2336,
      "step": 10060
    },
    {
      "epoch": 2.391923990498812,
      "grad_norm": 2.848452091217041,
      "learning_rate": 1.0134600158353127e-05,
      "loss": 0.2671,
      "step": 10070
    },
    {
      "epoch": 2.3942992874109263,
      "grad_norm": 3.8211781978607178,
      "learning_rate": 1.0095011876484562e-05,
      "loss": 0.2442,
      "step": 10080
    },
    {
      "epoch": 2.3966745843230406,
      "grad_norm": 5.34468936920166,
      "learning_rate": 1.0055423594615994e-05,
      "loss": 0.2349,
      "step": 10090
    },
    {
      "epoch": 2.3990498812351544,
      "grad_norm": 1.8964005708694458,
      "learning_rate": 1.0015835312747428e-05,
      "loss": 0.23,
      "step": 10100
    },
    {
      "epoch": 2.401425178147268,
      "grad_norm": 6.127842903137207,
      "learning_rate": 9.97624703087886e-06,
      "loss": 0.1979,
      "step": 10110
    },
    {
      "epoch": 2.4038004750593824,
      "grad_norm": 1.4506819248199463,
      "learning_rate": 9.936658749010293e-06,
      "loss": 0.3047,
      "step": 10120
    },
    {
      "epoch": 2.4061757719714967,
      "grad_norm": 2.4864306449890137,
      "learning_rate": 9.897070467141727e-06,
      "loss": 0.267,
      "step": 10130
    },
    {
      "epoch": 2.4085510688836105,
      "grad_norm": 6.43599796295166,
      "learning_rate": 9.857482185273159e-06,
      "loss": 0.182,
      "step": 10140
    },
    {
      "epoch": 2.4109263657957243,
      "grad_norm": 9.727895736694336,
      "learning_rate": 9.817893903404593e-06,
      "loss": 0.3033,
      "step": 10150
    },
    {
      "epoch": 2.4133016627078385,
      "grad_norm": 4.80397367477417,
      "learning_rate": 9.778305621536025e-06,
      "loss": 0.281,
      "step": 10160
    },
    {
      "epoch": 2.4156769596199523,
      "grad_norm": 3.5950515270233154,
      "learning_rate": 9.73871733966746e-06,
      "loss": 0.2532,
      "step": 10170
    },
    {
      "epoch": 2.4180522565320666,
      "grad_norm": 8.149469375610352,
      "learning_rate": 9.699129057798892e-06,
      "loss": 0.3527,
      "step": 10180
    },
    {
      "epoch": 2.4204275534441804,
      "grad_norm": 3.119236707687378,
      "learning_rate": 9.659540775930324e-06,
      "loss": 0.2387,
      "step": 10190
    },
    {
      "epoch": 2.4228028503562946,
      "grad_norm": 3.248317241668701,
      "learning_rate": 9.619952494061758e-06,
      "loss": 0.2125,
      "step": 10200
    },
    {
      "epoch": 2.4251781472684084,
      "grad_norm": 5.217310905456543,
      "learning_rate": 9.58036421219319e-06,
      "loss": 0.2712,
      "step": 10210
    },
    {
      "epoch": 2.4275534441805227,
      "grad_norm": 2.3646910190582275,
      "learning_rate": 9.540775930324624e-06,
      "loss": 0.32,
      "step": 10220
    },
    {
      "epoch": 2.4299287410926365,
      "grad_norm": 2.029292106628418,
      "learning_rate": 9.501187648456057e-06,
      "loss": 0.2516,
      "step": 10230
    },
    {
      "epoch": 2.4323040380047507,
      "grad_norm": 2.9840641021728516,
      "learning_rate": 9.46159936658749e-06,
      "loss": 0.1903,
      "step": 10240
    },
    {
      "epoch": 2.4346793349168645,
      "grad_norm": 1.3180060386657715,
      "learning_rate": 9.422011084718923e-06,
      "loss": 0.2171,
      "step": 10250
    },
    {
      "epoch": 2.4370546318289787,
      "grad_norm": 2.722398519515991,
      "learning_rate": 9.382422802850356e-06,
      "loss": 0.1701,
      "step": 10260
    },
    {
      "epoch": 2.4394299287410925,
      "grad_norm": 1.133342981338501,
      "learning_rate": 9.34283452098179e-06,
      "loss": 0.2338,
      "step": 10270
    },
    {
      "epoch": 2.441805225653207,
      "grad_norm": 4.1808390617370605,
      "learning_rate": 9.303246239113222e-06,
      "loss": 0.2414,
      "step": 10280
    },
    {
      "epoch": 2.4441805225653206,
      "grad_norm": 2.2823336124420166,
      "learning_rate": 9.263657957244656e-06,
      "loss": 0.3144,
      "step": 10290
    },
    {
      "epoch": 2.446555819477435,
      "grad_norm": 5.001722812652588,
      "learning_rate": 9.224069675376088e-06,
      "loss": 0.1609,
      "step": 10300
    },
    {
      "epoch": 2.4489311163895486,
      "grad_norm": 4.803506374359131,
      "learning_rate": 9.184481393507522e-06,
      "loss": 0.2061,
      "step": 10310
    },
    {
      "epoch": 2.451306413301663,
      "grad_norm": 7.03750467300415,
      "learning_rate": 9.144893111638955e-06,
      "loss": 0.3176,
      "step": 10320
    },
    {
      "epoch": 2.4536817102137767,
      "grad_norm": 2.2652270793914795,
      "learning_rate": 9.105304829770387e-06,
      "loss": 0.2039,
      "step": 10330
    },
    {
      "epoch": 2.456057007125891,
      "grad_norm": 0.850679874420166,
      "learning_rate": 9.065716547901821e-06,
      "loss": 0.1326,
      "step": 10340
    },
    {
      "epoch": 2.4584323040380047,
      "grad_norm": 2.6956543922424316,
      "learning_rate": 9.026128266033253e-06,
      "loss": 0.2633,
      "step": 10350
    },
    {
      "epoch": 2.460807600950119,
      "grad_norm": 4.33331298828125,
      "learning_rate": 8.986539984164687e-06,
      "loss": 0.2271,
      "step": 10360
    },
    {
      "epoch": 2.4631828978622328,
      "grad_norm": 4.282079219818115,
      "learning_rate": 8.94695170229612e-06,
      "loss": 0.2722,
      "step": 10370
    },
    {
      "epoch": 2.4655581947743466,
      "grad_norm": 3.2736988067626953,
      "learning_rate": 8.907363420427554e-06,
      "loss": 0.2094,
      "step": 10380
    },
    {
      "epoch": 2.467933491686461,
      "grad_norm": 10.619024276733398,
      "learning_rate": 8.867775138558986e-06,
      "loss": 0.2875,
      "step": 10390
    },
    {
      "epoch": 2.470308788598575,
      "grad_norm": 7.0945563316345215,
      "learning_rate": 8.82818685669042e-06,
      "loss": 0.2312,
      "step": 10400
    },
    {
      "epoch": 2.472684085510689,
      "grad_norm": 1.485780119895935,
      "learning_rate": 8.788598574821852e-06,
      "loss": 0.2628,
      "step": 10410
    },
    {
      "epoch": 2.4750593824228027,
      "grad_norm": 2.019775152206421,
      "learning_rate": 8.749010292953287e-06,
      "loss": 0.2806,
      "step": 10420
    },
    {
      "epoch": 2.477434679334917,
      "grad_norm": 5.168828964233398,
      "learning_rate": 8.709422011084719e-06,
      "loss": 0.135,
      "step": 10430
    },
    {
      "epoch": 2.4798099762470307,
      "grad_norm": 4.396110534667969,
      "learning_rate": 8.669833729216153e-06,
      "loss": 0.2137,
      "step": 10440
    },
    {
      "epoch": 2.482185273159145,
      "grad_norm": 4.910580635070801,
      "learning_rate": 8.630245447347585e-06,
      "loss": 0.2177,
      "step": 10450
    },
    {
      "epoch": 2.4845605700712587,
      "grad_norm": 3.4492664337158203,
      "learning_rate": 8.59065716547902e-06,
      "loss": 0.2493,
      "step": 10460
    },
    {
      "epoch": 2.486935866983373,
      "grad_norm": 6.223938465118408,
      "learning_rate": 8.551068883610452e-06,
      "loss": 0.2294,
      "step": 10470
    },
    {
      "epoch": 2.489311163895487,
      "grad_norm": 3.6472349166870117,
      "learning_rate": 8.511480601741886e-06,
      "loss": 0.2223,
      "step": 10480
    },
    {
      "epoch": 2.491686460807601,
      "grad_norm": 5.899288654327393,
      "learning_rate": 8.471892319873318e-06,
      "loss": 0.2109,
      "step": 10490
    },
    {
      "epoch": 2.494061757719715,
      "grad_norm": 4.796184539794922,
      "learning_rate": 8.432304038004752e-06,
      "loss": 0.2332,
      "step": 10500
    },
    {
      "epoch": 2.496437054631829,
      "grad_norm": 7.14527702331543,
      "learning_rate": 8.392715756136184e-06,
      "loss": 0.2138,
      "step": 10510
    },
    {
      "epoch": 2.498812351543943,
      "grad_norm": 0.988159716129303,
      "learning_rate": 8.353127474267618e-06,
      "loss": 0.1805,
      "step": 10520
    },
    {
      "epoch": 2.501187648456057,
      "grad_norm": 7.606086730957031,
      "learning_rate": 8.31353919239905e-06,
      "loss": 0.2173,
      "step": 10530
    },
    {
      "epoch": 2.503562945368171,
      "grad_norm": 9.791285514831543,
      "learning_rate": 8.273950910530483e-06,
      "loss": 0.2111,
      "step": 10540
    },
    {
      "epoch": 2.505938242280285,
      "grad_norm": 10.167927742004395,
      "learning_rate": 8.234362628661917e-06,
      "loss": 0.2771,
      "step": 10550
    },
    {
      "epoch": 2.508313539192399,
      "grad_norm": 6.439793586730957,
      "learning_rate": 8.19477434679335e-06,
      "loss": 0.1931,
      "step": 10560
    },
    {
      "epoch": 2.510688836104513,
      "grad_norm": 7.121138572692871,
      "learning_rate": 8.155186064924784e-06,
      "loss": 0.2574,
      "step": 10570
    },
    {
      "epoch": 2.513064133016627,
      "grad_norm": 5.107353687286377,
      "learning_rate": 8.115597783056216e-06,
      "loss": 0.2981,
      "step": 10580
    },
    {
      "epoch": 2.5154394299287413,
      "grad_norm": 3.2141454219818115,
      "learning_rate": 8.07600950118765e-06,
      "loss": 0.2476,
      "step": 10590
    },
    {
      "epoch": 2.517814726840855,
      "grad_norm": 5.5264763832092285,
      "learning_rate": 8.036421219319082e-06,
      "loss": 0.2546,
      "step": 10600
    },
    {
      "epoch": 2.520190023752969,
      "grad_norm": 3.226771831512451,
      "learning_rate": 7.996832937450515e-06,
      "loss": 0.1431,
      "step": 10610
    },
    {
      "epoch": 2.522565320665083,
      "grad_norm": 10.444999694824219,
      "learning_rate": 7.957244655581949e-06,
      "loss": 0.1773,
      "step": 10620
    },
    {
      "epoch": 2.5249406175771973,
      "grad_norm": 4.616898536682129,
      "learning_rate": 7.917656373713381e-06,
      "loss": 0.2097,
      "step": 10630
    },
    {
      "epoch": 2.527315914489311,
      "grad_norm": 5.150763511657715,
      "learning_rate": 7.878068091844815e-06,
      "loss": 0.1685,
      "step": 10640
    },
    {
      "epoch": 2.529691211401425,
      "grad_norm": 5.541269779205322,
      "learning_rate": 7.838479809976247e-06,
      "loss": 0.3199,
      "step": 10650
    },
    {
      "epoch": 2.532066508313539,
      "grad_norm": 10.808958053588867,
      "learning_rate": 7.798891528107681e-06,
      "loss": 0.2747,
      "step": 10660
    },
    {
      "epoch": 2.5344418052256534,
      "grad_norm": 5.381624221801758,
      "learning_rate": 7.759303246239114e-06,
      "loss": 0.2664,
      "step": 10670
    },
    {
      "epoch": 2.5368171021377672,
      "grad_norm": 2.0847909450531006,
      "learning_rate": 7.719714964370546e-06,
      "loss": 0.2151,
      "step": 10680
    },
    {
      "epoch": 2.539192399049881,
      "grad_norm": 4.109890937805176,
      "learning_rate": 7.68012668250198e-06,
      "loss": 0.3241,
      "step": 10690
    },
    {
      "epoch": 2.5415676959619953,
      "grad_norm": 3.6677374839782715,
      "learning_rate": 7.640538400633412e-06,
      "loss": 0.3033,
      "step": 10700
    },
    {
      "epoch": 2.5439429928741095,
      "grad_norm": 6.388497352600098,
      "learning_rate": 7.6009501187648464e-06,
      "loss": 0.23,
      "step": 10710
    },
    {
      "epoch": 2.5463182897862233,
      "grad_norm": 2.2965664863586426,
      "learning_rate": 7.561361836896279e-06,
      "loss": 0.177,
      "step": 10720
    },
    {
      "epoch": 2.548693586698337,
      "grad_norm": 5.556093215942383,
      "learning_rate": 7.521773555027713e-06,
      "loss": 0.2628,
      "step": 10730
    },
    {
      "epoch": 2.5510688836104514,
      "grad_norm": 5.5402069091796875,
      "learning_rate": 7.482185273159145e-06,
      "loss": 0.2648,
      "step": 10740
    },
    {
      "epoch": 2.553444180522565,
      "grad_norm": 4.643080711364746,
      "learning_rate": 7.4425969912905775e-06,
      "loss": 0.2102,
      "step": 10750
    },
    {
      "epoch": 2.5558194774346794,
      "grad_norm": 4.421738147735596,
      "learning_rate": 7.4030087094220115e-06,
      "loss": 0.2334,
      "step": 10760
    },
    {
      "epoch": 2.558194774346793,
      "grad_norm": 1.1008658409118652,
      "learning_rate": 7.363420427553444e-06,
      "loss": 0.1786,
      "step": 10770
    },
    {
      "epoch": 2.5605700712589075,
      "grad_norm": 3.4921391010284424,
      "learning_rate": 7.323832145684878e-06,
      "loss": 0.2376,
      "step": 10780
    },
    {
      "epoch": 2.5629453681710213,
      "grad_norm": 8.279617309570312,
      "learning_rate": 7.28424386381631e-06,
      "loss": 0.2507,
      "step": 10790
    },
    {
      "epoch": 2.5653206650831355,
      "grad_norm": 4.280498027801514,
      "learning_rate": 7.244655581947744e-06,
      "loss": 0.2833,
      "step": 10800
    },
    {
      "epoch": 2.5676959619952493,
      "grad_norm": 7.5255842208862305,
      "learning_rate": 7.205067300079177e-06,
      "loss": 0.246,
      "step": 10810
    },
    {
      "epoch": 2.5700712589073635,
      "grad_norm": 5.305319786071777,
      "learning_rate": 7.165479018210609e-06,
      "loss": 0.172,
      "step": 10820
    },
    {
      "epoch": 2.5724465558194773,
      "grad_norm": 1.4742168188095093,
      "learning_rate": 7.125890736342043e-06,
      "loss": 0.2279,
      "step": 10830
    },
    {
      "epoch": 2.5748218527315916,
      "grad_norm": 2.744807481765747,
      "learning_rate": 7.086302454473475e-06,
      "loss": 0.2129,
      "step": 10840
    },
    {
      "epoch": 2.5771971496437054,
      "grad_norm": 3.0658860206604004,
      "learning_rate": 7.046714172604909e-06,
      "loss": 0.3026,
      "step": 10850
    },
    {
      "epoch": 2.5795724465558196,
      "grad_norm": 4.150461196899414,
      "learning_rate": 7.007125890736342e-06,
      "loss": 0.1837,
      "step": 10860
    },
    {
      "epoch": 2.5819477434679334,
      "grad_norm": 4.398141384124756,
      "learning_rate": 6.967537608867776e-06,
      "loss": 0.255,
      "step": 10870
    },
    {
      "epoch": 2.5843230403800472,
      "grad_norm": 5.096343994140625,
      "learning_rate": 6.927949326999208e-06,
      "loss": 0.2443,
      "step": 10880
    },
    {
      "epoch": 2.5866983372921615,
      "grad_norm": 2.9002630710601807,
      "learning_rate": 6.888361045130641e-06,
      "loss": 0.2082,
      "step": 10890
    },
    {
      "epoch": 2.5890736342042757,
      "grad_norm": 2.126002788543701,
      "learning_rate": 6.8487727632620745e-06,
      "loss": 0.2567,
      "step": 10900
    },
    {
      "epoch": 2.5914489311163895,
      "grad_norm": 3.902216672897339,
      "learning_rate": 6.809184481393508e-06,
      "loss": 0.217,
      "step": 10910
    },
    {
      "epoch": 2.5938242280285033,
      "grad_norm": 3.344088077545166,
      "learning_rate": 6.769596199524941e-06,
      "loss": 0.2377,
      "step": 10920
    },
    {
      "epoch": 2.5961995249406176,
      "grad_norm": 2.214629650115967,
      "learning_rate": 6.730007917656374e-06,
      "loss": 0.1866,
      "step": 10930
    },
    {
      "epoch": 2.598574821852732,
      "grad_norm": 4.360372543334961,
      "learning_rate": 6.690419635787808e-06,
      "loss": 0.181,
      "step": 10940
    },
    {
      "epoch": 2.6009501187648456,
      "grad_norm": 3.5331294536590576,
      "learning_rate": 6.6508313539192404e-06,
      "loss": 0.173,
      "step": 10950
    },
    {
      "epoch": 2.6033254156769594,
      "grad_norm": 4.981261253356934,
      "learning_rate": 6.611243072050673e-06,
      "loss": 0.1836,
      "step": 10960
    },
    {
      "epoch": 2.6057007125890737,
      "grad_norm": 4.691564559936523,
      "learning_rate": 6.571654790182107e-06,
      "loss": 0.2988,
      "step": 10970
    },
    {
      "epoch": 2.608076009501188,
      "grad_norm": 1.4472975730895996,
      "learning_rate": 6.532066508313539e-06,
      "loss": 0.221,
      "step": 10980
    },
    {
      "epoch": 2.6104513064133017,
      "grad_norm": 4.286965370178223,
      "learning_rate": 6.492478226444973e-06,
      "loss": 0.2134,
      "step": 10990
    },
    {
      "epoch": 2.6128266033254155,
      "grad_norm": 3.711883544921875,
      "learning_rate": 6.4528899445764055e-06,
      "loss": 0.2066,
      "step": 11000
    },
    {
      "epoch": 2.6152019002375297,
      "grad_norm": 4.210353374481201,
      "learning_rate": 6.4133016627078396e-06,
      "loss": 0.1336,
      "step": 11010
    },
    {
      "epoch": 2.6175771971496435,
      "grad_norm": 1.284882664680481,
      "learning_rate": 6.373713380839272e-06,
      "loss": 0.2764,
      "step": 11020
    },
    {
      "epoch": 2.619952494061758,
      "grad_norm": 2.265042543411255,
      "learning_rate": 6.334125098970704e-06,
      "loss": 0.2051,
      "step": 11030
    },
    {
      "epoch": 2.6223277909738716,
      "grad_norm": 6.892951011657715,
      "learning_rate": 6.294536817102138e-06,
      "loss": 0.3123,
      "step": 11040
    },
    {
      "epoch": 2.624703087885986,
      "grad_norm": 3.256230592727661,
      "learning_rate": 6.254948535233571e-06,
      "loss": 0.2059,
      "step": 11050
    },
    {
      "epoch": 2.6270783847980996,
      "grad_norm": 6.092556953430176,
      "learning_rate": 6.215360253365004e-06,
      "loss": 0.2563,
      "step": 11060
    },
    {
      "epoch": 2.629453681710214,
      "grad_norm": 8.821176528930664,
      "learning_rate": 6.175771971496437e-06,
      "loss": 0.2507,
      "step": 11070
    },
    {
      "epoch": 2.6318289786223277,
      "grad_norm": 3.946295738220215,
      "learning_rate": 6.13618368962787e-06,
      "loss": 0.3044,
      "step": 11080
    },
    {
      "epoch": 2.634204275534442,
      "grad_norm": 4.085963249206543,
      "learning_rate": 6.096595407759303e-06,
      "loss": 0.2437,
      "step": 11090
    },
    {
      "epoch": 2.6365795724465557,
      "grad_norm": 7.386174201965332,
      "learning_rate": 6.0570071258907366e-06,
      "loss": 0.1935,
      "step": 11100
    },
    {
      "epoch": 2.63895486935867,
      "grad_norm": 3.386143445968628,
      "learning_rate": 6.01741884402217e-06,
      "loss": 0.1648,
      "step": 11110
    },
    {
      "epoch": 2.6413301662707838,
      "grad_norm": 7.324734210968018,
      "learning_rate": 5.977830562153603e-06,
      "loss": 0.3042,
      "step": 11120
    },
    {
      "epoch": 2.643705463182898,
      "grad_norm": 8.251937866210938,
      "learning_rate": 5.938242280285035e-06,
      "loss": 0.2598,
      "step": 11130
    },
    {
      "epoch": 2.646080760095012,
      "grad_norm": 4.617021083831787,
      "learning_rate": 5.8986539984164685e-06,
      "loss": 0.249,
      "step": 11140
    },
    {
      "epoch": 2.648456057007126,
      "grad_norm": 4.00510835647583,
      "learning_rate": 5.859065716547902e-06,
      "loss": 0.2391,
      "step": 11150
    },
    {
      "epoch": 2.65083135391924,
      "grad_norm": 1.3549208641052246,
      "learning_rate": 5.819477434679335e-06,
      "loss": 0.2956,
      "step": 11160
    },
    {
      "epoch": 2.653206650831354,
      "grad_norm": 2.2440924644470215,
      "learning_rate": 5.779889152810768e-06,
      "loss": 0.1555,
      "step": 11170
    },
    {
      "epoch": 2.655581947743468,
      "grad_norm": 2.6639554500579834,
      "learning_rate": 5.740300870942201e-06,
      "loss": 0.209,
      "step": 11180
    },
    {
      "epoch": 2.6579572446555817,
      "grad_norm": 4.140618324279785,
      "learning_rate": 5.700712589073634e-06,
      "loss": 0.2231,
      "step": 11190
    },
    {
      "epoch": 2.660332541567696,
      "grad_norm": 7.3650946617126465,
      "learning_rate": 5.661124307205068e-06,
      "loss": 0.2474,
      "step": 11200
    },
    {
      "epoch": 2.66270783847981,
      "grad_norm": 6.615248680114746,
      "learning_rate": 5.621536025336501e-06,
      "loss": 0.2443,
      "step": 11210
    },
    {
      "epoch": 2.665083135391924,
      "grad_norm": 10.251533508300781,
      "learning_rate": 5.581947743467934e-06,
      "loss": 0.2925,
      "step": 11220
    },
    {
      "epoch": 2.667458432304038,
      "grad_norm": 6.119657516479492,
      "learning_rate": 5.542359461599367e-06,
      "loss": 0.1529,
      "step": 11230
    },
    {
      "epoch": 2.669833729216152,
      "grad_norm": 6.09833288192749,
      "learning_rate": 5.5027711797308e-06,
      "loss": 0.237,
      "step": 11240
    },
    {
      "epoch": 2.6722090261282663,
      "grad_norm": 6.294963836669922,
      "learning_rate": 5.4631828978622335e-06,
      "loss": 0.2017,
      "step": 11250
    },
    {
      "epoch": 2.67458432304038,
      "grad_norm": 3.5027027130126953,
      "learning_rate": 5.423594615993667e-06,
      "loss": 0.2138,
      "step": 11260
    },
    {
      "epoch": 2.676959619952494,
      "grad_norm": 6.884472846984863,
      "learning_rate": 5.384006334125099e-06,
      "loss": 0.2861,
      "step": 11270
    },
    {
      "epoch": 2.679334916864608,
      "grad_norm": 4.646119594573975,
      "learning_rate": 5.344418052256532e-06,
      "loss": 0.3478,
      "step": 11280
    },
    {
      "epoch": 2.6817102137767224,
      "grad_norm": 5.571839809417725,
      "learning_rate": 5.3048297703879655e-06,
      "loss": 0.1889,
      "step": 11290
    },
    {
      "epoch": 2.684085510688836,
      "grad_norm": 3.1491942405700684,
      "learning_rate": 5.265241488519399e-06,
      "loss": 0.2548,
      "step": 11300
    },
    {
      "epoch": 2.68646080760095,
      "grad_norm": 5.803753852844238,
      "learning_rate": 5.225653206650832e-06,
      "loss": 0.2853,
      "step": 11310
    },
    {
      "epoch": 2.688836104513064,
      "grad_norm": 5.571955680847168,
      "learning_rate": 5.186064924782265e-06,
      "loss": 0.2406,
      "step": 11320
    },
    {
      "epoch": 2.691211401425178,
      "grad_norm": 3.658505916595459,
      "learning_rate": 5.146476642913698e-06,
      "loss": 0.2305,
      "step": 11330
    },
    {
      "epoch": 2.6935866983372923,
      "grad_norm": 8.292651176452637,
      "learning_rate": 5.1068883610451305e-06,
      "loss": 0.2434,
      "step": 11340
    },
    {
      "epoch": 2.695961995249406,
      "grad_norm": 11.11442756652832,
      "learning_rate": 5.067300079176564e-06,
      "loss": 0.2225,
      "step": 11350
    },
    {
      "epoch": 2.6983372921615203,
      "grad_norm": 5.51689338684082,
      "learning_rate": 5.027711797307997e-06,
      "loss": 0.3584,
      "step": 11360
    },
    {
      "epoch": 2.700712589073634,
      "grad_norm": 2.556077241897583,
      "learning_rate": 4.98812351543943e-06,
      "loss": 0.2346,
      "step": 11370
    },
    {
      "epoch": 2.7030878859857483,
      "grad_norm": 3.859525203704834,
      "learning_rate": 4.948535233570863e-06,
      "loss": 0.3468,
      "step": 11380
    },
    {
      "epoch": 2.705463182897862,
      "grad_norm": 2.987435817718506,
      "learning_rate": 4.9089469517022965e-06,
      "loss": 0.1813,
      "step": 11390
    },
    {
      "epoch": 2.7078384798099764,
      "grad_norm": 6.283468246459961,
      "learning_rate": 4.86935866983373e-06,
      "loss": 0.2416,
      "step": 11400
    },
    {
      "epoch": 2.71021377672209,
      "grad_norm": 1.7344145774841309,
      "learning_rate": 4.829770387965162e-06,
      "loss": 0.1392,
      "step": 11410
    },
    {
      "epoch": 2.7125890736342044,
      "grad_norm": 6.712685585021973,
      "learning_rate": 4.790182106096595e-06,
      "loss": 0.1453,
      "step": 11420
    },
    {
      "epoch": 2.7149643705463182,
      "grad_norm": 0.9011420011520386,
      "learning_rate": 4.750593824228028e-06,
      "loss": 0.2217,
      "step": 11430
    },
    {
      "epoch": 2.7173396674584325,
      "grad_norm": 6.692962646484375,
      "learning_rate": 4.711005542359462e-06,
      "loss": 0.2167,
      "step": 11440
    },
    {
      "epoch": 2.7197149643705463,
      "grad_norm": 11.014299392700195,
      "learning_rate": 4.671417260490895e-06,
      "loss": 0.2786,
      "step": 11450
    },
    {
      "epoch": 2.72209026128266,
      "grad_norm": 3.952275276184082,
      "learning_rate": 4.631828978622328e-06,
      "loss": 0.1907,
      "step": 11460
    },
    {
      "epoch": 2.7244655581947743,
      "grad_norm": 9.728678703308105,
      "learning_rate": 4.592240696753761e-06,
      "loss": 0.2108,
      "step": 11470
    },
    {
      "epoch": 2.7268408551068886,
      "grad_norm": 2.829892158508301,
      "learning_rate": 4.5526524148851935e-06,
      "loss": 0.221,
      "step": 11480
    },
    {
      "epoch": 2.7292161520190024,
      "grad_norm": 3.0920214653015137,
      "learning_rate": 4.513064133016627e-06,
      "loss": 0.1695,
      "step": 11490
    },
    {
      "epoch": 2.731591448931116,
      "grad_norm": 2.4015207290649414,
      "learning_rate": 4.47347585114806e-06,
      "loss": 0.1795,
      "step": 11500
    },
    {
      "epoch": 2.7339667458432304,
      "grad_norm": 4.26130485534668,
      "learning_rate": 4.433887569279493e-06,
      "loss": 0.2282,
      "step": 11510
    },
    {
      "epoch": 2.7363420427553447,
      "grad_norm": 7.456071376800537,
      "learning_rate": 4.394299287410926e-06,
      "loss": 0.263,
      "step": 11520
    },
    {
      "epoch": 2.7387173396674585,
      "grad_norm": 4.090663909912109,
      "learning_rate": 4.3547110055423594e-06,
      "loss": 0.2507,
      "step": 11530
    },
    {
      "epoch": 2.7410926365795723,
      "grad_norm": 0.902913510799408,
      "learning_rate": 4.315122723673793e-06,
      "loss": 0.2566,
      "step": 11540
    },
    {
      "epoch": 2.7434679334916865,
      "grad_norm": 6.8285136222839355,
      "learning_rate": 4.275534441805226e-06,
      "loss": 0.2836,
      "step": 11550
    },
    {
      "epoch": 2.7458432304038007,
      "grad_norm": 7.841450214385986,
      "learning_rate": 4.235946159936659e-06,
      "loss": 0.3404,
      "step": 11560
    },
    {
      "epoch": 2.7482185273159145,
      "grad_norm": 5.747529029846191,
      "learning_rate": 4.196357878068092e-06,
      "loss": 0.2631,
      "step": 11570
    },
    {
      "epoch": 2.7505938242280283,
      "grad_norm": 5.725616455078125,
      "learning_rate": 4.156769596199525e-06,
      "loss": 0.3118,
      "step": 11580
    },
    {
      "epoch": 2.7529691211401426,
      "grad_norm": 1.8525036573410034,
      "learning_rate": 4.1171813143309586e-06,
      "loss": 0.2695,
      "step": 11590
    },
    {
      "epoch": 2.7553444180522564,
      "grad_norm": 2.284318685531616,
      "learning_rate": 4.077593032462392e-06,
      "loss": 0.1729,
      "step": 11600
    },
    {
      "epoch": 2.7577197149643706,
      "grad_norm": 7.402403831481934,
      "learning_rate": 4.038004750593825e-06,
      "loss": 0.2185,
      "step": 11610
    },
    {
      "epoch": 2.7600950118764844,
      "grad_norm": 7.999599456787109,
      "learning_rate": 3.998416468725257e-06,
      "loss": 0.2726,
      "step": 11620
    },
    {
      "epoch": 2.7624703087885987,
      "grad_norm": 7.453600883483887,
      "learning_rate": 3.9588281868566905e-06,
      "loss": 0.2309,
      "step": 11630
    },
    {
      "epoch": 2.7648456057007125,
      "grad_norm": 2.4827394485473633,
      "learning_rate": 3.919239904988124e-06,
      "loss": 0.2844,
      "step": 11640
    },
    {
      "epoch": 2.7672209026128267,
      "grad_norm": 7.186317443847656,
      "learning_rate": 3.879651623119557e-06,
      "loss": 0.272,
      "step": 11650
    },
    {
      "epoch": 2.7695961995249405,
      "grad_norm": 1.8441416025161743,
      "learning_rate": 3.84006334125099e-06,
      "loss": 0.3102,
      "step": 11660
    },
    {
      "epoch": 2.7719714964370548,
      "grad_norm": 1.2975605726242065,
      "learning_rate": 3.8004750593824232e-06,
      "loss": 0.2179,
      "step": 11670
    },
    {
      "epoch": 2.7743467933491686,
      "grad_norm": 6.934550762176514,
      "learning_rate": 3.7608867775138564e-06,
      "loss": 0.2604,
      "step": 11680
    },
    {
      "epoch": 2.776722090261283,
      "grad_norm": 2.1332645416259766,
      "learning_rate": 3.7212984956452888e-06,
      "loss": 0.1695,
      "step": 11690
    },
    {
      "epoch": 2.7790973871733966,
      "grad_norm": 3.4919774532318115,
      "learning_rate": 3.681710213776722e-06,
      "loss": 0.1769,
      "step": 11700
    },
    {
      "epoch": 2.781472684085511,
      "grad_norm": 3.372360944747925,
      "learning_rate": 3.642121931908155e-06,
      "loss": 0.2538,
      "step": 11710
    },
    {
      "epoch": 2.7838479809976246,
      "grad_norm": 6.791434288024902,
      "learning_rate": 3.6025336500395883e-06,
      "loss": 0.2497,
      "step": 11720
    },
    {
      "epoch": 2.7862232779097384,
      "grad_norm": 4.964412212371826,
      "learning_rate": 3.5629453681710215e-06,
      "loss": 0.2066,
      "step": 11730
    },
    {
      "epoch": 2.7885985748218527,
      "grad_norm": 3.671468496322632,
      "learning_rate": 3.5233570863024547e-06,
      "loss": 0.2199,
      "step": 11740
    },
    {
      "epoch": 2.790973871733967,
      "grad_norm": 1.725723385810852,
      "learning_rate": 3.483768804433888e-06,
      "loss": 0.1603,
      "step": 11750
    },
    {
      "epoch": 2.7933491686460807,
      "grad_norm": 2.9580087661743164,
      "learning_rate": 3.4441805225653207e-06,
      "loss": 0.1805,
      "step": 11760
    },
    {
      "epoch": 2.7957244655581945,
      "grad_norm": 6.654819488525391,
      "learning_rate": 3.404592240696754e-06,
      "loss": 0.2252,
      "step": 11770
    },
    {
      "epoch": 2.798099762470309,
      "grad_norm": 8.267431259155273,
      "learning_rate": 3.365003958828187e-06,
      "loss": 0.2885,
      "step": 11780
    },
    {
      "epoch": 2.800475059382423,
      "grad_norm": 5.826049327850342,
      "learning_rate": 3.3254156769596202e-06,
      "loss": 0.2605,
      "step": 11790
    },
    {
      "epoch": 2.802850356294537,
      "grad_norm": 3.1074113845825195,
      "learning_rate": 3.2858273950910534e-06,
      "loss": 0.1451,
      "step": 11800
    },
    {
      "epoch": 2.8052256532066506,
      "grad_norm": 3.429009437561035,
      "learning_rate": 3.2462391132224866e-06,
      "loss": 0.231,
      "step": 11810
    },
    {
      "epoch": 2.807600950118765,
      "grad_norm": 2.205167293548584,
      "learning_rate": 3.2066508313539198e-06,
      "loss": 0.2208,
      "step": 11820
    },
    {
      "epoch": 2.809976247030879,
      "grad_norm": 3.0042881965637207,
      "learning_rate": 3.167062549485352e-06,
      "loss": 0.1662,
      "step": 11830
    },
    {
      "epoch": 2.812351543942993,
      "grad_norm": 4.307830333709717,
      "learning_rate": 3.1274742676167853e-06,
      "loss": 0.2662,
      "step": 11840
    },
    {
      "epoch": 2.8147268408551067,
      "grad_norm": 3.6894798278808594,
      "learning_rate": 3.0878859857482185e-06,
      "loss": 0.1801,
      "step": 11850
    },
    {
      "epoch": 2.817102137767221,
      "grad_norm": 2.3866119384765625,
      "learning_rate": 3.0482977038796517e-06,
      "loss": 0.1947,
      "step": 11860
    },
    {
      "epoch": 2.8194774346793348,
      "grad_norm": 6.956467151641846,
      "learning_rate": 3.008709422011085e-06,
      "loss": 0.2204,
      "step": 11870
    },
    {
      "epoch": 2.821852731591449,
      "grad_norm": 3.5012969970703125,
      "learning_rate": 2.9691211401425176e-06,
      "loss": 0.2709,
      "step": 11880
    },
    {
      "epoch": 2.824228028503563,
      "grad_norm": 5.153655529022217,
      "learning_rate": 2.929532858273951e-06,
      "loss": 0.2601,
      "step": 11890
    },
    {
      "epoch": 2.826603325415677,
      "grad_norm": 1.629255771636963,
      "learning_rate": 2.889944576405384e-06,
      "loss": 0.2321,
      "step": 11900
    },
    {
      "epoch": 2.828978622327791,
      "grad_norm": 3.0901482105255127,
      "learning_rate": 2.850356294536817e-06,
      "loss": 0.1852,
      "step": 11910
    },
    {
      "epoch": 2.831353919239905,
      "grad_norm": 2.8423171043395996,
      "learning_rate": 2.8107680126682504e-06,
      "loss": 0.3105,
      "step": 11920
    },
    {
      "epoch": 2.833729216152019,
      "grad_norm": 8.140326499938965,
      "learning_rate": 2.7711797307996836e-06,
      "loss": 0.2065,
      "step": 11930
    },
    {
      "epoch": 2.836104513064133,
      "grad_norm": 4.4756951332092285,
      "learning_rate": 2.7315914489311168e-06,
      "loss": 0.272,
      "step": 11940
    },
    {
      "epoch": 2.838479809976247,
      "grad_norm": 4.461867809295654,
      "learning_rate": 2.6920031670625495e-06,
      "loss": 0.2012,
      "step": 11950
    },
    {
      "epoch": 2.840855106888361,
      "grad_norm": 6.91685676574707,
      "learning_rate": 2.6524148851939827e-06,
      "loss": 0.3356,
      "step": 11960
    },
    {
      "epoch": 2.843230403800475,
      "grad_norm": 5.182732105255127,
      "learning_rate": 2.612826603325416e-06,
      "loss": 0.1909,
      "step": 11970
    },
    {
      "epoch": 2.8456057007125892,
      "grad_norm": 5.63961935043335,
      "learning_rate": 2.573238321456849e-06,
      "loss": 0.1677,
      "step": 11980
    },
    {
      "epoch": 2.847980997624703,
      "grad_norm": 4.298917770385742,
      "learning_rate": 2.533650039588282e-06,
      "loss": 0.2765,
      "step": 11990
    },
    {
      "epoch": 2.850356294536817,
      "grad_norm": 1.6238521337509155,
      "learning_rate": 2.494061757719715e-06,
      "loss": 0.1753,
      "step": 12000
    },
    {
      "epoch": 2.852731591448931,
      "grad_norm": 2.223053455352783,
      "learning_rate": 2.4544734758511482e-06,
      "loss": 0.1782,
      "step": 12010
    },
    {
      "epoch": 2.8551068883610453,
      "grad_norm": 1.0161633491516113,
      "learning_rate": 2.414885193982581e-06,
      "loss": 0.3453,
      "step": 12020
    },
    {
      "epoch": 2.857482185273159,
      "grad_norm": 4.662700176239014,
      "learning_rate": 2.375296912114014e-06,
      "loss": 0.2601,
      "step": 12030
    },
    {
      "epoch": 2.859857482185273,
      "grad_norm": 6.184931755065918,
      "learning_rate": 2.3357086302454474e-06,
      "loss": 0.1815,
      "step": 12040
    },
    {
      "epoch": 2.862232779097387,
      "grad_norm": 2.602983236312866,
      "learning_rate": 2.2961203483768806e-06,
      "loss": 0.1682,
      "step": 12050
    },
    {
      "epoch": 2.8646080760095014,
      "grad_norm": 5.9568095207214355,
      "learning_rate": 2.2565320665083133e-06,
      "loss": 0.2447,
      "step": 12060
    },
    {
      "epoch": 2.866983372921615,
      "grad_norm": 14.729241371154785,
      "learning_rate": 2.2169437846397465e-06,
      "loss": 0.2465,
      "step": 12070
    },
    {
      "epoch": 2.869358669833729,
      "grad_norm": 2.42111873626709,
      "learning_rate": 2.1773555027711797e-06,
      "loss": 0.1746,
      "step": 12080
    },
    {
      "epoch": 2.8717339667458432,
      "grad_norm": 4.263469219207764,
      "learning_rate": 2.137767220902613e-06,
      "loss": 0.2062,
      "step": 12090
    },
    {
      "epoch": 2.8741092636579575,
      "grad_norm": 3.558389902114868,
      "learning_rate": 2.098178939034046e-06,
      "loss": 0.2844,
      "step": 12100
    },
    {
      "epoch": 2.8764845605700713,
      "grad_norm": 5.654034614562988,
      "learning_rate": 2.0585906571654793e-06,
      "loss": 0.2586,
      "step": 12110
    },
    {
      "epoch": 2.878859857482185,
      "grad_norm": 3.0217535495758057,
      "learning_rate": 2.0190023752969125e-06,
      "loss": 0.1792,
      "step": 12120
    },
    {
      "epoch": 2.8812351543942993,
      "grad_norm": 0.925412118434906,
      "learning_rate": 1.9794140934283452e-06,
      "loss": 0.137,
      "step": 12130
    },
    {
      "epoch": 2.883610451306413,
      "grad_norm": 3.0098280906677246,
      "learning_rate": 1.9398258115597784e-06,
      "loss": 0.2442,
      "step": 12140
    },
    {
      "epoch": 2.8859857482185274,
      "grad_norm": 8.514504432678223,
      "learning_rate": 1.9002375296912116e-06,
      "loss": 0.2726,
      "step": 12150
    },
    {
      "epoch": 2.888361045130641,
      "grad_norm": 1.2604937553405762,
      "learning_rate": 1.8606492478226444e-06,
      "loss": 0.2053,
      "step": 12160
    },
    {
      "epoch": 2.8907363420427554,
      "grad_norm": 4.003965854644775,
      "learning_rate": 1.8210609659540776e-06,
      "loss": 0.2816,
      "step": 12170
    },
    {
      "epoch": 2.8931116389548692,
      "grad_norm": 2.9828169345855713,
      "learning_rate": 1.7814726840855108e-06,
      "loss": 0.2265,
      "step": 12180
    },
    {
      "epoch": 2.8954869358669835,
      "grad_norm": 5.553674221038818,
      "learning_rate": 1.741884402216944e-06,
      "loss": 0.2249,
      "step": 12190
    },
    {
      "epoch": 2.8978622327790973,
      "grad_norm": 5.474271297454834,
      "learning_rate": 1.702296120348377e-06,
      "loss": 0.2468,
      "step": 12200
    },
    {
      "epoch": 2.9002375296912115,
      "grad_norm": 4.217159748077393,
      "learning_rate": 1.6627078384798101e-06,
      "loss": 0.2487,
      "step": 12210
    },
    {
      "epoch": 2.9026128266033253,
      "grad_norm": 1.892781138420105,
      "learning_rate": 1.6231195566112433e-06,
      "loss": 0.1438,
      "step": 12220
    },
    {
      "epoch": 2.9049881235154396,
      "grad_norm": 6.353714466094971,
      "learning_rate": 1.583531274742676e-06,
      "loss": 0.2091,
      "step": 12230
    },
    {
      "epoch": 2.9073634204275534,
      "grad_norm": 1.8602066040039062,
      "learning_rate": 1.5439429928741092e-06,
      "loss": 0.2253,
      "step": 12240
    },
    {
      "epoch": 2.9097387173396676,
      "grad_norm": 5.037982940673828,
      "learning_rate": 1.5043547110055424e-06,
      "loss": 0.1858,
      "step": 12250
    },
    {
      "epoch": 2.9121140142517814,
      "grad_norm": 5.554229259490967,
      "learning_rate": 1.4647664291369754e-06,
      "loss": 0.1956,
      "step": 12260
    },
    {
      "epoch": 2.9144893111638956,
      "grad_norm": 2.9430158138275146,
      "learning_rate": 1.4251781472684086e-06,
      "loss": 0.1667,
      "step": 12270
    },
    {
      "epoch": 2.9168646080760094,
      "grad_norm": 3.973555088043213,
      "learning_rate": 1.3855898653998418e-06,
      "loss": 0.2624,
      "step": 12280
    },
    {
      "epoch": 2.9192399049881237,
      "grad_norm": 5.537790298461914,
      "learning_rate": 1.3460015835312748e-06,
      "loss": 0.2336,
      "step": 12290
    },
    {
      "epoch": 2.9216152019002375,
      "grad_norm": 2.6654884815216064,
      "learning_rate": 1.306413301662708e-06,
      "loss": 0.2538,
      "step": 12300
    },
    {
      "epoch": 2.9239904988123513,
      "grad_norm": 1.6480774879455566,
      "learning_rate": 1.266825019794141e-06,
      "loss": 0.2491,
      "step": 12310
    },
    {
      "epoch": 2.9263657957244655,
      "grad_norm": 5.204351902008057,
      "learning_rate": 1.2272367379255741e-06,
      "loss": 0.2332,
      "step": 12320
    },
    {
      "epoch": 2.92874109263658,
      "grad_norm": 5.2203779220581055,
      "learning_rate": 1.187648456057007e-06,
      "loss": 0.2575,
      "step": 12330
    },
    {
      "epoch": 2.9311163895486936,
      "grad_norm": 2.450068235397339,
      "learning_rate": 1.1480601741884403e-06,
      "loss": 0.2599,
      "step": 12340
    },
    {
      "epoch": 2.9334916864608074,
      "grad_norm": 4.53778600692749,
      "learning_rate": 1.1084718923198733e-06,
      "loss": 0.2514,
      "step": 12350
    },
    {
      "epoch": 2.9358669833729216,
      "grad_norm": 10.569989204406738,
      "learning_rate": 1.0688836104513065e-06,
      "loss": 0.3141,
      "step": 12360
    },
    {
      "epoch": 2.938242280285036,
      "grad_norm": 3.8555147647857666,
      "learning_rate": 1.0292953285827396e-06,
      "loss": 0.2514,
      "step": 12370
    },
    {
      "epoch": 2.9406175771971497,
      "grad_norm": 3.5533199310302734,
      "learning_rate": 9.897070467141726e-07,
      "loss": 0.3026,
      "step": 12380
    },
    {
      "epoch": 2.9429928741092635,
      "grad_norm": 0.75933438539505,
      "learning_rate": 9.501187648456058e-07,
      "loss": 0.2313,
      "step": 12390
    },
    {
      "epoch": 2.9453681710213777,
      "grad_norm": 5.781267166137695,
      "learning_rate": 9.105304829770388e-07,
      "loss": 0.2126,
      "step": 12400
    },
    {
      "epoch": 2.947743467933492,
      "grad_norm": 2.0670406818389893,
      "learning_rate": 8.70942201108472e-07,
      "loss": 0.1382,
      "step": 12410
    },
    {
      "epoch": 2.9501187648456058,
      "grad_norm": 4.7621989250183105,
      "learning_rate": 8.313539192399051e-07,
      "loss": 0.3034,
      "step": 12420
    },
    {
      "epoch": 2.9524940617577196,
      "grad_norm": 6.836242198944092,
      "learning_rate": 7.91765637371338e-07,
      "loss": 0.2379,
      "step": 12430
    },
    {
      "epoch": 2.954869358669834,
      "grad_norm": 5.235250473022461,
      "learning_rate": 7.521773555027712e-07,
      "loss": 0.1922,
      "step": 12440
    },
    {
      "epoch": 2.9572446555819476,
      "grad_norm": 2.3469150066375732,
      "learning_rate": 7.125890736342043e-07,
      "loss": 0.1983,
      "step": 12450
    },
    {
      "epoch": 2.959619952494062,
      "grad_norm": 5.799537658691406,
      "learning_rate": 6.730007917656374e-07,
      "loss": 0.2653,
      "step": 12460
    },
    {
      "epoch": 2.9619952494061756,
      "grad_norm": 7.993014335632324,
      "learning_rate": 6.334125098970705e-07,
      "loss": 0.1991,
      "step": 12470
    },
    {
      "epoch": 2.96437054631829,
      "grad_norm": 2.6242501735687256,
      "learning_rate": 5.938242280285035e-07,
      "loss": 0.255,
      "step": 12480
    },
    {
      "epoch": 2.9667458432304037,
      "grad_norm": 9.183503150939941,
      "learning_rate": 5.542359461599366e-07,
      "loss": 0.1705,
      "step": 12490
    },
    {
      "epoch": 2.969121140142518,
      "grad_norm": 3.827383279800415,
      "learning_rate": 5.146476642913698e-07,
      "loss": 0.2102,
      "step": 12500
    },
    {
      "epoch": 2.9714964370546317,
      "grad_norm": 1.1418956518173218,
      "learning_rate": 4.750593824228029e-07,
      "loss": 0.2479,
      "step": 12510
    },
    {
      "epoch": 2.973871733966746,
      "grad_norm": 4.445493221282959,
      "learning_rate": 4.35471100554236e-07,
      "loss": 0.1707,
      "step": 12520
    },
    {
      "epoch": 2.97624703087886,
      "grad_norm": 6.6430158615112305,
      "learning_rate": 3.95882818685669e-07,
      "loss": 0.2657,
      "step": 12530
    },
    {
      "epoch": 2.978622327790974,
      "grad_norm": 2.193411111831665,
      "learning_rate": 3.5629453681710215e-07,
      "loss": 0.1928,
      "step": 12540
    },
    {
      "epoch": 2.980997624703088,
      "grad_norm": 10.553242683410645,
      "learning_rate": 3.1670625494853523e-07,
      "loss": 0.1689,
      "step": 12550
    },
    {
      "epoch": 2.983372921615202,
      "grad_norm": 4.934523105621338,
      "learning_rate": 2.771179730799683e-07,
      "loss": 0.2071,
      "step": 12560
    },
    {
      "epoch": 2.985748218527316,
      "grad_norm": 4.832884311676025,
      "learning_rate": 2.3752969121140145e-07,
      "loss": 0.2839,
      "step": 12570
    },
    {
      "epoch": 2.9881235154394297,
      "grad_norm": 4.583235740661621,
      "learning_rate": 1.979414093428345e-07,
      "loss": 0.2297,
      "step": 12580
    },
    {
      "epoch": 2.990498812351544,
      "grad_norm": 1.0729763507843018,
      "learning_rate": 1.5835312747426762e-07,
      "loss": 0.1946,
      "step": 12590
    },
    {
      "epoch": 2.992874109263658,
      "grad_norm": 6.757442951202393,
      "learning_rate": 1.1876484560570073e-07,
      "loss": 0.2619,
      "step": 12600
    },
    {
      "epoch": 2.995249406175772,
      "grad_norm": 2.886103868484497,
      "learning_rate": 7.917656373713381e-08,
      "loss": 0.2201,
      "step": 12610
    },
    {
      "epoch": 2.9976247030878858,
      "grad_norm": 4.411028861999512,
      "learning_rate": 3.9588281868566904e-08,
      "loss": 0.2883,
      "step": 12620
    },
    {
      "epoch": 3.0,
      "grad_norm": 17.914278030395508,
      "learning_rate": 0.0,
      "loss": 0.2955,
      "step": 12630
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.29417434334754944,
      "eval_runtime": 51.7003,
      "eval_samples_per_second": 16.866,
      "eval_steps_per_second": 1.064,
      "step": 12630
    }
  ],
  "logging_steps": 10,
  "max_steps": 12630,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6805923233854464.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
